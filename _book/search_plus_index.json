{"简历.html":{"url":"简历.html","title":"个人简历","keywords":"","body":"联系方式 手机：18069898338 Email：18069898338@163.com 微信号：Benjamin-Fy 个人信息 方洋/男/1993 教育:大专/武汉软件工程职业学院（2012～2015） 工作年限：6年 期望职位：项目主管、Java资深后端开发 期望薪资：30k~35k 期望城市：杭州 技能清单 Linux : 熟练使用 Linux，有 Linux 下开发的实际经验。 Java：熟练掌握 Java 基础知识、并发、AQS、设计模式、在线诊断工具(Arthas)、JVM排查问题和调优。 数据库：熟练掌握 MySQL 数据库以及常见优化手段（比如索引、SQL 优化、ShardingJDBC读写分离&分库分表、Druid监控sql执行情况）; Redis 使用经验丰富,如缓存雪崩，缓存穿透，缓存击穿，热点缓存重建。 框架：熟练掌握 Spring、 SpringBoot、Spring Cloud、MyBatis等主流开发框架。 搜索引擎 ：熟练掌握 Elasticsearch 的使用及原理。 分布式： 熟练掌握 RPC（Dubbo）、分布式事务（Seata AT 模式）、注册与配置中心（nacos）、分布式日志链路追踪、应用性能监控分析（Elastic APM）、分布式 id（Snowflake）的使用； 熟悉 Spring Cloud（Ribbon、Feign、Hystrix） 全家桶常见组件的使用； 高并发&高可用 ：熟练消息队列 RabbitMQ、RocketMQ、Kafka 的使用，解决过各种消息通信场景的疑难问题，如消息丢失、消息重复消费，消息顺序性，大规模消息积压问题 ;有限流、降级、熔断的实战经验； 工具：掌握 Git、Maven、Docker。 建模工具: VSCode+ Plantuml (用例图、时序图、活动图)、Processon(架构图)、DbSchema (数据库ER图建模)、Markmap （思维导图）、VSCode+MarkDown(文档编写)。 其他： 熟练规则引擎QLExpress、熟悉领域驱动DDD模型、了解反应式编程。 工作经历 杭州今元标矩科技有限公司(金柚网)（ 2020.07 ~ 至今 ） 项目名称: 人力资源SaaS平台 项目描述 [!note] 人力资源SaaS平台是服务公司业务人员的综合性内部管理系统，为互联网、餐饮、零售、在线教育等多行业提供业务外包、招聘外包、社会化用工、商保等，提供一体化HR SaaS平台。为业务人员从线下转向线上全流程数字化服务，降本增效；目前已为85000+企业提供服务。 涉及技术 Ngnix、SpringCloud、Nacos、FeignClient、Hystrix、Redis、Mysql、Mybatis、Elasticsearch、RocketMQ、XXL-Job、Kubernetes、Jenkins、Swagger 设计技术 1、采用分布式的项目开发模式整个项目可分社保、薪税、商保、财务、CRM、审批中心、消息中心、招聘交付、发薪、考勤等二十多个服务组成； 2、复杂批量数据导入，采用EasyExcel、Validation验证框架、CompletableFuture(线程池)、规则引擎QLExpress等来适应灵活多变的规则并提升性能； 3、项目分布式事务采用两种方式 异步（最终一致性）：RocketMQ最大努力通知的分布式事务去处理分布式事务场景； 同步（强一致性）：开源分布式事务框架 Seata AT 模式； 4、数据量较大的表使用Sharding-JDBC在实现了主从的基础上实现分库分表，读写分离； 5、利用Hystrix: 服务降级、断路器机制、资源隔离、调用超时保护、请求缓存、请求合并； 责任描述 1、制定系统架构及复杂业务的解决方案架构,负责分布式平台基础组件的搭建（如注册中心、配置中心、Seata、XXL-JOB、RocketMQ等）, 并产出架构设计文档； 2、推动搭建Elasticsearch、Filebeat、Kibana、Logstash组合的ELK日志收集搜索系统；唯一标识traceId追踪全部链路显示在日志中（Logback、TransmittableThreadLocal）； 3、负责核心代码编写及维护、主导核心业务性能优化，技术文档的编写以及维护，coding代码。在公司内部组织过数次技术分享，主题包括Elastic APM 应用性能监控分析 , 使用规则引擎QLExpress、分布式日志链路跟踪、Arthas在线诊断工具 等； 4、推行领域驱动模型代码风格，对代码质量高要求，分享DDD领域驱动架构模型分析； 5、负责服务器的规划、日常监控、故障处理、日志分析、性能瓶颈分析等工作。对线上服务器资源维护、提高系统的可用率及可维护性，节约公司服务器成本； 项目总结 [!note] 前期主要工作是与团队将整个项目是从单体式架构迁移到微服务架构，包括技术选型调研、服务抽取、数据量递增预估后分库分表。提升了系统架构设计与文档梳理能力。积极性强。中后期项目趋于稳定，能主动挤出时间承担技术平台或工具类或组件类的建设工作，并对这一块的工作推动起到了作用；对系统出现的慢sql、慢接口提出经验性的的想法，如有必要提供可行的方案并主导优化。落实代码 Review、迭代回顾会、技术分享会等关键制度或规范。 杭州弧途科技有限公司 （ 2018.07 ~ 2020.06 ） 项目名称: 青团社兼职 项目描述 [!note] 青团社是为大学生免费提供兼职灵活就业的平台。在为学生提供服务的同时，为企业打造优质的弹性用工服务，让企业招到优质的人，弹性使用，降低成本。累计注册商家42万、平台注册用户超2800万、单日报名人次超85万。首届支付宝小程序”青团社兼职”小程序冠军，从支付宝首页资源位引流拉新。 涉及技术 Ngnix、SpringCloud、FeignClient、Hystrix、Redis、Mysql、Mybatis、Elasticsearch、RocketMQ、Kafka、Hbase 设计技术 1、采用分布式的项目开发模式整个项目可分兼职、兼职报名单、商家、支付、积分商城、小任务、用户、资源位、标签、埋点、评价等二十多个服务组成; 2、基于RocketMQ支持事务消息特点，采用最大努力通知的方案去处理分布式事务场景; 3、基于Redis、消息中间件、悲观锁版本号，实现兼职报名幂等，支持高并发场景（支付宝引流峰值8000QPS）; 4、对于数据量较大的表使用Sharding-JDBC在实现了主从的基础上实现分库分表，读写分离; 5、采用Elasticsearch分布式搜索引擎，实现数据库数据同步ES提升高并发场景的搜索效率，同时采用ik中文分词器强化了分词搜索; 责任描述 1、负责商家端 商家实名认证、组织部门录入、兼职发布、敏感词过滤、自动化审核、客服复核、录取、报名查询等; 订单、支付、充值与纪录、消费纪录、商家中心、反馈、会员续费、升级、商家权益等; 2、负责Elasticsearch兼职查询相关需求开发; 3、短信、APP消息推送; 4、对接阿里云平台，拉取服务慢接口、SQL、错误日志解析后存入后台管理系统展示。每日定时推送钉钉，督促各业务线进行优化; 项目总结 [!note] 通过该项目的开发，对高并发，大数据量等业务场景有了自己的认识，也知道在什么样的场景下，结合Redis、RocketMQ、Elasticsearch等中间件的使用提高服务性能效率，以及面对高并发的场景做怎样的及时应对.leader每次review代码也能发现我的成长。在CTO与同事的带领下，从需求评审、视觉评审，到自己的用例图、时序图、数据库ER图的设计，开发、链调、提测、上线每个环节，不断学习总结。 杭州万家乐网络有限公司 （ 2017.05 ～ 2018.07 ） 点滴信用 [!note] 点滴信用模拟虚拟城市生活让用户更清晰的体验在日常生活中有哪些影响信用的行为，用户在点滴信用中 的日常信用行为都会生成相应的数据报表。 趣借钱 [!note] P2P，移动互联网金融APP,专为用户提供小额短期、纯信用的实时借款服务 东信昆辰科技股份有限公司（2015.11～ 2017.03 ） 获客无忧 技术文章 一个产品经理眼中的云计算：前生今世和未来 来自HeroKu的HTTP API 设计指南(翻译文章) （ 好的翻译文章可以侧证你对英文技术文档的阅读能力） 致谢 感谢您花时间阅读我的简历，期待能有机会和您共事。 "},"./":{"url":"./","title":"基础技能","keywords":"","body":"Java篇 计算机基础 计算机组成原理、操作系统、计算机网络、数据结构算法 建模工具 用例图、时序图、活动图: https://plantuml.com/zh 架构图: https://www.processon.com/ 数据库ER图建模: https://dbschema.com/?AFFILIATE=96594&__c=1 思维导图: https://markmap.js.org 文档编写: VSCode、MarkDown 博客 1、强烈推荐（Java基础底层源码解析）:https://javadoop.com/ 2、综合知识汇总:https://snailclimb.gitee.io/javaguide/#/?id=java 3、各主流框架源码解析（芋道源码）:https://www.iocoder.cn/ 4、Baeldung:https://www.baeldung.com 一个外国博客，提供了Java生态中各种主流实践与指导 5、Guava官方教程:https://github.com/google/guava/wiki 6、正则表达式入门:https://deerchao.cn/tutorials/regex/regex.htm 7、Maven命令:https://maven.apache.org/plugins/index.html 视频 Java全栈入门优质视频教程： http://www.atguigu.com/download.shtml https://www.bilibili.com/read/cv5216534/?spm_id_from=333.788.b_636f6d6d656e74.5 公众号 芋道源码 付费课程 极客时间（推荐） 腾讯课堂 慕课网 技术社区 https://juejin.cn/ https://tech.meituan.com/ 书籍 Jvm相关：《深入java虚拟机（周志明第3版）》、《Java性能调优指南》 Java并发：《Java并发编程实战》 数据存储：《高性能Mysql》、《Redis设计与实现》、Elasticsearch 其他：《Effective Java》、《代码简洁之道》、《重构-改善既有代码的设计》、《设计模式》、《Spring源码深度解析》 分布式相关：《大型网站技术架构》、《大型分布式网站架构设计与实践》、《分布式服务框架原理与实践》、《数据密集型应用系统设计》 版本控制相关：《Pro Git》 "},"架构图.html":{"url":"架构图.html","title":"系统架构图系列","keywords":"","body":"技术评审涉及相关图 用例图示例 [!note] 由VSCode编辑器、plantuml语法生成 https://plantuml.com/zh/ 时序图示例 [!note] 由VSCode、plantuml生成 活动图示例 [!note] 由VSCode、plantuml生成 系统架构图 [!note] 由Processon生成 "},"chapter1/":{"url":"chapter1/","title":"1.技术文档","keywords":"","body":"技术文档 [!note] 主要是记录一些项目中封装调研的中间件 "},"chapter1/section1.html":{"url":"chapter1/section1.html","title":"1.1 规则引擎QLExpress","keywords":"","body":"规则引擎QLExpress 前言 [!note] 目前业务逻辑比较复杂，只有不断的添加if-else去满足复杂的业务场景，规则逻辑在不断的发生改变，如果在代码中写死，那么发生一个改变就需要改一下代码，测试人员需要进行全链路的回归后，在进行系统的发布上线，引擎可以改变目前现状，通过高效可靠的方式去适应这些业务规则的改变。 增加业务的透明程度，目前只能通过代码口口相传. 规则引擎能将业务判断逻辑从系统逻辑中捷解藕出来，使多种逻辑可以独立而变化，降低逻辑的维护成本。 减少业务人员和开发人员的矛盾，开发人员通常会因为一些时间因素或者一些理解不到位导致业务人员的规则实现有偏差。 之前刚进如社保组的写的第一个模块是政策包导入，一个完整的excel表头字段有150个，目前先抛开性能优化的解决的难点。目前只讨论针对灵活多变的参数验证可以多达300多条，单纯用java硬编码的话，单单验证这块代码量可能就会超过一万行。这个时候就需要引入今天我要说的规则引擎。 说明: 下面的活动图、状态图都是根据plantuml脚本语言生成的。另外还支持顺序图、用例图、类图、对象图、组建图、部署图、时序图等。 网站:https://plantuml.com/zh/ 常见的案例分析 [!note] 首先来看下项目中一些实际业务场景。通过这些场景能更好的理解什么是规则。在每个场景后面都介绍系统现在使用的解决方案以及主要的优缺点。 对于表单投保（康康）信息验证 场景 康康中的企业表单投保导入入库前，投保单作为投保的第一个门卡，其中的第一步就是针对一些字段的校验规则。 下面梳理了在投保过程中投保人信息的业务校验的规则模型（简化），如下图 : 规则主体包含三部分 1、分支条件: 分支内逻辑条件为“==”和“ 2、简单计算规则: 如：字符串长度。 3、业务定制计算规则: 岗位选定范围、投保年龄要求、日志格式等。 方案-硬编码 // 验证基础信息 private void checkBaseInfo(FormImportBO importBO, StringBuilder errMsg, PcFormStaffRecordEntity entity) { if (StringUtils.isEmpty(importBO.getName())) { errMsg.append(\"员工姓名不能为空;\"); } if (StringUtils.isNotEmpty(importBO.getName()) && !StringUtils.isName(importBO.getName().trim())) { errMsg.append(\"员工姓名格式不正确;\"); } if (StringUtils.isEmpty(importBO.getIdentityCard())) { errMsg.append(\"身份证号码不能为空;\"); } if (StringUtils.isNotEmpty(importBO.getIdentityCard()) && !StringUtils.isIDCard(importBO.getIdentityCard().trim())) { errMsg.append(\"身份证号码格式不正确;\"); } if (StringUtils.isNotEmpty(importBO.getPhone()) && !StringUtils.isMobile(importBO.getPhone().trim())) { errMsg.append(\"手机号格式不正确;\"); } if (StringUtils.isNotEmpty(importBO.getDepartment()) && importBO.getDepartment().trim().length() > 50) { errMsg.append(\"部门字数不可超过50;\"); } 优点 1、当规则较少、变动不频繁时，开发效率最高。 2、稳定性较佳：语法级别错误不会出现，由编译系统保证。 缺点 1、规则迭代成本高：对规则的少量改动就需要走全流程（开发、测试、部署）。 2、当存量规则较多时，可维护性差。 3、规则开发和维护门槛高：规则对业务分析人员不可见。业务分析人员有规则变更需求后无法自助完成开发，需要由开发人员介入开发。 发票报销审批流程 [!note] 流程控制中心（负责在运行时根据输入的报销金额大小选择不同的流程流程节点从而构建一个流程实例），根据报销金额的大小确定本次审批走那些节点，其中的选择策略模型如下。 规则配置流转图 规则主体是分支条件 分支条件是“>、boolean”，参与计算的参数是固定值和用户输入时序报销的金额。 正常的规则配置流程 上图中QLExpress就是规则的主体，可配置的规则如下 if (approved(经理, 金额)) { if (金额 > 5000) { if (审批通过(总监, 金额)) { if (审批通过(财务, 金额)) { 报销入账(金额) } else { 打回修改(申请人) } } else { 打回修改(申请人) } } else { if (审批通过(财务, 金额)) { 报销入账(金额) } else { 打回修改(申请人) } } } else { 打回修改(申请人) } 打印(\"完成\") function 审批通过(String a, int b){ System.out.println(a + \"审批:金额:\" + b); if(b > 6000) return false; return true; } function 报销入账(int a){ System.out.println(\"报销入卡:金额:\" + a); } function 打回修改(String a){ System.out.println(\"重填:申请人:\" + a); } 3、Java脚本语言示例 /** * 执行一段文本 * * @throws Exception 异常抛出 */ @Test public void testApprove1() throws Exception { String express = \"\" + \"if (审批通过(经理, 金额)) {\\n\" + \" if (金额 > 5000) {\\n\" + \" if (审批通过(总监, 金额)) {\\n\" + \" if (审批通过(财务, 金额)) {\\n\" + \" 报销入账(金额)\\n\" + \" } else {\\n\" + \" 打回修改(申请人)\\n\" + \" }\\n\" + \" } else {\\n\" + \" 打回修改(申请人)\\n\" + \" }\\n\" + \" } else {\\n\" + \" if (审批通过(财务, 金额)) {\\n\" + \" 报销入账(金额)\\n\" + \" } else {\\n\" + \" 打回修改(申请人)\\n\" + \" }\\n\" + \" }\\n\" + \"} else {\\n\" + \" 打回修改(申请人)\\n\" + \"}\\n\" + \"打印(\\\"完成\\\")\\n\"; System.out.println(\"express = \" + express); ExpressRunner runner = new ExpressRunner(); // 定义操作符别名 runner.addFunctionOfServiceMethod(\"打印\", new AccountServiceApplicationTests(), \"println\", new String[]{\"String\"}, null); // 定义方法 runner.addFunction(\"审批通过\", new ApproveOperator(1)); runner.addFunction(\"报销入账\", new ApproveOperator(2)); runner.addFunction(\"打回修改\", new ApproveOperator(3)); // 设置上下文变量 IExpressContext expressContext = new DefaultContext<>(); expressContext.put(\"经理\", \"王经理\"); expressContext.put(\"总监\", \"李总监\"); expressContext.put(\"财务\", \"张财务\"); expressContext.put(\"申请人\", \"小强\"); expressContext.put(\"金额\", 4000); runner.execute(express, expressContext, null, false, false); } package com.example.accountservice; import com.ql.util.express.Operator; /** * 定义一个继承自com.ql.util.express.Operator的操作符 */ public class ApproveOperator extends Operator { private final int operator; public ApproveOperator(int op) { this.operator = op; } @Override public Object executeInner(Object[] list) { if (this.operator == 1) { System.out.println(list[0] + \"审批:金额:\" + list[1]); return ((Integer) list[1]) 4、优点 策略规则和执行逻辑解耦方便维护。 可以将对应的规则语句放入到mysql等数据库，如果规则有变更，可通过后台管理端对数据库中的规则语句进行操作，规则引擎直接读取最新的规则语句，就可以达到动态更新规则不影响业务需求和运行的服务实例。 5、缺点 1、业务分析师无法独立完成规则配置：由于规则主体QLE是编程语言（支持Java），因此仍然需要开发工程师维护。 2、规则规模变大以后也会变得不好维护，相对硬编码的优势便不复存在。 其他待补充todo QLExpree介绍 背景介绍 [!note] 由阿里的电商业务规则、表达式（布尔组合）、特殊数学公式计算（高精度）、语法分析、脚本二次定制等强需求而设计的一门动态脚本引擎解析工具。 在阿里集团有很强的影响力，同时为了自身不断优化、发扬开源贡献精神，于2012年开源。 QLExpress脚本引擎被广泛应用在阿里的电商业务场景，具有以下的一些特性: 下面介绍都是引用地址: https://github.com/alibaba/QLExpress 具体的可以看开源的框架的介绍 里面介绍的更加较详细. 1、线程安全，引擎运算过程中的产生的临时变量都是threadlocal类型。 2、高效执行，比较耗时的脚本编译过程可以缓存在本地机器，运行时的临时变量创建采用了缓冲池的技术，和groovy性能相当。 3、弱类型脚本语言，和groovy，javascript语法类似，虽然比强类型脚本语言要慢一些，但是使业务的灵活度大大增强。 4、安全控制, 可以通过设置相关运行参数，预防死循环、高危系统api调用等情况。 5、代码精简，依赖最小，250k的jar包适合所有java的运行环境，在android系统的低端pos机也得到广泛运用。 java语法 [!note] 支持 +, -, *, /, , =, ==, !=, <>【等同于!=】, %, mod【取模等同于%】, ++, --, in【类似sql】, like【sql语法】, &&, ||, !, 等操作符 支持for，break、continue、if then else 等标准的程序控制逻辑 1、与java语法相比，避免的一些ql写法错误 1、不支持try{}catch{} 2、注释目前只支持 /**/，不支持单行注释 // 3、不支持java8的lambda表达式 4、不支持for循环集合操作for (Item item : list) 5、弱类型语言，请不要定义类型声明, 更不要用Template（Map之类的） 6、array的声明不一样 7、min, max, round, print, println, like, in 都是系统默认函数的关键字，请不要作为变量名 2、依赖引入 com.alibaba QLExpress 3.2.0 3、扩展操作符Operator 1、替换 if then else 等关键字 /** * 替换 if then else 等关键字 * * @throws Exception 异常抛出 */ @Test public void test1() throws Exception { ExpressRunner runner = new ExpressRunner(); runner.addOperatorWithAlias(\"如果\", \"if\", null); runner.addOperatorWithAlias(\"则\", \"then\", null); runner.addOperatorWithAlias(\"否则\", \"else\", null); String express = \"如果 (语文 + 数学 + 英语 > 270) 则 {return 1;} 否则 {return 0;}\"; DefaultContext context = new DefaultContext<>(); Object execute = runner.execute(express, context, null, false, false, null); log.info(\"返回值:\" + execute.toString()); } 2、自定义Operator package com.example.accountservice; import com.ql.util.express.Operator; /** * 定义一个继承自com.ql.util.express.Operator的操作符 */ public class ApproveOperator extends Operator { private final int operator; public ApproveOperator(int op) { this.operator = op; } @Override public Object executeInner(Object[] list) { if (this.operator == 1) { System.out.println(list[0] + \"审批:金额:\" + list[1]); return ((Integer) list[1]) 3、如何使用Operator @Test public void test2() throws Exception { ExpressRunner runner = new ExpressRunner(); DefaultContext context = new DefaultContext<>(); runner.addFunction(\"join\", new ApproveOperator(1)); String express = \"join('客户经理', 2000)\"; Object execute = runner.execute(express, context, null, false, false, null); log.info(\"返回值:\" + execute.toString()); } 4、绑定java类或者对象的method /** * 绑定java类或者对象的method * * @param abc 需要转换大小的字符串. * @return the String */ public static String upper(String abc) { return abc.toUpperCase(); } /** * 绑定java类或者对象的method. * * @throws Exception 数据异常. */ @Test public void test4() throws Exception { ExpressRunner runner = new ExpressRunner(); runner.addFunctionOfClassMethod(\"转换为大写\", AccountServiceApplicationTests.class.getName(), \"upper\", new String[]{\"String\"}, null); String express = \"转换为大写(\\\"hello world\\\")\"; DefaultContext context = new DefaultContext<>(); Object execute = runner.execute(express, context, null, false, false, null); log.info(\"返回值:\" + execute.toString()); } 5、macro 宏定义 /** * macro 宏定义 * * @throws Exception 异常数据 */ @Test public void test5() throws Exception { ExpressRunner runner = new ExpressRunner(); runner.addMacro(\"计算平均成绩\", \"(语文+数学+英语)/3.0\"); runner.addMacro(\"是否优秀\", \"计算平均成绩>90\"); IExpressContext context = new DefaultContext<>(); context.put(\"语文\", 88); context.put(\"数学\", 99); context.put(\"英语\", 95); Object result = runner.execute(\"是否优秀\", context, null, false, false); log.info(\"是否优秀:\" + result); Object execute = runner.execute(\"计算平均成绩\", context, null, false, false); log.info(\"计算平均成绩:\" + execute); } 6、编译脚本，查询外部需要定义的变量和函数 /** * 获取一个表达式需要的外部变量名称列表 * * @throws Exception 异常信息. */ @Test public void test6() throws Exception { String express = \"int 平均分 = (语文 + 数学 + 英语 + 综合考试.科目2) / 4.0; return 平均分\"; ExpressRunner runner = new ExpressRunner(true, true); String[] names = runner.getOutVarNames(express); for (String s : names) { log.info(\"var:\" + s); } } 7、集合的快捷写法 /** * 集合的快捷写法 * * @throws Exception 异常信息 */ @Test public void test7() throws Exception { ExpressRunner runner = new ExpressRunner(false, false); DefaultContext context = new DefaultContext<>(); String express = \"abc = NewMap(1:1, 2:2); return abc.get(1) + abc.get(2);\"; Object r = runner.execute(express, context, null, false, false); log.info(\"r :\" + r); express = \"abc = NewList(1, 2, 3); return abc.get(1) + abc.get(2)\"; r = runner.execute(express, context, null, false, false); log.info(\"r :\" + r); express = \"abc = [1, 2, 3]; return abc[1] + abc[2];\"; r = runner.execute(express, context, null, false, false); log.info(\"r :\" + r); } 运行参数和API列表介绍 1、属性开关 isPrecise 高精度计算在会计财务中非常重要，java的float、double、int、long存在很多隐式转换，做四则运算和比较的时候其实存在非常多的安全隐患。 所以类似汇金的系统中，会有很多BigDecimal转换代码。而使用QLExpress，你只要关注数学公式本身 订单总价 = 单价 数量 + 首重价格 + （ 总重量 - 首重） 续重单价 ，然后设置这个属性即可，所有的中间运算过程都会保证不丢失精度。 /** * 是否需要高精度计算 */ private boolean isPrecise = false; isTrace /** * 是否输出所有的跟踪信息，同时还需要log级别是DEBUG级别 */ private boolean isTrace = false; 2、调用入参 /** * 执行一段文本 * @param expressString 程序文本 * @param context 执行上下文，可以扩展为包含ApplicationContext * @param errorList 输出的错误信息List * @param isCache 是否使用Cache中的指令集,建议为true * @param isTrace 是否输出详细的执行指令信息，建议为false * @param aLog 输出的log * @return object * @throws Exception */ Object execute(String expressString, IExpressContext context, List errorList, boolean isCache, boolean isTrace, Log aLog); 功能扩展API列表 安全风险控制 防止死循环 try { express = \"sum = 0; for(i = 0; i 防止调用不安全的系统api ExpressRunner runner = new ExpressRunner(); QLExpressRunStrategy.setForbiddenInvokeSecurityRiskMethods(true); DefaultContext context = new DefaultContext(); try { express = \"System.exit(1);\"; Object r = runner.execute(express, context, null, true, false); System.out.println(r); throw new Exception(\"没有捕获到不安全的方法\"); } catch (QLException e) { System.out.println(e); } 增强上下文参数Context相关的api与spring框架集成 与spring框架的无缝集成 上下文参数 IExpressContext context 非常有用，它允许put任何变量，然后在脚本中识别出来 package com.example.orderservice.service.spring; import com.ql.util.express.IExpressContext; import org.springframework.context.ApplicationContext; import java.util.HashMap; import java.util.Map; public class QLExpressContext extends HashMap implements IExpressContext { private final ApplicationContext applicationContext; public QLExpressContext(ApplicationContext applicationContext) { this.applicationContext = applicationContext; } public QLExpressContext(Map properties, ApplicationContext applicationContext) { super(properties); this.applicationContext = applicationContext; } /** * 抽象方法：根据名称从属性列表中提取属性值 */ @Override public Object get(Object name) { Object result; result = super.get(name); try { if (result == null && this.applicationContext != null && this.applicationContext.containsBean((String) name)) { // 如果在Spring容器中包含bean，则返回String的Bean result = this.applicationContext.getBean((String) name); } } catch (Exception e) { throw new RuntimeException(e); } return result; } @Override public Object put(String name, Object object) { return super.put(name, object); } } ppackage com.example.orderservice.service.spring; import com.ql.util.express.ExpressRunner; import com.ql.util.express.IExpressContext; import lombok.Getter; import org.springframework.beans.BeansException; import org.springframework.context.ApplicationContext; import org.springframework.context.ApplicationContextAware; import org.springframework.stereotype.Component; import java.util.Map; /** * （1）打通了spring容器，通过扩展IExpressContext->QLExpressContext * 获取本地变量的时候，可以获取到spring的bean * （2）在runner初始化的时候，使用了函数映射功能：addFunctionOfServiceMethod * （3）在runner初始化的时候，使用了代码映射功能：addMacro */ @Component public class QlExpressUtil implements ApplicationContextAware { private static final ExpressRunner runner; static { runner = new ExpressRunner(); } private static boolean isInitialRunner = false; private ApplicationContext applicationContext;// spring上下文 /** * @param statement 执行语句 * @param context 上下文 * @throws Exception 异常处理. */ public Object execute(String statement, Map context) throws Exception { initRunner(); IExpressContext expressContext = new QLExpressContext(context, applicationContext); return runner.execute(statement, expressContext, null, true, false); } private void initRunner() { if (isInitialRunner) { return; } synchronized (QlExpressUtil.runner) { if (isInitialRunner) { return; } try { QlExpressUtil.runner.addFunctionOfServiceMethod(\"读取用户信息\", applicationContext.getBean(\"userServiceImpl\"), \"get\", new Class[]{String.class}, null); QlExpressUtil.runner.addMacro(\"判定用户是否vip\", \"userDO.salary>200000\"); } catch (Exception e) { throw new RuntimeException(\"初始化失败表达式\", e); } } isInitialRunner = true; } @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException { this.applicationContext = applicationContext; } } 对应的Controller脚本语言 package com.example.orderservice.controller; import com.central.common.api.CommonResult; import com.example.orderservice.service.OrderService; import com.example.orderservice.service.spring.QlExpressUtil; import lombok.extern.slf4j.Slf4j; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; import javax.annotation.Resource; import java.util.HashMap; import java.util.Map; @Slf4j @RestController @RequestMapping(value = \"/order\") public class OrderController { @Resource private QlExpressUtil qlExpressUtil; @RequestMapping(\"/qle\") public CommonResult test() throws Exception { // 数据开始处理. String express = \"\" + \"if(userServiceImpl.get(nick)!=null) {\" + \" userDO = userServiceImpl.get(nick);\" + \" if(userDO.salary>20000 && userDO.salary=200000) {\" + \" System.out.println('vip客户:'+userDO.nick);\" + \" return '规则引擎该用户是VIP用户哈';\" + \" } else {\" + \" System.out.println('普通客户:'+userDO.nick);\" + \" return '规则引擎该用户是普通用户';\" + \" }\" + \"} else {\" + \" System.out.println('用户信息不存在');\" + \" return '查询不到用户信息';\" + \"}\"; Map context = new HashMap<>(); context.put(\"nick\", \"马总\"); Object execute2 = qlExpressUtil.execute(express, context); log.info(execute2.toString()); context.put(\"nick\", \"小王\"); Object execute = qlExpressUtil.execute(express, context); log.info(execute.toString()); context.put(\"nick\", \"XXX\"); Object execute1 = qlExpressUtil.execute(express, context); log.info(execute1.toString()); return CommonResult.success(\"规则引擎\"); } @RequestMapping(\"/qle2\") public CommonResult test2() throws Exception { // 规则表达式处理. String express = \"\" + \"userDO = 读取用户信息(nick);\" + \"if(userDO != null) {\" + \" if(判定用户是否vip)\" + \" System.out.println('vip客户:' + nick);\" + \"} else {\" + \" System.out.println('用户信息不存在，nick:' + nick);\" + \"}\"; Map context = new HashMap<>(); context.put(\"nick\", \"马总\"); qlExpressUtil.execute(express, context); context.put(\"nick\", \"小王\"); qlExpressUtil.execute(express, context); context.put(\"nick\", \"XXX\"); qlExpressUtil.execute(express, context); return CommonResult.success(\"规则引擎执行的方法.\"); } } 麒麟系统社保政策变更申请导入参数验证应用引擎规则 单例的规则封装 [!note] 这快目前写在代码中，后续可以单独放在表中或者专门有一个规则的系统进行服务。存在数据库可以动态的修改对应的模块的规则 package com.joyowo.smarthr.social.common.excel; import java.util.ArrayList; import java.util.List; public class SocPolicyChangeApplySingleton { private static List singleton = null; /** * 获取Singleton实例，也叫静态工厂方法 * * @return Singleton */ public static synchronized List getSingleton() { if (singleton == null) { singleton = getAggregation(); } return singleton; } /** * 关联参数验证. * * @return the list of errMessage */ private static List getAggregation() { List ruleList = new ArrayList<>(); // 缴纳主体 0:个人 1:企业 2:个+企 // 月缴个缴计算规则：0-按固定值，1-按基数比例 ruleList.add(\"if (subject==null){return \\\"数据库缴纳主体为空\\\"}\"); // 停止执行年月 需晚于等于执行开始时间 ruleList.add(\"if (getAggregation1(startYearMonthRightsAndInterests,startYearMonth)){return \\\"开始执行年月最多可往前选择12个月\\\"}\"); ruleList.add(\"if (getAggregation2(startYearMonth,endYearMonth)){return \\\"停止执行年月 需晚于等于执行开始时间\\\"}\"); // 追溯对象不为空的情况下、应该与缴纳主体一致 perTrace ruleList.add(\"if (getAggregation4(whetherRetroactive,perTrace,subject)){return \\\"追溯对象应该与政策包缴纳主体一致\\\"}\"); // 企缴固定金额（元）收费频率等于按月 缴纳主体等于企业或者全部 当且仅当“当月缴企缴规则等于按固定值”时必填 ruleList.add(\"if (chargingFrequency==0 && subject in [1,2] && monthEntCalRule==0 && entAmount==null){return \\\"企缴固定金额（元）收费频率等于按月 缴纳主体等于企业或者全部 当且仅当“当月缴企缴规则等于按固定值”时必填\\\"}\"); // 个缴固定金额（元）收费频率等于按月 缴纳主体等于个人或者全部 当且仅当“月缴个缴规则等于按固定值”时必填 ruleList.add(\"if (chargingFrequency==0 && (subject==0 || subject==2) && monthPerCalRule==0 && perAmount==null){return \\\"个缴固定金额（元） 收费频率等于按月 缴纳主体等于个人或者全部 当且仅当“月缴个缴规则等于按固定值”时必填\\\"}\"); // 企缴最低基数（元):收费频率为月,月缴企缴计算规则等于缴基数比例,缴纳主体等于企业或者全部时必填 ruleList.add(\"if (chargingFrequency==0 && subject in [1,2] && monthEntCalRule==1 && entMinCardinal==null){return \\\"企缴最低基数（元):收费频率为月,月缴企缴计算规则等于缴基数比例,缴纳主体等于企业或者全部时必填\\\"}\"); // 企缴最低基数（元):收费频率等于季年,季年缴计算规则等于按基数比例,缴纳主体等于企业或者全部时必填 ruleList.add(\"if (chargingFrequency!=0 && subject in [1,2] && seasonYearBaseCalRule==1 && entMinCardinal==null){return \\\"企缴最低基数（元):收费频率等于季年,季年缴计算规则等于按基数比例,缴纳主体等于企业或者全部时必填\\\"}\"); // 企缴最高基数（元):收费频率为月,月缴企缴计算规则等于缴基数比例,缴纳主体等于企业或者全部时必填 ruleList.add(\"if (chargingFrequency==0 && subject in [1,2] && monthEntCalRule==1 && entMaxCardinal==null){return \\\"企缴最高基数（元):收费频率为月,月缴企缴计算规则等于缴基数比例,缴纳主体等于企业或者全部时必填\\\"}\"); // 企缴最高基数（元）收费频率等于季年,季年缴计算规则等于按基数比例,缴纳主体等于个人或者全部时必填 ruleList.add(\"if (chargingFrequency!=0 && subject in [1,2] && seasonYearBaseCalRule==1 && entMaxCardinal==null){return \\\"企缴最高基数（元）收费频率等于季年,季年缴计算规则等于按基数比例,缴纳主体等于个人或者全部时必填\\\"}\"); // 企缴最高基数（元）大于等于 企缴最低基数（元) ruleList.add(\"if (entMinCardinal!=null && entMaxCardinal!=null && getAggregation3(entMaxCardinal,entMinCardinal)){return \\\"企缴最高基数（元）应该大于等于企缴最低基数（元)\\\"}\"); // 个缴最低基数(元）:收费频率为月,月缴个缴计算规则等于缴基数比例,缴纳主体等于个人或者全部时必填 ruleList.add(\"if (chargingFrequency==0 && (subject==0 || subject==2) && monthPerCalRule==1 && perMinCardinal==null){return \\\"个缴最低基数(元）收费频率为月 月缴个缴计算规则等于缴基数比例，缴纳主体等于个人或者全部时必填\\\"}\"); // 个缴最低基数(元）:收费频率等于季年,季年缴计算规则等于按基数比例,缴纳主体等于个人或者全部时必填 ruleList.add(\"if (chargingFrequency!=0 && (subject==0 || subject==2) && seasonYearBaseCalRule==1 && perMinCardinal==null){return \\\"个缴最低基数(元）收费频率等于季年 季年缴计算规则等于按基数比例 缴纳主体等于个人或者全部时必填\\\"}\"); // 个缴最高基数（元）:收费频率为月,月缴个缴计算规则等于缴基数比例,缴纳主体等于个人或者全部时必填 ruleList.add(\"if (chargingFrequency==0 && (subject==0 || subject==2) && monthPerCalRule==1 && perMaxCardinal==null){return \\\"个缴最高基数（元）收费频率为月 月缴个缴计算规则等于缴基数比例 缴纳主体等于个人或者全部时必填\\\"}\"); // 个缴最高基数（元）:收费频率等于季年,季年缴计算规则等于按基数比例,缴纳主体等于个人或者全部时必填 ruleList.add(\"if (chargingFrequency!=0 && (subject==0 || subject==2) && seasonYearBaseCalRule==1 && perMaxCardinal==null){return \\\"个缴最高基数（元）收费频率等于季年 季年缴计算规则等于按基数比例 缴纳主体等于个人或者全部时必填\\\"}\"); // 个缴最高基数（元）大于等于 个缴最低基数(元） ruleList.add(\"if ( (subject==0 || subject==2) && perMinCardinal!=null && perMaxCardinal!=null && getAggregation3(perMaxCardinal,perMinCardinal)){return \\\"个缴最高基数（元）应该大于等于个缴最低基数(元）\\\"}\"); // 企缴比例(%)+个缴比例（%):收费频率为月,月缴个缴计算规则等于按基数比例，缴纳主体等于个人或者全部时必填 ruleList.add(\"if (chargingFrequency==0 && (subject==0 || subject==2) && monthPerCalRule==1 && totalRatio==null){return \\\"企缴比例(%)+个缴比例（%)收费频率为月 月缴个缴计算规则等于缴基数比例，缴纳主体等于个人或者全部时必填\\\"}\"); // 企缴比例(%)+个缴比例（%):收费频率等于季年 季年缴计算规则等于按基数比例,缴纳主体等于个人或者全部时必填 ruleList.add(\"if (chargingFrequency!=0 && (subject==0 || subject==2) && seasonYearBaseCalRule==1 && totalRatio==null){return \\\"企缴比例(%)+个缴比例（%):收费频率等于季年 季年缴计算规则等于按基数比例,缴纳主体等于个人或者全部时必填\\\"}\"); // 企缴比例(%)+个缴比例（%):收费频率为月,月缴企缴计算规则等于按基数比例，缴纳主体等于企业或者全部时必填 ruleList.add(\"if (chargingFrequency==0 && subject in [1,2] && monthEntCalRule==1 && totalRatio==null){return \\\"企缴比例(%)+个缴比例（%):收费频率为月,月缴企缴计算规则等于按基数比例，缴纳主体等于企业或者全部时必填\\\"}\"); // 企缴比例(%)+个缴比例（%):收费频率等于季年 季年缴计算规则等于按基数比例,缴纳主体等于企业或者全部时必填 ruleList.add(\"if (chargingFrequency!=0 &&subject in [1,2] && seasonYearBaseCalRule==1 && totalRatio==null){return \\\"企缴比例(%)+个缴比例（%):收费频率等于季年 季年缴计算规则等于按基数比例,缴纳主体等于企业或者全部时必填\\\"}\"); // 季年缴纳时候、参保类型只能为不区分 ruleList.add(\"if (chargingFrequency!=0 && insuredTypeName!=\\\"不区分\\\"){return \\\"季年缴纳时候、参保类型只能为不区分\\\"}\"); // 月缴纳缴交额总计最低（元）小于 缴交额总计最高（元） ruleList.add(\"if (chargingFrequency==0 && payMinAmount!=null && payMaxAmount!=null && getAggregation3(payMaxAmount,payMinAmount)){return \\\"月缴纳缴交额总计最低（元）小于 缴交额总计最高（元）\\\"}\"); // 期内企缴全额（元） 生效政策包当“季缴年度计算规则=按固定值”“险种缴纳主体包含企业”时必填 ruleList.add(\"if (chargingFrequency!=0 && subject in [1,2] && seasonYearBaseCalRule==0 && seasonEntAmount==null){return \\\"期内企缴全额（元）生效政策包当“季缴年度计算规则=按固定值”“险种缴纳主体包含企业”时必填\\\"}\"); // 1月企缴费用分摊（元）当“季缴年度计算规则=按固定值”“险种缴纳主体包含企业”“中途参保规则=中途参保收剩余月份”时必填 ruleList.add(\"if (chargingFrequency!=0 && subject in [1,2] && seasonYearBaseCalRule==0 && seasonYearMiddleInsuredCalRule==1 && enterpriseJanuaryAmount==null){return \\\"1月企缴费用分摊（元）当“季缴年度计算规则=按固定值”“险种缴纳主体包含企业”“中途参保规则=中途参保收剩余月份”时必填\\\"}\"); // 2月企缴费用分摊（元）当“季缴年度计算规则=按固定值”“险种缴纳主体包含企业”“中途参保规则=中途参保收剩余月份”时必填 ruleList.add(\"if (chargingFrequency!=0 && subject in [1,2] && seasonYearBaseCalRule==0 && seasonYearMiddleInsuredCalRule==1 && enterpriseFebruaryAmount==null){return \\\"2月企缴费用分摊（元）当“季缴年度计算规则=按固定值”“险种缴纳主体包含企业”“中途参保规则=中途参保收剩余月份”时必填\\\"}\"); // 3月企缴费用分摊（元）当“季缴年度计算规则=按固定值”“险种缴纳主体包含企业”“中途参保规则=中途参保收剩余月份”时必填 ruleList.add(\"if (chargingFrequency!=0 && subject in [1,2] && seasonYearBaseCalRule==0 && seasonYearMiddleInsuredCalRule==1 && enterpriseMarchAmount==null){return \\\"3月企缴费用分摊（元）当“季缴年度计算规则=按固定值”“险种缴纳主体包含企业”“中途参保规则=中途参保收剩余月份”时必填\\\"}\"); // 4月企缴费用分摊（元）当“季缴年度计算规则=按固定值”“险种缴纳主体包含企业”“中途参保规则=中途参保收剩余月份”时必填 ruleList.add(\"if (chargingFrequency!=0 && subject in [1,2] && seasonYearBaseCalRule==0 && seasonYearMiddleInsuredCalRule==1 && enterpriseAprilAmount==null){return \\\"4月企缴费用分摊（元）当“季缴年度计算规则=按固定值”“险种缴纳主体包含企业”“中途参保规则=中途参保收剩余月份”时必填\\\"}\"); // 5月企缴费用分摊（元）当“季缴年度计算规则=按固定值”“险种缴纳主体包含企业”“中途参保规则=中途参保收剩余月份”时必填 ruleList.add(\"if (chargingFrequency!=0 && subject in [1,2] && seasonYearBaseCalRule==0 && seasonYearMiddleInsuredCalRule==1 && enterpriseMayAmount==null){return \\\"5月企缴费用分摊（元）当“季缴年度计算规则=按固定值”“险种缴纳主体包含企业”“中途参保规则=中途参保收剩余月份”时必填\\\"}\"); // 6月企缴费用分摊（元）当“季缴年度计算规则=按固定值”“险种缴纳主体包含企业”“中途参保规则=中途参保收剩余月份”时必填 ruleList.add(\"if (chargingFrequency!=0 && subject in [1,2] && seasonYearBaseCalRule==0 && seasonYearMiddleInsuredCalRule==1 && enterpriseJuneAmount==null){return \\\"6月企缴费用分摊（元）当“季缴年度计算规则=按固定值”“险种缴纳主体包含企业”“中途参保规则=中途参保收剩余月份”时必填\\\"}\"); // 7月企缴费用分摊（元）当“季缴年度计算规则=按固定值”“险种缴纳主体包含企业”“中途参保规则=中途参保收剩余月份”时必填 ruleList.add(\"if (chargingFrequency!=0 && subject in [1,2] && seasonYearBaseCalRule==0 && seasonYearMiddleInsuredCalRule==1 && enterpriseJulyAmount==null){return \\\"7月企缴费用分摊（元）当“季缴年度计算规则=按固定值”“险种缴纳主体包含企业”“中途参保规则=中途参保收剩余月份”时必填\\\"}\"); // 8月企缴费用分摊（元）当“季缴年度计算规则=按固定值”“险种缴纳主体包含企业”“中途参保规则=中途参保收剩余月份”时必填 ruleList.add(\"if (chargingFrequency!=0 && subject in [1,2] && seasonYearBaseCalRule==0 && seasonYearMiddleInsuredCalRule==1 && enterpriseAugustAmount==null){return \\\"8月企缴费用分摊（元）当“季缴年度计算规则=按固定值”“险种缴纳主体包含企业”“中途参保规则=中途参保收剩余月份”时必填\\\"}\"); // 9月企缴费用分摊（元）当“季缴年度计算规则=按固定值”“险种缴纳主体包含企业”“中途参保规则=中途参保收剩余月份”时必填 ruleList.add(\"if (chargingFrequency!=0 && subject in [1,2] && seasonYearBaseCalRule==0 && seasonYearMiddleInsuredCalRule==1 && enterpriseSeptemberAmount==null){return \\\"9月企缴费用分摊（元）当“季缴年度计算规则=按固定值”“险种缴纳主体包含企业”“中途参保规则=中途参保收剩余月份”时必填\\\"}\"); // 10月企缴费用分摊（元）当“季缴年度计算规则=按固定值”“险种缴纳主体包含企业”“中途参保规则=中途参保收剩余月份”时必填 ruleList.add(\"if (chargingFrequency!=0 && subject in [1,2] && seasonYearBaseCalRule==0 && seasonYearMiddleInsuredCalRule==1 && enterpriseOctoberAmount==null){return \\\"10月企缴费用分摊（元）当“季缴年度计算规则=按固定值”“险种缴纳主体包含企业”“中途参保规则=中途参保收剩余月份”时必填\\\"}\"); // 11月企缴费用分摊（元）当“季缴年度计算规则=按固定值”“险种缴纳主体包含企业”“中途参保规则=中途参保收剩余月份”时必填 ruleList.add(\"if (chargingFrequency!=0 && subject in [1,2] && seasonYearBaseCalRule==0 && seasonYearMiddleInsuredCalRule==1 && enterpriseNovemberAmount==null){return \\\"11月企缴费用分摊（元）当“季缴年度计算规则=按固定值”“险种缴纳主体包含企业”“中途参保规则=中途参保收剩余月份”时必填\\\"}\"); // 12月企缴费用分摊（元）当“季缴年度计算规则=按固定值”“险种缴纳主体包含企业”“中途参保规则=中途参保收剩余月份”时必填 ruleList.add(\"if (chargingFrequency!=0 && subject in [1,2] && seasonYearBaseCalRule==0 && seasonYearMiddleInsuredCalRule==1 && enterpriseDecemberAmount==null){return \\\"12月企缴费用分摊（元）当“季缴年度计算规则=按固定值”“险种缴纳主体包含企业”“中途参保规则=中途参保收剩余月份”时必填\\\"}\"); // 期内个人全额(元）当“季缴年度计算规则=按固定值”“险种缴纳主体包含个人”时必填 ruleList.add(\"if (chargingFrequency!=0 && (subject==0 || subject==2) && seasonYearBaseCalRule==0 && seasonEntPerAmount==null){return \\\"期内个人全额(元）当“季缴年度计算规则=按固定值”“险种缴纳主体包含个人”时必填\\\"}\"); // 1月个缴费用分摊（元）当“季缴年度计算规则=按固定值”“险种缴纳主体包含个人”“中途参保规则=中途参保收剩余月份”时必填 ruleList.add(\"if (chargingFrequency!=0 && (subject==0 || subject==2) && seasonYearBaseCalRule==0 && seasonYearMiddleInsuredCalRule==1 && personalJanuaryAmount==null){return \\\"1月个缴费用分摊（元）当“季缴年度计算规则=按固定值”“险种缴纳主体包含个人”“中途参保规则=中途参保收剩余月份”时必填\\\"}\"); // 2月个缴费用分摊（元）当“季缴年度计算规则=按固定值”“险种缴纳主体包含个人”“中途参保规则=中途参保收剩余月份”时必填 ruleList.add(\"if (chargingFrequency!=0 && (subject==0 || subject==2) && seasonYearBaseCalRule==0 && seasonYearMiddleInsuredCalRule==1 && personalFebruaryAmount==null){return \\\"2月个缴费用分摊（元）当“季缴年度计算规则=按固定值”“险种缴纳主体包含个人”“中途参保规则=中途参保收剩余月份”时必填\\\"}\"); // 3月个缴费用分摊（元）当“季缴年度计算规则=按固定值”“险种缴纳主体包含个人”“中途参保规则=中途参保收剩余月份”时必填 ruleList.add(\"if (chargingFrequency!=0 && (subject==0 || subject==2) && seasonYearBaseCalRule==0 && seasonYearMiddleInsuredCalRule==1 && personalMarchAmount==null){return \\\"3月个缴费用分摊（元）当“季缴年度计算规则=按固定值”“险种缴纳主体包含个人”“中途参保规则=中途参保收剩余月份”时必填\\\"}\"); // 4月个缴费用分摊（元）当“季缴年度计算规则=按固定值”“险种缴纳主体包含个人”“中途参保规则=中途参保收剩余月份”时必填 ruleList.add(\"if (chargingFrequency!=0 && (subject==0 || subject==2) && seasonYearBaseCalRule==0 && seasonYearMiddleInsuredCalRule==1 && personalAprilAmount==null){return \\\"4月个缴费用分摊（元）当“季缴年度计算规则=按固定值”“险种缴纳主体包含个人”“中途参保规则=中途参保收剩余月份”时必填\\\"}\"); // 5月个缴费用分摊（元）当“季缴年度计算规则=按固定值”“险种缴纳主体包含个人”“中途参保规则=中途参保收剩余月份”时必填 ruleList.add(\"if (chargingFrequency!=0 && (subject==0 || subject==2) && seasonYearBaseCalRule==0 && seasonYearMiddleInsuredCalRule==1 && personalMayAmount==null){return \\\"5月个缴费用分摊（元）当“季缴年度计算规则=按固定值”“险种缴纳主体包含个人”“中途参保规则=中途参保收剩余月份”时必填\\\"}\"); // 6月个缴费用分摊（元）当“季缴年度计算规则=按固定值”“险种缴纳主体包含个人”“中途参保规则=中途参保收剩余月份”时必填 ruleList.add(\"if (chargingFrequency!=0 && (subject==0 || subject==2) && seasonYearBaseCalRule==0 && seasonYearMiddleInsuredCalRule==1 && personalJuneAmount==null){return \\\"6月个缴费用分摊（元）当“季缴年度计算规则=按固定值”“险种缴纳主体包含个人”“中途参保规则=中途参保收剩余月份”时必填\\\"}\"); // 7月个缴费用分摊（元）当“季缴年度计算规则=按固定值”“险种缴纳主体包含个人”“中途参保规则=中途参保收剩余月份”时必填 ruleList.add(\"if (chargingFrequency!=0 && (subject==0 || subject==2) && seasonYearBaseCalRule==0 && seasonYearMiddleInsuredCalRule==1 && personalJulyAmount==null){return \\\"7月个缴费用分摊（元）当“季缴年度计算规则=按固定值”“险种缴纳主体包含个人”“中途参保规则=中途参保收剩余月份”时必填\\\"}\"); // 8月个缴费用分摊（元）当“季缴年度计算规则=按固定值”“险种缴纳主体包含个人”“中途参保规则=中途参保收剩余月份”时必填 ruleList.add(\"if (chargingFrequency!=0 && (subject==0 || subject==2) && seasonYearBaseCalRule==0 && seasonYearMiddleInsuredCalRule==1 && personalAugustAmount==null){return \\\"8月个缴费用分摊（元）当“季缴年度计算规则=按固定值”“险种缴纳主体包含个人”“中途参保规则=中途参保收剩余月份”时必填\\\"}\"); // 9月个缴费用分摊（元）当“季缴年度计算规则=按固定值”“险种缴纳主体包含个人”“中途参保规则=中途参保收剩余月份”时必填 ruleList.add(\"if (chargingFrequency!=0 && (subject==0 || subject==2) && seasonYearBaseCalRule==0 && seasonYearMiddleInsuredCalRule==1 && personalSeptemberAmount==null){return \\\"9月个缴费用分摊（元）当“季缴年度计算规则=按固定值”“险种缴纳主体包含个人”“中途参保规则=中途参保收剩余月份”时必填\\\"}\"); // 10月个缴费用分摊（元）当“季缴年度计算规则=按固定值”“险种缴纳主体包含个人”“中途参保规则=中途参保收剩余月份”时必填 ruleList.add(\"if (chargingFrequency!=0 && (subject==0 || subject==2) && seasonYearBaseCalRule==0 && seasonYearMiddleInsuredCalRule==1 && personalOctoberAmount==null){return \\\"10月个缴费用分摊（元）当“季缴年度计算规则=按固定值”“险种缴纳主体包含个人”“中途参保规则=中途参保收剩余月份”时必填\\\"}\"); // 11月个缴费用分摊（元）当“季缴年度计算规则=按固定值”“险种缴纳主体包含个人”“中途参保规则=中途参保收剩余月份”时必填 ruleList.add(\"if (chargingFrequency!=0 && (subject==0 || subject==2) && seasonYearBaseCalRule==0 && seasonYearMiddleInsuredCalRule==1 && personalNovemberAmount==null){return \\\"11月个缴费用分摊（元）当“季缴年度计算规则=按固定值”“险种缴纳主体包含个人”“中途参保规则=中途参保收剩余月份”时必填\\\"}\"); // 12月个缴费用分摊（元）当“季缴年度计算规则=按固定值”“险种缴纳主体包含个人”“中途参保规则=中途参保收剩余月份”时必填 ruleList.add(\"if (chargingFrequency!=0 && (subject==0 || subject==2) && seasonYearBaseCalRule==0 && seasonYearMiddleInsuredCalRule==1 && personalDecemberAmount==null){return \\\"12月个缴费用分摊（元）当“季缴年度计算规则=按固定值”“险种缴纳主体包含个人”“中途参保规则=中途参保收剩余月份”时必填\\\"}\"); // 追溯对象：是否追溯等于是时必填，值为企业和个人，多个时以英文逗号隔开 whetherRetroactive 是否追溯 0-否 1-是 ruleList.add(\"if (whetherRetroactive==1 && isPerTrace==null){return \\\"追溯对象:是否追溯等于是时必填，值为企业和个人，多个时以英文逗号隔开\\\"}\"); // 追溯方式：是否追溯=是时必填，值为；指定月份在职的员工缴纳月份补收、指定月份在职 的员工追溯月全部补收、追溯期内有缴纳员工的缴纳月份补收、追溯期内有缴纳的员工追溯月全部补收 ruleList.add(\"if (whetherRetroactive==1 && socTraceTypeMethod==null){return \\\"追溯方式:是否追溯等于是时必填\\\"}\"); // 在职指定月份：追溯方式=指定月份在职的员工缴纳月份补收或指定月份在职 的员工追溯月全部补收时必填，格式为202103 ruleList.add(\"if (whetherRetroactive==1 && socTraceType in [1,2] && appointedMonth==null){return \\\"追溯方式等于指定月份在职的员工缴纳月份补收或指定月份在职 的员工追溯月全部补收时必填\\\"}\"); // 追溯方式有值 追溯对象为空异常 ruleList.add(\"if (isPerTrace==null && socTraceTypeMethod!=null){return \\\"追溯对象为空的情况下、追溯方式不能有值\\\"}\"); // 缴纳主体个缴,企缴固定金额导入应该为空 ruleList.add(\"if (subject==0 && entAmount != null){return \\\"当前缴纳主体为个缴,企缴固定金额导入应该为空\\\"}\"); // 缴纳主体个缴,企业最低基数导入应该为空 ruleList.add(\"if (subject==0 && entMinCardinal != null){return \\\"当前缴纳主体为个缴,企业最低基数导入应该为空\\\"}\"); // 缴纳主体个缴,企业最高基数导入应该为空 ruleList.add(\"if (subject==0 && entMaxCardinal != null){return \\\"当前缴纳主体为个缴,企业最高基数导入应该为空\\\"}\"); // 缴纳主体个缴,期内企缴全额（元）导入应该为空 ruleList.add(\"if (subject==0 && seasonEntAmount != null){return \\\"当前缴纳主体为个缴,期内企缴全额（元）导入应该为空\\\"}\"); // 缴纳主体个缴,1月企缴费用分摊（元）导入应该为空 ruleList.add(\"if (subject==0 && enterpriseJanuaryAmount != null){return \\\"当前缴纳主体为个缴,1月企缴费用分摊（元）导入应该为空\\\"}\"); // 缴纳主体个缴,2月企缴费用分摊（元）导入应该为空 ruleList.add(\"if (subject==0 && enterpriseFebruaryAmount != null){return \\\"当前缴纳主体为个缴,2月企缴费用分摊（元）导入应该为空\\\"}\"); // 缴纳主体个缴,3月企缴费用分摊（元）导入应该为空 ruleList.add(\"if (subject==0 && enterpriseMarchAmount != null){return \\\"当前缴纳主体为个缴,3月企缴费用分摊（元）导入应该为空\\\"}\"); // 缴纳主体个缴,4月企缴费用分摊（元）导入应该为空 ruleList.add(\"if (subject==0 && enterpriseAprilAmount != null){return \\\"当前缴纳主体为个缴,4月企缴费用分摊（元）导入应该为空\\\"}\"); // 缴纳主体个缴,5月企缴费用分摊（元）导入应该为空 ruleList.add(\"if (subject==0 && enterpriseMayAmount != null){return \\\"当前缴纳主体为个缴,5月企缴费用分摊（元）导入应该为空\\\"}\"); // 缴纳主体个缴,6月企缴费用分摊（元）导入应该为空 ruleList.add(\"if (subject==0 && enterpriseJuneAmount != null){return \\\"当前缴纳主体为个缴,6月企缴费用分摊（元）导入应该为空\\\"}\"); // 缴纳主体个缴,7月企缴费用分摊（元）导入应该为空 ruleList.add(\"if (subject==0 && enterpriseJulyAmount != null){return \\\"当前缴纳主体为个缴,7月企缴费用分摊（元）导入应该为空\\\"}\"); // 缴纳主体个缴,8月企缴费用分摊（元）导入应该为空 ruleList.add(\"if (subject==0 && enterpriseAugustAmount != null){return \\\"当前缴纳主体为个缴,8月企缴费用分摊（元）导入应该为空\\\"}\"); // 缴纳主体个缴,9月企缴费用分摊（元）导入应该为空 ruleList.add(\"if (subject==0 && enterpriseSeptemberAmount != null){return \\\"当前缴纳主体为个缴,9月企缴费用分摊（元）导入应该为空\\\"}\"); // 缴纳主体个缴,10月企缴费用分摊（元）导入应该为空 ruleList.add(\"if (subject==0 && enterpriseOctoberAmount != null){return \\\"当前缴纳主体为个缴,10月企缴费用分摊（元）导入应该为空\\\"}\"); // 缴纳主体个缴,11月企缴费用分摊（元）导入应该为空 ruleList.add(\"if (subject==0 && enterpriseNovemberAmount != null){return \\\"当前缴纳主体为个缴,11月企缴费用分摊（元）导入应该为空\\\"}\"); // 缴纳主体个缴,12月企缴费用分摊（元）导入应该为空 ruleList.add(\"if (subject==0 && enterpriseDecemberAmount != null){return \\\"当前缴纳主体为个缴,12月企缴费用分摊（元）导入应该为空\\\"}\"); // 当前缴纳主体为企缴，导入的个缴固定金额应该为空 ruleList.add(\"if (subject==1 && perAmount != null){return \\\"当前缴纳主体为企缴，导入的个缴固定金额应该为空\\\"}\"); // 当前缴纳主体为企缴，导入的个人最低基数应该为空 ruleList.add(\"if (subject==1 && perMinCardinal != null){return \\\"当前缴纳主体为企缴，导入的个人最低基数应该为空\\\"}\"); // 当前缴纳主体为企缴，导入的个人最高基数应该为空 ruleList.add(\"if (subject==1 && perMaxCardinal != null){return \\\"当前缴纳主体为企缴，导入的个人最高基数应该为空\\\"}\"); // 当前缴纳主体为企缴，导入的期内个人全额（元）应该为空 ruleList.add(\"if (subject==1 && seasonEntPerAmount != null){return \\\"当前缴纳主体为企缴，导入的期内个人全额（元）应该为空\\\"}\"); // 当前缴纳主体为企缴，导入的1月个缴费用分摊（元）应该为空 ruleList.add(\"if (subject==1 && personalJanuaryAmount != null){return \\\"当前缴纳主体为企缴，导入的1月个缴费用分摊（元）应该为空\\\"}\"); // 当前缴纳主体为企缴，导入的2月个缴费用分摊（元）应该为空 ruleList.add(\"if (subject==1 && personalFebruaryAmount != null){return \\\"当前缴纳主体为企缴，导入的2月个缴费用分摊（元）应该为空\\\"}\"); // 当前缴纳主体为企缴，导入的3月个缴费用分摊（元）应该为空 ruleList.add(\"if (subject==1 && personalMarchAmount != null){return \\\"当前缴纳主体为企缴，导入的3月个缴费用分摊（元）应该为空\\\"}\"); // 当前缴纳主体为企缴，导入的4月个缴费用分摊（元）应该为空 ruleList.add(\"if (subject==1 && personalAprilAmount != null){return \\\"当前缴纳主体为企缴，导入的4月个缴费用分摊（元）应该为空\\\"}\"); // 当前缴纳主体为企缴，导入的5月个缴费用分摊（元）应该为空 ruleList.add(\"if (subject==1 && personalMayAmount != null){return \\\"当前缴纳主体为企缴，导入的5月个缴费用分摊（元）应该为空\\\"}\"); // 当前缴纳主体为企缴，导入的6月个缴费用分摊（元）应该为空 ruleList.add(\"if (subject==1 && personalJuneAmount != null){return \\\"当前缴纳主体为企缴，导入的6月个缴费用分摊（元）应该为空\\\"}\"); // 当前缴纳主体为企缴，导入的7月个缴费用分摊（元）应该为空 ruleList.add(\"if (subject==1 && personalJulyAmount != null){return \\\"当前缴纳主体为企缴，导入的7月个缴费用分摊（元）应该为空\\\"}\"); // 当前缴纳主体为企缴，导入的8月个缴费用分摊（元）应该为空 ruleList.add(\"if (subject==1 && personalAugustAmount != null){return \\\"当前缴纳主体为企缴，导入的8月个缴费用分摊（元）应该为空\\\"}\"); // 当前缴纳主体为企缴，导入的9月个缴费用分摊（元）应该为空 ruleList.add(\"if (subject==1 && personalSeptemberAmount != null){return \\\"当前缴纳主体为企缴，导入的9月个缴费用分摊（元）应该为空\\\"}\"); // 当前缴纳主体为企缴，导入的10月个缴费用分摊（元）应该为空 ruleList.add(\"if (subject==1 && personalOctoberAmount != null){return \\\"当前缴纳主体为企缴，导入的10月个缴费用分摊（元）应该为空\\\"}\"); // 当前缴纳主体为企缴，导入的11月个缴费用分摊（元）应该为空 ruleList.add(\"if (subject==1 && personalNovemberAmount != null){return \\\"当前缴纳主体为企缴，导入的11月个缴费用分摊（元）应该为空\\\"}\"); // 当前缴纳主体为企缴，导入的12月个缴费用分摊（元）应该为空 ruleList.add(\"if (subject==1 && personalDecemberAmount != null){return \\\"当前缴纳主体为企缴，导入的12月个缴费用分摊（元）应该为空\\\"}\"); return ruleList; } } 规则验证 package com.joyowo.smarthr.social.common.excel; import com.joyowo.smarthr.core.utils.StringUtil; import com.joyowo.smarthr.social.common.util.SocMonthCalculateUtil; import com.ql.util.express.DefaultContext; import com.ql.util.express.ExpressRunner; import lombok.Getter; import lombok.extern.slf4j.Slf4j; import org.springframework.util.StringUtils; import java.math.BigDecimal; import java.time.LocalDate; import java.util.*; @Slf4j @Getter public class SocPolicyChangeApplyCheck { private final Map dataCheckMap = new HashMap<>(); private final DefaultContext ctx = new DefaultContext<>(); private String errMsg; String getErrMsg() { return errMsg; } SocPolicyChangeApplyCheck addCtxValue(String key, Object value) { ctx.put(key, value); return this; } /** * 先单字段校验，如果不通过，则结束；否则执行多字段校验 */ void exec() { //多字段 if (StringUtils.isEmpty(errMsg)) { //多字段聚合判断 try { multiFieldAggregationVerification(); } catch (Exception e) { log.error(\"ql express error\", e); } } } /** * 规则条件匹配. * * @throws Exception the error */ private void multiFieldAggregationVerification() throws Exception { ExpressRunner expressRunner = new ExpressRunner(); // *开始执行年月 必填，默认险种当前权益月（根据当前有效版本中，险种的增员规则计算） 最多可往前选择12个月 expressRunner.addFunctionOfClassMethod(\"getAggregation1\", SocPolicyChangeApplyCheck.class.getName(), \"equityMonthJudgment\", new String[]{\"String\", \"String\"}, null); expressRunner.addFunctionOfClassMethod(\"getAggregation2\", SocPolicyChangeApplyCheck.class.getName(), \"stopExecutionYearAndMonth\", new String[]{\"String\", \"String\"}, null); expressRunner.addFunctionOfClassMethod(\"getAggregation3\", SocPolicyChangeApplyCheck.class.getName(), \"comparison\", new String[]{\"String\", \"String\"}, null); expressRunner.addFunctionOfClassMethod(\"getAggregation4\", SocPolicyChangeApplyCheck.class.getName(), \"traceableObject\", new String[]{\"Integer\", \"Integer\", \"Integer\"}, null); // 单例模式获取匹配规则. List aggregationList = SocPolicyChangeApplySingleton.getSingleton(); for (String aggregation : aggregationList) { Object execute = null; try { execute = expressRunner.execute(aggregation, ctx, null, true, false); log.debug(\"执行QlExpress: {} 执行结果：{}\", aggregation, execute); } catch (Exception e) { e.printStackTrace(); log.error(\"SocPolicyChangeApplyCheck判断规则出错={}\", e.getMessage()); } if (!StringUtils.isEmpty(execute)) { errMsg = execute.toString(); return; } } expressRunner.clearExpressCache(); } /** * 开始执行年月不能超过12这个月 * * @param startYearMonthRightsAndInterests 开始执行年月 * @return the boolean startYearMonthRightsAndInterests */ public static Boolean equityMonthJudgment(String startYearMonthRightsAndInterests, String startYearMonth) { // 得到开始执行年月转换值. LocalDate startYearMonthLocalDate = SocMonthCalculateUtil.parseStr(startYearMonth); LocalDate startYearMonthLocal = SocMonthCalculateUtil.parseStr(startYearMonthRightsAndInterests); LocalDate minDate = startYearMonthLocal.plusMonths(-12); if (minDate.compareTo(startYearMonthLocalDate) > 0) { return Boolean.TRUE; } return Boolean.FALSE; } /** * 停止执行年月 需晚于等于执行开始时间 * * @param endYearMonth 停止执行年月. * @return the boolean */ public static Boolean stopExecutionYearAndMonth(String startYearMonth, String endYearMonth) { if (StringUtil.isNotBlankTrim(startYearMonth) && StringUtil.isNotBlankTrim(endYearMonth)) { LocalDate startYearMonthLocalDate = SocMonthCalculateUtil.parseStr(startYearMonth); LocalDate endYearMonthLocalDate = SocMonthCalculateUtil.parseStr(endYearMonth); if (startYearMonthLocalDate.compareTo(endYearMonthLocalDate) > 0) { return Boolean.TRUE; } } return Boolean.FALSE; } /** * 比较两个值的大小 * * @param maxMoney money * @param minMoney money * @return the boolean */ public static boolean comparison(String maxMoney, String minMoney) { if (!StringUtils.isEmpty(maxMoney) && !StringUtils.isEmpty(minMoney)) { if (new BigDecimal(minMoney).compareTo(new BigDecimal(maxMoney)) > 0) { return Boolean.TRUE; } } return Boolean.FALSE; } public static boolean traceableObject(Integer whetherRetroactive, Integer perTrace, Integer subject) { if (perTrace != null) { if (perTrace == 1) { perTrace = 0; } else if (perTrace == 0) { perTrace = 1; } } if (subject == 2) { return Boolean.FALSE; } if (whetherRetroactive == 1 && !perTrace.equals(subject)) { return Boolean.TRUE; } return Boolean.FALSE; } } "},"chapter1/section2.html":{"url":"chapter1/section2.html","title":"1.2 Elastic APM 应用性能监控分析及使用","keywords":"","body":"Elastic APM 应用性能监控分析及使用 [!note] 简介: 目前麒麟系统初步完成功能上的建设，进入到推广阶段，随着推广的逐步深入，对接口性能的优化级必须提高。通过对比已有的SkyWalking与Elastic APM之后，发现Elastic APM更胜一筹。 Elastic APM，用于实时监控软件服务和应用程序的各项性能指标，如：请求访问的各项指标、访问耗时、数据库查询、缓存调用、外部 HTTP 请求等。便于测试后端人员快速排查和修复各种性能问题. 目前已经进行汉化处理 参考链接: 1、https://help.aliyun.com/document_detail/326329.html 2、https://cloud.tencent.com/developer/article/1543781 Elastic APM 背景信息 优势 1、了解服务的时间花在什么上，以及它崩溃的原因。 2、了解服务如何相互交互，以及它的可视化瓶颈。 3、主动发现并修复性能瓶颈和错误。 4、度量指标（比如Java JVM和Go Runtime的指标） 5、在浏览器中跟踪终端用户链路。 对比SkyWalking与Elastic APM 对比项 Elastic APM SkyWalking 支持的语言 Java Java . NET . NET Core NodeJS NodeJS Python PHP Ruby Go Javascript Go 是否支持tracing 是 否 支持的存储 Elasticsearch ElasticSearch、H2和MySQL UI丰富度 高。相比SkyWalking，Elastic APM能够在UI中进行复杂的查询和过滤。 高。相比Elastic APM，SkyWalking能够提供服务间的拓扑图。 Agent易用性（代码侵入性） Java、. NET Core和NodeJS部分开源库无需侵入代码自动装配（instrument）。 Java、. NET Core和NodeJS部分开源库无需侵入代码自动装配，不支持的无法使用。 Python、Ruby、Javascript和Go部分开源库提供SDK手动装配。 Go和PHP提供SDK手动装配。 对于不支持的库或框架，也能通过Public API采集Agent数据。 查询能力 能在Kibana APM UI中，查询或过滤任意APM信息。 仅支持查询TraceId和Endpoint name。 告警 支持 支持 JVM监控 支持 支持 Go Runtime监控 支持 不支持 收集错误和异常 支持 不支持 全面可观测性 支持。Elastic Stack已经提供了日志及指标监控的完备解决方案，再结合APM，您可以搭建全面的可观测性系统。 不支持 APM相关组件 [!note] 应用程序性能管理（Application Performance Managemen）简称 APM。 Elastic APM 由4个组件组成：APM 代理、APM 服务端、Elasticsearch 和 Kibana。 APM Agent : 以应用程序库的形式提供，负责收集应用运行时的性能监控数据和错误数据，短时间缓存后发送APM Server。 APM Server : 一个独立的组件，负责接收APM Agent中发送的性能监控数据。验证并处理完数据后，会转存储到Elasticsearch中，之后就可以在Kibana APM 应用中查看性能监控数据了。 Elasticsearch : 用于存储应用性能监控数据并提供聚合功能。 Kibana APM app : 可视化查看APM性能监控数据，有助于找到性能瓶颈。 架构及数据模型 [!note] APM Agent采集器从其监测的应用程序中收集不同类型的信息和数据，这些被称为事件。事件支持的类型包括Spans、Transaction、Errors和Metrics。 Elastic APM事件 Span（跨度）：Span包含一次操作过程中代码执行路径的信息。它从操作的开始到结束进行度量，并且可以与其他Span具有父/子关系。 Transaction（事务）：Transaction是一种特殊的Span，具有与之关联的其他属性。它描述了Elastic APM Agent捕获的最高级别事件，比如一次请求、一次批处理任务等。 Error（错误）：Error事件至少包含错误发生的原始异常或创建的日志的信息。 Metric（度量）：APM Agent 自动获取基本的主机级别指标，包括系统和进程级别的CPU和内存指标。也可以获取特定于代理的指标，例如Java Agent中的JVM指标和Go Agent中的Go运行时指标。 使用实践 安装步骤 // todo 查看APM中包含的所有服务 多次调用应用接口，即可查看到应用性能信息 以kylin-pre-social事务服务为例，服务信息如下图（每项服务都具有类似的布局） 打开某个事物（Transaction）查看详情，可以看到连SQL执行耗时信息 打开执行查询的Span查看详情，SQL语句也已经收集 查询依赖调用的的微服务链路 如下依赖了kylin-pre-crmproject、kylin-pre-supplier、kylin-pre-entry服务 社保SocStaffIncreaseRecordController#submitIncreaseRecord调用链路图 点击依赖的kylin-pre-crmproject详情 点击依赖的kylin-pre-suppliert详情 服务异常跟踪 [!note] 点击错误tab进行切换，可以看到目前社保（social）目前收集到的错误系信息的统计 点击查看对应的异常堆栈追溯信息 点击元数据可以通过http.response.headers. Insignia:p_927938471752896512查看整个链路的日志标识 主机的度量信息，CPU、内存、JVM信息都有，以后性能调优的时候可以看看 总结 Elastic APM 完全可以取代SkyWalking来做分布式请求链路追踪，并且提供了数据库及缓存调用时长的统计，还可以用来实时监控应用性能信息及度量指标，连错误日志也收集。相比下Elastic APM更加性能监控更为强大. Elastic APM 应用性能监控分析及使用 [!note] 目前麒麟系统初步完成功能上的建设，进入到推广阶段，对接口性能的优化需要提高。对比已有的SkyWalking与Elastic APM之后，Elastic APM更胜一筹。目前pre环境已经搭建好了Elastic APM，大家可以先熟悉下，后续生产环境上的SkyWalking将会下掉，用Elastic APM进行替代。 Elastic APM 功能 1、了解服务的时间花在什么上，以及它崩溃的原因。 2、了解服务如何相互交互，以及它的可视化瓶颈。 3、主动发现并修复性能瓶颈和错误。 4、度量指标（比如Java JVM和Go Runtime的指标） 5、在浏览器中跟踪终端用户链路。 语雀地址: https://joyowo.yuque.com/techs/regulations/xtdqrf "},"chapter1/section3.html":{"url":"chapter1/section3.html","title":"1.3 Nacos注册中心、配置中心","keywords":"","body":"nacos注册中心、配置中心架构 Nacos概述 服务注册、发现Nacos Discovery 摘抄自官方文档说明 [!note] https://github.com/alibaba/spring-cloud-alibaba/blob/master/spring-cloud-alibaba-docs/src/main/asciidoc-zh/nacos-discovery.adoc#%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C%E5%8F%91%E7%8E%B0-nacos-discovery 服务发现是微服务架构体系中最关键的组件之一。如果尝试着用手动的方式来给每一个客户端来配置所有服务提供者的服务列表是一件非常困难的事，而且也不利于服务的动态扩缩容。 Nacos Discovery可以帮助您将服务自动注册到Nacos服务端并且能够动态感知和刷新某个服务实例的服务列表。 除此之外，Nacos Discovery 也将服务实例自身的一些元数据信息-例如hostport, 健康检查URL主页等内容注册到 Nacos。 注册中心原理 注册中心的三种角色 [!note] 服务提供者（Service Provider）、服务消费者（Service Consumer）、注册中心（Registry） 服务提供者 1、启动时，向注册中心注册自己为一个服务（Service）的实例。 2、定期向注册中心发送心跳，告诉自己还存活。 3、关闭时，向注册中心取消注册。 服务消费者 1、启动时，向注册中心订阅使用到的服务，并缓存服务的实例列表在内存中。 2、后续，服务消费者向对应服务的提供者发起调用时，从内存中的选择一个该服务的实例，进行远程调用。 3、关闭时，向注册中心取消订阅。 注册中心 1、服务提供者超过一定时间未心跳时，从服务的实例列表移除。 2、服务的实例列表发生变化（新增或者移除）时，通知订阅该服务的消费者，从而让消费者能够刷新本地缓存 Nacos安装部署 依赖环境 1、64 bit OS，支持 Linux/Unix/Mac/Windows，推荐选用 Linux/Unix/Mac 2、64 bit JDK 1.8+ 3、Maven 3.2.x+ 从 Github 上下载源码方式 ➜ webApp git clone https://github.com/alibaba/nacos.git 正克隆到 'nacos'... remote: Enumerating objects: 87393, done. remote: Counting objects: 100% (159/159), done. remote: Compressing objects: 100% (94/94), done. remote: Total 87393 (delta 34), reused 47 (delta 6), pack-reused 87234 接收对象中: 100% (87393/87393), 42.07 MiB | 1.65 MiB/s, 完成. 处理 delta 中: 100% (37309/37309), 完成. /opt/webApp/nacos-2.0.4/distribution/target/nacos-server.jar 编译 mvn -Prelease-nacos -Dmaven.test.skip=true clean install -U 运行 #进入nacos/distribution目录下，找到对应版本的编译后的文件夹= mvn -Prelease-nacos -Dmaven.test.skip=true clean install -U #Linux/Unix/Mac /opt/webApp/nacos-2.0.4/distribution/target/nacos-server-2.1.0-SNAPSHOT/nacos/bin sh startup.sh -m standalone 访问 http://127.0.0.1:8848/nacos Nacos 架构概念 引用 https://nacos.io/zh-cn/docs/architecture.html 数据模型 Nacos 数据模型 Key 由三元组唯一确定, Namespace默认是空串，公共命名空间（public），分组默认是 DEFAULT_GROUP。 1、注册中心 Namespace + Group + Service 2、配置中心 Namespace + Group + DataId Namespace 命名空间 用于进行租户粒度的配置隔离。默认为 public（公共命名空间）。不同环境的配置的区分隔离 Group服务分组 不同的服务可以归类到同一分组。默认为 DEFAULT_GROUP（默认分组） Service 服务 例如: 订单服务、库存服务 整合代码 代码地址 [!note] https://github.com/BenjaminFyang/frameService-platform.git 项目结构 . ├── HELP.md ├── SpringCloud-Service.iml ├── eureka-services │ ├── accountService │ ├── eureka-services.iml │ ├── orderService │ ├── pom.xml │ └── storageService ├── nacos-services │ ├── nacos-discovery-account-provider (服务提供者) │ ├── nacos-discovery-order-consumer （服务消费者） │ ├── nacos-service.iml │ └── pom.xml ├── pom.xml ├── traceId-commons │ ├── feignOkHttp │ ├── pom.xml │ ├── traceId-common-core │ ├── traceId-commons.iml │ ├── traceId-log-springcloud-starter │ └── traceId-rocketmq-starter ├── traceId-eureka ├── traceId-gateway └── traceId-loadbalancer 搭建服务提供者 依赖版本关系梳理 首先梳理下 Spring Boot、Spring Cloud、Spring Cloud Alibaba 三者 BOM 文件，进行依赖版本的管理，防止不兼容 引用自 https://github.com/alibaba/spring-cloud-alibaba/wiki/%E7%89%88%E6%9C%AC%E8%AF%B4%E6%98%8E 依赖版本关系如下 Spring Cloud Alibaba Version Spring Cloud Version Spring Boot Version 2.2.7. RELEASE Spring Cloud Hoxton. SR12 2.3.12. RELEASE 2021.1 Spring Cloud 2020.0.1 2.4.2 2.2.6. RELEASE Spring Cloud Hoxton. SR9 2.3.2. RELEASE 2.1.4. RELEASE Spring Cloud Greenwich. SR6 2.1.13. RELEASE 2.2.1. RELEASE Spring Cloud Hoxton. SR3 2.2.5. RELEASE 2.2.0. RELEASE Spring Cloud Hoxton. RELEASE 2.2. X. RELEASE 2.1.2. RELEASE Spring Cloud Greenwich 2.1. X. RELEASE 2.0.4. RELEASE(停止维护，建议升级) Spring Cloud Finchley 2.0. X. RELEASE 1.5.1. RELEASE(停止维护，建议升级) Spring Cloud Edgware 1.5. X. RELEASE 引入pom依赖 4.0.0 com.example nacos-service 0.0.1-SNAPSHOT nacos-discovery-account-provider 2.0.1 nacos-discovery-account-provider 账号信息 org.springframework.boot spring-boot-starter-web com.alibaba.cloud spring-cloud-starter-alibaba-nacos-discovery org.springframework.cloud spring-cloud-starter-openfeign io.github.openfeign feign-httpclient org.projectlombok lombok com.example traceId-common-core 2.0.1 com.example traceId-log-springCloud-starter 2.0.1 配置文件 创建application.yml 配置文件，添加 Nacos Discovery配置项 spring: application: name: nacos-account-service # Spring 应用名 cloud: nacos: # Nacos 作为注册中心的配置项，对应 NacosDiscoveryProperties 配置类 discovery: server-addr: 127.0.0.1:8848 # Nacos 服务器地址 service: ${spring.application.name} # 注册到 Nacos 的服务名。默认值为 ${spring.application.name}。 server: port: 8182 #服务器端口。默认为 8080 启动类 @EnableDiscoveryClient 注解，开启 Spring Cloud 的注册发现功能。不过从 Spring Cloud Edgware 版本开始，实际上已经不需要添加 @EnableDiscoveryClient 注解，只需要引入 Spring Cloud 注册发现组件，就会自动开启注册发现的功能 package com.example.nacos.account; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.client.discovery.EnableDiscoveryClient; @SpringBootApplication @EnableDiscoveryClient public class DiscoveryAccountProviderApplication { public static void main(String[] args) { SpringApplication.run(DiscoveryAccountProviderApplication.class, args); } } 启动项目 1、启动项目类DiscoveryAccountProviderApplication，发现日志打印c.a.c.n.registry. NacosServiceRegistry 说明注册成功. [nacos-account-service:192.168.130.167:8182] 2022-01-06 10:37:26.990 INFO 31879 [] [main] c.a.c.n.registry.NacosServiceRegistry nacos registry, DEFAULT_GROUP nacos-account-service 192.168.130.167:8182 register finished [nacos-account-service:192.168.130.167:8182] 2022-01-06 10:37:27.014 INFO 31879 [] [main] .n.a.DiscoveryAccountProviderApplication Started DiscoveryAccountProviderApplication in 5.673 seconds (JVM running for 7.337) [nacos-account-service:192.168.130.167:8182] 2022-01-06 10:37:27.165 INFO 31879 [] [RMI TCP Connection(4)-127.0.0.1] o.a.c.c.C.[Tomcat].[localhost].[/] Initializing Spring DispatcherServlet 'dispatcherServlet' [nacos-account-service:192.168.130.167:8182] 2022-01-06 10:37:27.165 INFO 31879 [] [RMI TCP Connection(4)-127.0.0.1] o.s.web.servlet.DispatcherServlet Initializing Servlet 'dispatcherServlet' [nacos-account-service:192.168.130.167:8182] 2022-01-06 10:37:27.168 INFO 31879 [] [RMI TCP Connection(4)-127.0.0.1] o.s.web.servlet.DispatcherServlet Completed initialization in 3 ms 2、打开 Nacos 控制台，可以在服务列表看到服务nacos-account-service 搭建服务消费者 [!note] 参考搭建服务提供者、目前代码demo已经提供参考，故不在多做叙说 消费者配置文件 spring: application: name: nacos-order-service # Spring 应用名 cloud: nacos: # Nacos 作为注册中心的配置项，对应 NacosDiscoveryProperties 配置类 discovery: server-addr: 127.0.0.1:8848 # Nacos 服务器地址 server: port: 8183 # 服务器端口。默认为 8080 打开nacos控制台、可以看到对应的服务列表nacos-account-service 测试开始调用对应的依赖服务 Java实现例子 package com.example.nacos.order.service.impl; import com.example.nacos.order.domain.Order; import com.example.nacos.order.service.AccountService; import com.example.nacos.order.service.OrderService; import com.google.common.collect.Lists; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.stereotype.Service; import javax.annotation.Resource; import java.util.List; /** * 订单业务实现类 */ @Service public class OrderServiceImpl implements OrderService { private static final Logger LOGGER = LoggerFactory.getLogger(OrderServiceImpl.class); @Resource private AccountService accountService; /** * 创建订单->调用库存服务扣减库存->调用账户服务扣减账户余额->修改订单状态 */ public void create(Order order) { LOGGER.info(\"------->order-service中扣减余额开始\"); accountService.decrease(); LOGGER.info(\"------->order-service中扣减余额结束\"); } } package com.example.nacos.order.service; import com.central.common.api.CommonResult; import org.springframework.cloud.openfeign.FeignClient; import org.springframework.web.bind.annotation.RequestMapping; @FeignClient(value = \"nacos-account-service\") public interface AccountService { /** * 扣减账户余额 */ @RequestMapping(\"/account/decrease\") CommonResult decrease(); } 调用订单参数 curl --location --request POST 'http://localhost:8183/order/create' \\ --header 'Content-Type: application/json' \\ --data-raw '{ \"id\": 0, \"userId\": 0, \"productId\": 0, \"count\": 0, \"money\": 0, \"status\": 0 }' 返回 { \"code\": 200, \"message\": \"操作成功\", \"data\": \"订单创建成功!\" } 微服务用例多环境配置 针对同一个服务，会部署在开发、测试、预发布、生产环境中，在需要的项目中，添加不同环境的nacos配置。一般情况下，开发和测试使用同一个 Nacos，预发布和生产使用另一个 Nacos。那么针对相同的 Nacos，怎么实现不同环境的隔离 创建nacos命名空间 配置文件修改 修改application.yaml 将 Nacos Discovery 配置项删除，稍后添加在不同环境的配置文件中 spring: application: name: nacos-account-service # Spring 应用名 server: port: 8182 #服务器端口。默认为 8080 新增开发环境application-dev.yaml 配置 spring: cloud: nacos: # Nacos 作为注册中心的配置项，对应 NacosDiscoveryProperties 配置类 discovery: server-addr: 127.0.0.1:8848 # Nacos 服务器地址 namespace: 2c2e6be6-b514-47da-b216-c800b4292aa7 # Nacos 命名空间 dev 的编号 新增生产环境application-prod.yaml 配置 spring: cloud: nacos: # Nacos 作为注册中心的配置项，对应 NacosDiscoveryProperties 配置类 discovery: server-addr: 127.0.0.1:8848 # Nacos 服务器地址 namespace: 2c2e6be6-b514-47da-b216-c800b4292aa7 # Nacos 命名空间 prod 的编号 分环境进行测试 增加命令参数--spring.profiles.active配置项，实现不同环境，读取不同配置文件。 1、配置 --spring.profiles.active 为 dev 如下 2、启动项目, 打开Nacos控制台在服务列表dev下面看到微服务 nacos配置中心 新建项目nacos-coinfig pom 文件新增依赖 com.alibaba.cloud spring-cloud-starter-alibaba-nacos-config 配置文件设置 需要注意bootstrap.yaml 而不是application.yaml不然无法从配置中心加载配置文件 application 配置文件这个容易理解，主要用于 Spring Boot 项目的自动化配置。 bootstrap 配置文件有以下几个应用场景。 1、使用 Spring Cloud Config 配置中心时，这时需要在 bootstrap 配置文件中添加连接到配置中心的配置属性来加载外部配置中心的配置信息； 2、一些固定的不能被覆盖的属性 3、一些加密/解密的场景； spring: application: name: nacos-config-service # Spring 应用名 cloud: nacos: # Nacos Config 配置项，对应 NacosConfigProperties 配置属性类 config: server-addr: 127.0.0.1:8848 # Nacos 服务器地址 namespace: # 使用的 Nacos 的命名空间，默认为 null group: DEFAULT_GROUP # 使用的 Nacos 配置分组，默认为 DEFAULT_GROUP name: # 使用的 Nacos 配置集的 dataId，默认为 spring.application.name file-extension: yaml # 使用的 Nacos 配置集的 dataId 的文件拓展名，同时也是 Nacos 配置集的配置格式，默认为 properties server: port: 8195 # 服务器端口。默认为 8080 创建Nacos配置 1、打开Nacos UI界面 2、新建配置 3、创建OrderProperties配置类 package com.example.nacosConfig.configProperties; import lombok.Data; import org.springframework.boot.context.properties.ConfigurationProperties; import org.springframework.stereotype.Component; @Data @Component @ConfigurationProperties(prefix = \"order\") public class OrderProperties { /** * 订单支付超时时长，单位：秒。 */ private Integer payTimeoutSeconds; /** * 订单创建频率，单位：秒 */ private Integer createFrequencySeconds; } 4、创建OrderController请求类 package com.example.nacosConfig.controller; import com.central.common.api.CommonResult; import com.example.nacosConfig.configProperties.OrderProperties; import com.example.nacosConfig.domain.Order; import org.springframework.web.bind.annotation.PostMapping; import org.springframework.web.bind.annotation.RequestBody; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; import javax.annotation.Resource; @RestController @RequestMapping(\"/order\") public class OrderController { @Resource private OrderProperties orderProperties; @PostMapping(\"/create\") public CommonResult create(@RequestBody Order order) { return CommonResult.success(\"订单创建成功!\"); } @PostMapping(\"/getOrderProperties\") public CommonResult getOrderProperties() { return CommonResult.success(orderProperties); } } 5、启动项目，可以就看到Nacos的相关日志如下 [nacos-config-service:192.168.130.167:8195] 2022-01-10 11:38:35.597 INFO 60022 [] [main] com.alibaba.nacos.client.naming [BEAT] adding beat: {\"cluster\":\"DEFAULT\",\"ip\":\"192.168.130.167\",\"metadata\":{\"preserved.register.source\":\"SPRING_CLOUD\"},\"period\":5000,\"port\":8195,\"scheduled\":false,\"serviceName\":\"DEFAULT_GROUP@@nacos-config-service\",\"stopped\":false,\"weight\":1.0} to beat map. [nacos-config-service:192.168.130.167:8195] 2022-01-10 11:38:35.658 INFO 60022 [] [main] com.alibaba.nacos.client.naming [REGISTER-SERVICE] public registering service DEFAULT_GROUP@@nacos-config-service with instance: {\"clusterName\":\"DEFAULT\",\"enabled\":true,\"ephemeral\":true,\"healthy\":true,\"instanceHeartBeatInterval\":5000,\"instanceHeartBeatTimeOut\":15000,\"ip\":\"192.168.130.167\",\"ipDeleteTimeout\":30000,\"metadata\":{\"preserved.register.source\":\"SPRING_CLOUD\"},\"port\":8195,\"weight\":1.0} [nacos-config-service:192.168.130.167:8195] 2022-01-10 11:38:35.665 INFO 60022 [] [main] c.a.c.n.registry.NacosServiceRegistry nacos registry, DEFAULT_GROUP nacos-config-service 192.168.130.167:8195 register finished [nacos-config-service:192.168.130.167:8195] 2022-01-10 11:38:35.670 INFO 60022 [] [main] c.e.nacosConfig.NacosConfigApplication Started NacosConfigApplication in 4.49 seconds (JVM running for 5.209) [nacos-config-service:192.168.130.167:8195] 2022-01-10 11:38:35.676 INFO 60022 [] [main] c.a.n.client.config.impl.ClientWorker [fixed-127.0.0.1_8848] [subscribe] nacos-config-service.yaml+DEFAULT_GROUP [nacos-config-service:192.168.130.167:8195] 2022-01-10 11:38:35.676 INFO 60022 [] [main] c.a.nacos.client.config.impl.CacheData [fixed-127.0.0.1_8848] [add-listener] ok, tenant=, dataId=nacos-config-service.yaml, group=DEFAULT_GROUP, cnt=1 [nacos-config-service:192.168.130.167:8195] 2022-01-10 11:38:35.677 INFO 60022 [] [main] c.a.n.client.config.impl.ClientWorker [fixed-127.0.0.1_8848] [subscribe] nacos-config-service+DEFAULT_GROUP [nacos-config-service:192.168.130.167:8195] 2022-01-10 11:38:35.677 INFO 60022 [] [main] c.a.nacos.client.config.impl.CacheData [fixed-127.0.0.1_8848] [add-listener] ok, tenant=, dataId=nacos-config-service, group=DEFAULT_GROUP, cnt=1 5、请求接口如下 nacos配置中心多环境配置 增加dev配置中心 增加NacosConfig配置 com.alibaba.cloud spring-cloud-starter-alibaba-nacos-config 项目新增dev、prod配置 1、新增dev配置文件 spring: cloud: nacos: # Nacos 作为注册中心的配置项，对应 NacosDiscoveryProperties 配置类 config: server-addr: 127.0.0.1:8848 # Nacos 服务器地址 namespace: ec2feef0-6b78-432b-b19f-c67bd8d25622 # Nacos 命名空间 dev 的编号 group: DEFAULT_GROUP # 使用的 Nacos 配置分组，默认为 DEFAULT_GROUP name: ${spring.application.name} # 使用的 Nacos 配置集的 dataId，默认为 spring.application.name file-extension: yaml # 使用的 Nacos 配置集的 dataId 的文件拓展名，同时也是 Nacos 配置集的配置格式，默认为 propertie 2、新增prod配置文件 spring: cloud: nacos: # Nacos 作为注册中心的配置项，对应 NacosDiscoveryProperties 配置类 config: server-addr: 127.0.0.1:8848 # Nacos 服务器地址 namespace: 2c2e6be6-b514-47da-b216-c800b4292aa7 # Nacos 命名空间 prod 的编号 group: DEFAULT_GROUP # 使用的 Nacos 配置分组，默认为 DEFAULT_GROUP name: ${spring.application.name} # 使用的 Nacos 配置集的 dataId，默认为 spring.application.name file-extension: yaml # 使用的 Nacos 配置集的 dataId 的文件拓展名，同时也是 Nacos 配置集的配置格式，默认为 propertie 3、bootstrap.yaml bootstrap.yaml 配置文件，放不同环境的相同配置。例如说，spring.application.name 配置项，肯定是相同的啦。配置如下 spring: application: name: nacos-config-service # Spring 应用名 启动项目测试 使用 VM 参数进行 -Dspring.profiles.active=dev，对 bootstrap.yaml 配置文件有效 项目启动后可以看到打印的参数如下: [nacos-config-service:192.168.130.167:0000] 2022-01-10 13:48:31.415 INFO 97990 [] [main] c.e.nacosConfig.NacosConfigApplication The following profiles are active: dev [nacos-config-service:192.168.130.167:0000] 2022-01-10 13:48:32.183 WARN 97990 [] [main] o.s.boot.actuate.endpoint.EndpointId Endpoint ID 'nacos-config' contains invalid characters, please migrate to a valid format. [nacos-config-service:192.168.130.167:0000] 2022-01-10 13:48:32.187 WARN 97990 [] [main] o.s.boot.actuate.endpoint.EndpointId Endpoint ID 'nacos-discovery' contains invalid characters, please migrate to a valid format 配置中心自动刷新设置 增加注解@RefreshScope package com.example.nacosConfig.controller; import com.central.common.api.CommonResult; import com.example.nacosConfig.configProperties.OrderProperties; import org.springframework.cloud.context.config.annotation.RefreshScope; import org.springframework.web.bind.annotation.PostMapping; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; import javax.annotation.Resource; @RestController @RequestMapping(\"/order\") @RefreshScope public class OrderController { @Resource private OrderProperties orderProperties; @PostMapping(\"/create\") public CommonResult create() { return CommonResult.success(\"订单创建成功!\"); } @PostMapping(\"/getOrderProperties\") public CommonResult getOrderProperties() { return CommonResult.success(orderProperties); } } 启动项目 对配置进行修改 1、修改前的配置 2、请求http://localhost:8195/order/getOrderProperties接口测试 3、修改nacos配置中心相关数据 4、重新请求接口http://localhost:8195/order/getOrderProperties接口测试 发现配置已经动态刷新 增加动态监听配置事件 1、java代码如下 package com.example.nacosConfig.Listener; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.cloud.context.environment.EnvironmentChangeEvent; import org.springframework.context.ApplicationListener; import org.springframework.core.env.ConfigurableEnvironment; import org.springframework.stereotype.Component; import javax.annotation.Resource; @Component public class EnvironmentChangeListener implements ApplicationListener { private final Logger logger = LoggerFactory.getLogger(getClass()); @Resource private ConfigurableEnvironment environment; public void onApplicationEvent(EnvironmentChangeEvent environmentChangeEvent) { for (String key : environmentChangeEvent.getKeys()) { logger.info(\"[onApplicationEvent][key({}) 最新 value 为 {}]\", key, environment.getProperty(key)); } } } 2、测试更新配置如下打印日志 九、配置加密设置 考虑到安全性，最好将配置文件中的敏感信息进行加密。例如说，MySQL 的用户名密码、第三方平台的Token令牌等等 Nacos + Jasypt 配置加密 1、增加pom引入 com.github.ulisesbocchio jasypt-spring-boot-starter 3.0.2 2、新增nacos配置 3、JasyptTest 测试类进行加密 package com.example.nacosConfig.controller; import org.jasypt.encryption.StringEncryptor; import org.junit.Test; import org.junit.runner.RunWith; import org.springframework.boot.test.context.SpringBootTest; import org.springframework.test.context.ActiveProfiles; import org.springframework.test.context.junit4.SpringRunner; import javax.annotation.Resource; @RunWith(SpringRunner.class) @SpringBootTest @ActiveProfiles(\"dev\") public class JasyptTest { @Resource private StringEncryptor encryptor; @Test public void encode() { String password = \"joyowo\"; System.out.println(encryptor.encrypt(password)); } } 4、执行方法encode（）获得加密结果 Q1Iu4V1Nk7QpnxAT+EKbeHc3cnSG4UBc 5、将加密后的值填入nacos配置项xxx-password中 对Nacos的加密配置进行解密 1、JasyptEnvironmentChangeListener监听器解密 package com.example.nacosConfig.Listener; import org.apache.commons.lang3.StringUtils; import org.jasypt.encryption.StringEncryptor; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.cloud.context.environment.EnvironmentChangeEvent; import org.springframework.cloud.context.environment.EnvironmentManager; import org.springframework.context.ApplicationListener; import org.springframework.stereotype.Component; import javax.annotation.Resource; @Component public class JasyptEnvironmentChangeListener implements ApplicationListener { private final Logger logger = LoggerFactory.getLogger(getClass()); // Environment 管理器，可以实现配置项的获取和修改 @Resource private EnvironmentManager environmentManager; // Jasypt 加密器，可以对配置项进行加密和加密 @Resource private StringEncryptor encryptor; public void onApplicationEvent(EnvironmentChangeEvent event) { for (String key : event.getKeys()) { // 获得 value Object valueObj = environmentManager.getProperty(key); if (!(valueObj instanceof String)) { continue; } String value = (String) valueObj; // 判断 value 是否为加密。如果是，则进行解密 if (value.startsWith(\"ENC(\") && value.endsWith(\")\")) { value = encryptor.decrypt(StringUtils.substringBetween(value, \"ENC(\", \")\")); logger.info(\"[onApplicationEvent][key({}) 解密后为 {}]\", key, value); // 设置到 Environment 中 environmentManager.setProperty(key, value); } } } } 2、调用接口进行测试http://localhost:8195/order/test 调用方法实现解密返回joyowo 十、配置加载顺序 Nacos Config 提供了三种配置 Nacos 配置集的方式： 当三种方式共同使用时，它们的优先级关系是：1 1、通过 spring.cloud.nacos.config.shared-configs 配置项，支持多个共享 Nacos 配置集。 2、通过 spring.cloud.nacos.config.extension-configs 配置项，支持多个拓展 Nacos 配置集。 3、通过 spring.cloud.nacos.config.name 配置项，支持一个 Nacos 配置集。 配置文件如下显示 spring: application: name: social #各服务只需修改此服务名配置，其他配置不用变更，也不建议变更 profiles: active: '@profileActive@' cloud: nacos: config: #服务需动态刷新的配置，如开关、阀值等，如没有，可以不配置, 如需配置，请在配置中心添加，完整配置文件名为admin-refreshable.yml(例) name: ${spring.application.name}-refreshable namespace: # 使用的 Nacos 的命名空间，默认为 null group: DEFAULT_GROUP # 使用的 Nacos 配置分组，默认为 DEFAULT_GROUP file-extension: yml # 拓展配置集数组，对应 Config 数组 extension-configs: - data-id: ${spring.application.name}-fixed.yml #与环境无关，各服务固定的配置，不可动态刷新，如服务端口、job端口、ID生成器编号等 group: DEFAULT_GROUP # 使用的 Nacos 配置分组，默认为 DEFAULT_GROUP refresh: true # 是否自动刷新配置，默认为 false - data-id: ${spring.application.name}-test1db.yml #数据库配置，与环境、服务都有关，需分别配置，不可动态刷新，请在配置中心添加，完整配置文件名为admin-db.yml(例) group: DEFAULT_GROUP # 使用的 Nacos 配置分组，默认为 DEFAULT_GROUP refresh: true # 是否自动刷新配置，默认为 false # 共享配置集数组，对应 Config 数组 shared-configs: - data-id: common.yml #系统整体公共的配置，不可动态刷新，与环境、服务都无关，架构统一配置，各服务无需配置 refresh: true # 是否自动刷新配置，默认为 false group: common - data-id: shared-midware.yml #公共的中间件配置，不可动态刷新，与环境有关，服务无关，如mq、redis、注册中心、xxl-job等，日志等级也在此配置 #运维统一配置，各服务无需配置 refresh: true # 是否自动刷新配置，默认为 false group: common #不同环境只需不同的配置中心地址，无其他额外配置，故采用单文件多文档块配置 #注意不要删了分割符“---” --- spring: profiles: dev cloud: nacos: config: namespace: abd0ead4-597a-418a-92e7-efad9c0c274b server-addr: 172.16.16.30:8848 [!note] alibaba/nacos注册中心、配置中心架构整合 麒麟系统已经引入nacos作为注册中心、配置中心,本文梳理了整个nacos架构模型。目前各环境是配置在maven中依赖配置的，在本地环境调试切换时需要实时刷新maven环境依赖，比较吃本地电脑性能。建议将环境切换配置在项目启动参数上，减少maven不必要的刷新提高本地性能，同时职责单一。 nacos 主要大纲 1、了解注册、配置中心多环境配置过程。（开发、测试、预发布、生产等环境隔离） 2、了解自动刷新配置。（不重启项目对配置更新事件进行监听通知更新） 3、配置加密（敏感信息进行加密。如MySQL的用户名密码、第三方平台的Token令牌等） 4、了解Nacos配置集的方式 使用教程语雀地址: https://joyowo.yuque.com/techs/regulations/xtdqrf "},"chapter1/section4.html":{"url":"chapter1/section4.html","title":"1.4 Nacos配置中心持久化","keywords":"","body":"Nacos配置中心持久化 [!note] 当使用默认启动Nacos时候，所有的配置文件被nacos保存在了内置的数据库中； Nacos通过集中式存储来保证数据的持久化，同时也为Nacos集群部署奠定了基础； 组建Nacos集群，那各个节点中的数据唯一性就是最大的问题. Nacos采用了单一数据源，直接解决了分布式和集群部署中的一致性问题。 单机模式支持mysql 在0.7版本之前，在单机模式时nacos使用嵌入式数据库实现数据的存储，不方便观察数据存储的基本情况。0.7版本增加了支持mysql数据源能力，具体的操作步骤 [!note] 1、安装数据库，版本要求：5.6.5+ 2、初始化mysql数据库，数据库初始化文件：nacos-mysql.sql 3、修改conf/application.properties文件，增加支持mysql数据源配置（目前只支持mysql），添加mysql 数据源的url、用户名和密码。 初始化数据库 进入 /nacos-2.0.4/distribution/target/nacos-server-2.1.0-SNAPSHOT/nacos/conf目录下 初始化文件nacos-mysql.sql 修改配置文件 [!note] /nacos-2.0.4/distribution/target/nacos-server-2.1.0-SNAPSHOT/nacos/conf 位于application.properties 32 ### If use MySQL as datasource: 33 spring.datasource.platform=mysql 34 35 ### Count of DB: 36 db.num=1 37 38 ### Connect URL of DB: 39 db.url.0=jdbc:mysql://127.0.0.1:3306:3306/nacos?characterEncoding=utf8&connectTimeout=1000&socketTimeout=3000&autoReconnect=true&useUnicode=true&useSSL=false&serverTimezone=UTC 40 db.user.0=fangyang 41 db.password.0=224206799qqFy 在此启动Nacos sh startup.sh -m standalone 增加nacos配置 查看是否持化话到mysql "},"chapter1/section5.html":{"url":"chapter1/section5.html","title":"1.5 服务容错Sentinel","keywords":"","body":"aibaba服务容错Sentinel Sentinel是什么 [!note] https://sentinelguard.io/zh-cn/docs/introduction.html Sentinel 是面向分布式服务架构的高可用防护组件，主要以流量为切入点，从流量控制、熔断降级、系统自适应保护等多个维度来帮助用户保障微服务的稳定性 随着微服务的流行，服务和服务之间的稳定性变得越来越重要。Sentinel 以流量为切入点，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性。 组成 Sentinel分为两个部分: 1、核心库（Java 客户端）不依赖任何框架/库，能够运行于所有 Java 运行时环境，同时对 Dubbo / Spring Cloud 等框架也有较好的支持。 2、控制台（Dashboard）基于 Spring Boot 开发，打包后可以直接运行，不需要额外的 Tomcat 等应用容器。 安装sentinel 下载 版本v1.8.3 https://github.com/alibaba/Sentinel/releases/download/1.8.3/sentinel-dashboard-1.8.3.jar # 下载 ➜ webApp wget https://github.com/alibaba/Sentinel/releases/download/1.8.3/sentinel-dashboard-1.8.3.jar 启动 # 启动 java -Dserver.port=7070 -Dcsp.sentinel.dashboard.server=localhost:7070 -Dproject.name=sentinel-dashboard -jar sentinel-dashboard-1.8.3.jar 访问界面 [!note] 地址 http://localhost:7070/ 默认账号密码 「sentinel / sentinel」 流量控制 pom文件引入新的依赖 com.alibaba.cloud spring-cloud-starter-alibaba-sentinel 配置文件结构 server: port: 9866 #对应服务的端口号 spring: application: name: alibaba-sentinel-service # Spring 应用名 cloud: sentinel: # Sentinel 配置项，对应 SentinelProperties 配置属性类 enabled: true # 是否开启。默认为 true 开启 eager: true # 是否饥饿加载。默认为 false 关闭 transport: dashboard: 127.0.0.1:7070 # Sentinel 控制台地址 filter: url-patterns: /** # 拦截请求的地址。默认为 /* 代码测试 1、对应流量异常拦截器实现 package com.example.alibaba.sentinel.webHandler; import com.alibaba.csp.sentinel.adapter.spring.webmvc.callback.BlockExceptionHandler; import com.alibaba.csp.sentinel.slots.block.BlockException; import com.central.common.exception.BusinessException; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.stereotype.Component; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; /** * 自定义sentinel异常捕获 */ @Component public class CustomBlockExceptionHandler implements BlockExceptionHandler { private static final Logger LOGGER = LoggerFactory.getLogger(CustomBlockExceptionHandler.class); @Override public void handle(HttpServletRequest request, HttpServletResponse response, BlockException e) throws Exception { LOGGER.error(\"CustomBlockExceptionHandler捕获流量异常\", e); throw new BusinessException(\"捕获流量异常\"); } } 2、测试类实现 package com.example.alibaba.sentinel.controller; import com.central.common.api.CommonResult; import com.example.alibaba.sentinel.domain.Order; import com.example.alibaba.sentinel.service.OrderService; import org.springframework.web.bind.annotation.*; import javax.annotation.Resource; @RestController @RequestMapping(\"/order\") public class OrderController { @Resource private OrderService orderService; @PostMapping(\"/create\") public CommonResult create(@RequestBody Order order) { orderService.create(order); return CommonResult.success(\"订单创建成功!\"); } @GetMapping(\"/sleep\") public CommonResult sleep() throws InterruptedException { Thread.sleep(100L); return CommonResult.success(\"sleep!\"); } } idea项目启动日志 [alibaba-sentinel-service:192.168.130.167:9866] 2022-01-13 19:03:11.852 INFO 16038 [] [main] trationDelegate$BeanPostProcessorChecker Bean 'spring.cloud.sentinel-com.alibaba.cloud.sentinel.SentinelProperties' of type [com.alibaba.cloud.sentinel.SentinelProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) INFO: log output type is: file INFO: log charset is: utf-8 INFO: log base dir is: /Users/apple/logs/csp/ INFO: log name use pid is: false [alibaba-sentinel-service:192.168.130.167:9866] 2022-01-13 19:03:12.252 INFO 16038 [] [main] trationDelegate$BeanPostProcessorChecker Bean 'com.alibaba.cloud.sentinel.custom.SentinelAutoConfiguration' of type [com.alibaba.cloud.sentinel.custom.SentinelAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying) [alibaba-sentinel-service:192.168.130.167:9866] 2022-01-13 19:03:12.741 INFO 16038 [] [main] o.s.b.w.embedded.tomcat.TomcatWebServer Tomcat initialized with port(s): 9866 (http) [alibaba-sentinel-service:192.168.130.167:9866] 2022-01-13 19:03:12.753 INFO 16038 [] [main] o.a.coyote.http11.Http11NioProtocol Initializing ProtocolHandler [\"http-nio-9866\"] [alibaba-sentinel-service:192.168.130.167:9866] 2022-01-13 19:03:12.754 INFO 16038 [] [main] o.apache.catalina.core.StandardService Starting service [Tomcat] [alibaba-sentinel-service:192.168.130.167:9866] 2022-01-13 19:03:12.754 INFO 16038 [] [main] org.apache.catalina.core.StandardEngine Starting Servlet engine: [Apache Tomcat/9.0.30] [alibaba-sentinel-service:192.168.130.167:9866] 2022-01-13 19:03:12.876 INFO 16038 [] [main] o.a.c.c.C.[Tomcat].[localhost].[/] Initializing Spring embedded WebApplicationContext [alibaba-sentinel-service:192.168.130.167:9866] 2022-01-13 19:03:12.876 INFO 16038 [] [main] o.s.web.context.ContextLoader Root WebApplicationContext: initialization completed in 2205 ms [alibaba-sentinel-service:192.168.130.167:9866] 2022-01-13 19:03:13.320 INFO 16038 [] [main] org.redisson.Version Redisson 3.16.1 [alibaba-sentinel-service:192.168.130.167:9866] 2022-01-13 19:03:13.616 INFO 16038 [] [redisson-netty-2-14] o.r.c.pool.MasterPubSubConnectionPool 1 connections initialized for localhost/127.0.0.1:6379 [alibaba-sentinel-service:192.168.130.167:9866] 2022-01-13 19:03:13.637 INFO 16038 [] [redisson-netty-2-20] o.r.c.pool.MasterConnectionPool 24 connections initialized for localhost/127.0.0.1:6379 [alibaba-sentinel-service:192.168.130.167:9866] 2022-01-13 19:03:14.274 INFO 16038 [] [main] o.s.s.concurrent.ThreadPoolTaskExecutor Initializing ExecutorService 'applicationTaskExecutor' [alibaba-sentinel-service:192.168.130.167:9866] 2022-01-13 19:03:14.316 INFO 16038 [] [main] c.a.c.s.SentinelWebAutoConfiguration [Sentinel Starter] register SentinelWebInterceptor with urlPatterns: [/**]. [alibaba-sentinel-service:192.168.130.167:9866] 2022-01-13 19:03:14.924 INFO 16038 [] [main] o.s.b.a.e.web.EndpointLinksResolver Exposing 2 endpoint(s) beneath base path '/actuator' 使用浏览器访问下 http://127.0.0.1:7070/地址进入到Sentinel控制台 [!note] 如下所示的菜单中，可以看到当前项目应用注册到Sentinel上的所有的实例 调用接口多次 http://localhost:9866/order/create 如下所示 针对/order/create接口点击[流量]按钮，弹出[新增流控规则] [!note] 这里创建的规则比较简单，仅允许/order/create 资源被每秒调用五次. 1、多次调用接口http://localhost:9866/order/create 五次以上会出现被Sentinel流量控制而拒绝 如下所示 点击 Sentinel 控制台的「实时监控」菜单，可以看到该接口被拒绝的统计 熔断降级 [!note] 参考 https://github.com/alibaba/Sentinel/wiki/%E7%86%94%E6%96%AD%E9%99%8D%E7%BA%A7 什么是熔断降级 [!note] 引用自：https://github.com/alibaba/Sentinel/wiki/%E4%B8%BB%E9%A1%B5#%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6 除了流量控制以外，及时对调用链路中的不稳定因素进行熔断也是Sentinel的使命之一。由于调用关系的复杂性，如果调用链路中的某个资源出现了不稳定，可能会导致请求发生堆积，进而导致联级错误。 熔断降级设计理念 [!note] Sentinel和Hystrix的原则是一致的: 当检测到调用链路中某个资源出现不稳定的表现，例如请求响应时间长或异常比例升高的时候，则对这个资源的调用进行限制，让请求快速失败，避免影响到其他的资源而导致联级故障。 在限制的手段上，Sentinel和Hystrix采取了完全不一样的方法。 Hystrix通过线程池隔离的方式，来对依赖（Sentinel的概念中对对应的资源）进行了隔离。这样做的好处是资源和资源之间做到了最彻底的隔离。缺点是除了增加了线程切换的成本（过多的线程池导致了线程数目过多），还需要预先给各个资源做线程池大小的分配。 Sentinel采取的手段解决方式 1、通过并发线程进行限制. 和资源池隔离的方法不同，sentinel通过限制资源并发的数量，来减少不稳定资源相对其他资源的影响。这样不但没有线程切换的损耗，也不需要预先分配线程池的大小。当某个资源出现不稳定的情况下，例如响应时间变长，对资源的直接影响就是会造成线程数的逐步堆积。当线程在特定资源上堆积到一定的数量之后，对该资源的新请求就会拒绝。堆积的线程完成任务之后才开始继续接收请求。 2、通过响应时间对资源进行降级。 除了对并发线程数进行控制以外，Sentinel还可以通过相应时间快速降级不稳定的资源。当依赖的资源出现相应的时间过长后，所有对该资源的访问都会被直接拒绝，直到了指定的时间窗口之后才重新恢复。 测试实战 1、代码例子 @GetMapping(\"/sleep\") public CommonResult sleep() throws InterruptedException { Thread.sleep(200L); return CommonResult.success(\"sleep!\"); } 2、创建新的熔断规则 慢调用比例 (SLOW_REQUEST_RATIO)：选择以慢调用比例作为阈值，需要设置允许的慢调用 RT（即最大的响应时间），请求的响应时间大于该值则统计为慢调用。当单位统计时长1s（statIntervalMs）内请求数目大于设置的最小请求数目，并且慢调用的比例大于阈值，则接下来的熔断时长内请求会自动被熔断。经过熔断时长后熔断器会进入探测恢复状态（HALF-OPEN 状态），若接下来的一个请求响应时间小于设置的慢调用 RT 则结束熔断，若大于设置的慢调用 RT 则会再次被熔断。 3、多次调用接口测试 http://localhost:9866/order/sleep 4、点击Sentinel控制台，可以看看到该接口被拒绝的统计 热点数据限流 [!note] 引用 https://github.com/alibaba/Sentinel/wiki/%E7%83%AD%E7%82%B9%E5%8F%82%E6%95%B0%E9%99%90%E6%B5%81 何为热点？热点即经常访问的数据。很多时候我们希望统计某个热点数据中访问频次最高的 Top 数据，并对其访问进行限制 1、商品 ID 为参数，统计一段时间内最常购买的商品 ID 并进行限制 2、用户 ID 为参数，针对一段时间内频繁访问的用户 ID 进行限制 热点参数限流说明 热点参数限流会统计传入参数中的热点参数，并根据配置的限流阀值与模式，对包含热点参数的资源调用进行限流。热点参数限流可以看作是一种特殊的流量控制，仅对包含热点参数额资源调用生效. [!note] Sentinel 利用LRU策略统计最近最常访问的热点参数，结合令牌桶算法来进行参数级别的流控。热点参数限流支持集群模式。 热点参数限流测试实战 1、代码例子 // 测试热点数据限流 @GetMapping(\"/orderInfo\") @SentinelResource(\"orderInfo\") public CommonResult orderInfo(Integer id) { return CommonResult.success(\"订单编号：\" + id); } Sentinel UI界面新增新增热点规则 [!note] 这里，设置了参数索引为0，统计窗口时长为30秒，请求最大次数为10 编辑热点规则 [!note] 这里配置了第一个参数的值为1时，限制在统计窗口中，请求最大的次数为1 1、使用浏览器访问http://127.0.0.1:9866/demo/product_info?id=1接口两次，可以看到接口被拒绝的统计如下 2、使用浏览器访问http://127.0.0.1:9866/demo/product_info?id=3接口，不会存在限流的情况。而是在快速访问10次，才会被限流。 系统自适应限流 [!note] 引自: https://github.com/alibaba/Sentinel/wiki/%E4%B8%BB%E9%A1%B5#%E7%B3%BB%E7%BB%9F%E8%B4%9F%E8%BD%BD%E4%BF%9D%E6%8A%A4 Sentinel同时提供系统维度的自适应保护能力。防止雪崩，是系统防护中重要一环。当系统负载较高的时候，如果还持续让请求进入，可能会导致系统崩溃，无法相应。在集群环境中，网络负载均衡会把本应这台机器承载的流量转发到其他的机器上去。如果这个时候其他的机器也处在一个边缘状态的时候，这个增加的流量就会导致这台机器崩溃，最后导致整个集群不可用。 针对这个情况，Sentinel 提供了对应的保护机制，让系统入口的流量和系统的负载达到一个平衡，保证系统在能力范围之内处理最多的请求。 新增系统保护规则 1、在Sentinel控制台 系统规则菜单，新增系统规则, 创建一条CPU超过1%后，自动进行系统限流如下: Sentinel的五种规则 1、Load自适应（仅对linux机器生效） [!note] 系统的load1作为启发指标，进行自适应系统保护。当系统load1超过设定的启发值，且系统的并发线程数超过估算的系统容量时才会触发系统保护（BBR阶段）。系统容量由系统maxQps*minRt 估算得出。设定参考值一般是 CPU cores*2.5 2、CPU usage（1.50+ 版本） [!note] 当系统CPU使用率超过阀值即触发系统保护，单位是毫秒。 3、平均RT [!note] 当单台机器上所有入口流量的平均RT 达到阀值即触发系统保护，单位是毫秒。 4、并发线程数 [!note] 当单台机器上所有流量的并发线程数达到阀值即触发系统保护 5、入口QPS [!note] 当单台机器上所有入口流量的QPS达到阀值即触发系统保护。 调用测试 黑白名单控制 [!note] 引自: https://github.com/alibaba/Sentinel/wiki/%E9%BB%91%E7%99%BD%E5%90%8D%E5%8D%95%E6%8E%A7%E5%88%B6 很多时候，我们需要根据调用来源来判断该次请求是否允许通过放行，这时候可以使用Sentinel的来源访问控制（黑白名单）的功能。来源访问控制根据资源的请求来源（origin）限制资源是否通过： 1、若配置白名单则只有请求来源位于白名单的内时才通过 2、若配置黑名单则请求来源位于黑名单时不通过，其余的请求通过 拦截器RequestOriginParser 从请求中解析到调用来源，例如说使用IP、请求头user、请求头appName等 实现代码 package com.example.alibaba.sentinel.webFilter; import com.alibaba.csp.sentinel.adapter.spring.webmvc.callback.RequestOriginParser; import org.springframework.stereotype.Component; import org.springframework.util.StringUtils; import javax.servlet.http.HttpServletRequest; @Component public class CustomRequestOriginParser implements RequestOriginParser { @Override public String parseOrigin(HttpServletRequest request) { // 从 Header 中，获得请求来源 String origin = request.getHeader(\"s-user\"); // 如果为空，给一个默认的 if (StringUtils.isEmpty(origin)) { origin = \"default\"; } return origin; } } 新增授权规则 [!note] 添加方法 /order/orderInfo的授权规则 1、使用浏览器请求接口http://localhost:9866/order/orderInfo 2、请求头增加Head \"s-user\": \"test\" Sentinel客户端API 注解支持 [!note] @SentinelResource 注解 引自: https://github.com/alibaba/Sentinel/wiki/%E6%B3%A8%E8%A7%A3%E6%94%AF%E6%8C%81 1、value: 资源名称，必须项（不能为空） 2、entryType: entry类型，可选项（默认为EntryType. OUT） 3、blockHandler/blockHandlerClass: blockHandler对应处理BlockException 的函数名称，可选项。blockHandler函数访问范围是public，返回类型需要与原方法相匹配，参数类型需要和原方法相匹配并且最后一个额外的参数，类型是BlockException。blockHandler函数默认需要和原方法在同一个类中。若希望使用其他类的函数，则可以指定blockHandlerClass对应的类的Class对象，注意对应的函数必须为static函数，否则无法解析. 4、fallback/fallbackClass: fallback函数名称，可选项，用于抛出异常的时候提供fallback处理逻辑。fallback函数可以针对所有类型的异常（除了exceptionsToIgnore 里面排除掉的异常类型）进行处理。fallback 函数签名和位置要求    返回值类型必须与原函数返回值类型一致；    方法参数列表需要和原函数一致，或者可以额外多一个 Throwable 类型的参数用于接收对应的异常。    fallback函数默认需要和原方法在同一个类中。若希望使用其他类的函数，则可以指定fallbackClass 为对应的类的Class对象，注意对应的函数必需为 static 函数否则无法解析。 5、defaultFallback（since 1.6.0）：默认的 fallback 函数名称，可选项，通常用于通用的 fallback 逻辑（即可以用于很多服务或方法）。默认 fallback 函数可以针对所有类型的异常（除了 exceptionsToIgnore 里面排除掉的异常类型）进行处理。若同时配置了 fallback 和 defaultFallback，则只有 fallback 会生效。defaultFallback 函数签名要求    返回值类型必须与原函数返回值类型一致； 方法参数列表需要为空，或者可以额外多一个 Throwable 类型的参数用于接收对应的异常。 6、defaultFallback :函数默认需要和原方法在同一个类中。若希望使用其他类的函数，则可以指定 fallbackClass 为对应的类的 Class 对象，注意对应的函数必需为 static 函数，否则无法解析。 特别地，若 blockHandler 和 fallback 都进行了配置，则被限流降级而抛出 BlockException 时只会进入 blockHandler 处理逻辑。若未配置 blockHandler、fallback 和 defaultFallback，则被限流降级时会将 BlockException 直接抛出（若方法本身未定义 throws BlockException 则会被 JVM 包装一层 UndeclaredThrowableException）。 注解代码示例 [!note] blockHandler和fallback都进行配置，则被限流而抛出BlockException时只会进入blockHandler处理逻辑. fallback和fallHandler的差异点，在于clockHandler只能处理BlockException异常，fallback能处理所有的异常 // 测试「Sentinel @SentinelResource 注解」 @GetMapping(\"/annotations\") @SentinelResource(value = \"annotations\", blockHandler = \"blockHandler\", fallback = \"fallback\") public CommonResult annotationsDemo(@RequestParam(required = false) Integer id) { if (id == null) { throw new BusinessException(\"id 参数不允许为空\"); } return CommonResult.success(\"success...\"); } // BlockHandler 处理函数，参数最后多一个 BlockException，其余与原函数一致. public CommonResult blockHandler(Integer id, BlockException ex) { return CommonResult.success(\"block：\" + ex.getClass().getSimpleName()); } // Fallback 处理函数，函数签名与原函数一致或加一个 Throwable 类型的参数. public CommonResult fallback(Integer id, Throwable throwable) { return CommonResult.success(\"fallback：\" + throwable.getMessage()); } 规则管理及推送 [!note] 引自: https://github.com/alibaba/Sentinel/wiki/%E5%9C%A8%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E4%B8%AD%E4%BD%BF%E7%94%A8-Sentinel 规则管理及推送三种模式 推送模式 说明 优点 缺点 原始模式 API 将规则推送至客户端并直接更新到内存中，扩展写数据源（WritableDataSource） 简单，无任何依赖 不保证一致性；规则保存在内存中，重启即消失。严重不建议用于生产环境 Pull模式 扩展写数据源（WritableDataSource）， 客户端主动向某个规则管理中心定期轮询拉取规则，这个规则中心可以是 RDBMS、文件 等 简单，无任何依赖；规则持久化 不保证一致性；实时性不保证，拉取过于频繁也可能会有性能问题。 Push模式 扩展读数据源（ReadableDataSource），规则中心统一推送，客户端通过注册监听器的方式时刻监听变化，比如使用 Nacos、Zookeeper 等配置中心。这种方式有更好的实时性和一致性保证。生产环境下一般采用 push 模式的数据源。 规则持久化；一致性；快速 引入第三方依赖 Push模式 [!note] 生产环境下一般更常用的是 push 模式的数据源。对于 push 模式的数据源,如远程配置中心（ZooKeeper, Nacos, Apollo等等），推送的操作不应由 Sentinel 客户端进行，而应该经控制台统一进行管理，直接进行推送，数据源仅负责获取配置中心推送的配置并更新到本地。因此推送规则正确做法应该是 配置中心控制台/Sentinel 控制台 → 配置中心 → Sentinel 数据源 → Sentinel，而不是经 Sentinel 数据源推送至配置中心。这样的流程就非常清晰了 使用Nacos作为数据源 [!note] 使用Nacos作为Sentinel规则的数据源，并使用Push模式推送规则 引入pom依赖 com.alibaba.csp sentinel-datasource-nacos 配置文件 server: port: 9866 #对应服务的端口号 spring: application: name: alibaba-sentinel-service # Spring 应用名 cloud: # Sentinel 配置项，对应 SentinelProperties 配置属性类 sentinel: enabled: true # 是否开启。默认为 true 开启 eager: true # 是否饥饿加载。默认为 false 关闭 transport: dashboard: 127.0.0.1:7070 # Sentinel 控制台地址 filter: url-patterns: /** # 拦截请求的地址。默认为 /* # Sentinel 规则的数据源，是一个 Map 类型。key 为数据源名，可自定义；value 为数据源的具体配置 datasource: ds1: # 对应 DataSourcePropertiesConfiguration 类 nacos: server-addr: 127.0.0.1:8848 # Nacos 服务器地址 namespace: # Nacos 命名空间 group-id: DEFAULT_GROUP # Nacos 分组 data-id: ${spring.application.name}-flow-rule # Nacos 配置集编号 data-type: json # 数据格式 rule-type: FLOW # 规则类型 [!note] 通过添加 spring.cloud.sentinel.datasource 配置项，设置接入的 Sentinel 规则的数据源。注意它是一个 Map 类型 1、key: 为数据源名，可自定义，无特殊含义。 2、value :为数据源的具体配置，对应 DataSourcePropertiesConfiguration 类，可以选择 file、nacos、zk、apollo、redis 任一作为数据的数据源。这里我们选择 nacos 来接入 Nacos 作为数据源 rule-type：数据源对应的 Sentinel 规则类型，在 RuleType 类枚举。这里我们设置了 FLOW 对应流量控制的规则 data-type：数据源的数据格式，默认为 json。这里我们设置了 json，所以稍后创建的 Nacos 配置集的数据格式要为 JSON。 server-addr：Nacos 服务器地址。 namespace：Nacos 分组。 data-id：Nacos 配置集编号。推荐配置集编号的命名规则为 ${applicationName}-${ruleType}，因此这里我们设置为 alibaba-sentinel-service，即 alibaba-sentinel 应用的流控规则。 "},"chapter1/section6.html":{"url":"chapter1/section6.html","title":"1.6 参数校验工具类介绍","keywords":"","body":"参数校验工具类介绍 前言 [!note] 目前项目中对于参数验证有各种形式、有的接口参数一个个校验的话就太繁琐了，代码可读性极差。有的用到Spring Boot中自带的验证注解，但是使用的仅仅只是在表层. 所以目前这边做了统一的梳理，方便大家理解和后续的使用。 在项目中不管是前端页面表单提交的对象数据和第三方公司进行接口对接又或者是项目中的Excel导入的参数验证，都是需要对接收的数据进行校验（非空、长度、格式等等）。前端js校验可以涵盖大部分的校验指责，但是为了避免用户绕过浏览器，使用http工具直接向后端请求一些违法数据，服务器的数据校验也是必要的，可以防止脏数据落到数据库中。同时后端中比较原始的的写法是使用if一个个进行校验（字段非常多），靠代码对接口参数一个个校验的话就太繁琐了，代码可读性极差。下面主要是说明SprinBoot中如何集成参数校验Validator，以及参数校验的高阶技巧（自定义校验，分组校验）。 [!note] 此文是依赖已有代码基础，已经在项目中加入了全局异常校验器。 本地代码已上传远程仓库 https://github.com/BenjaminFyang/javaVal.git Java Bean 验证基础 概述 在项目中使用前，首先需要介绍下标准框架 JSR 380（也称为Bean Validation 2.0）验证 Java bean 的基础知识。 在大多数应用程序中，验证用户输入是一个非常普遍的要求。而 Java Bean Validation 框架已经成为处理这种逻辑的事实标准。 JSR 380 JSR 380是用于bean验证的Java API规范。这确保bean的属性满足特定条件，使用诸如@NotNull、@Min和@Max 之类的注释 此版本需要 Java 8或更高版本，并利用Java 8 中添加的新功能，例如类型注释和对Optional和LocalDate等新类型的支持。 有关规范的完整信息，请继续阅读JSR 380 依赖、验证API javax.validation validation-api 2.0.1.Final org.hibernate.validator hibernate-validator 6.0.13.Final 使用验证注解 这里使用一个 Userbean 添加一些简单的验证 package com.java.xval.val.beanvalidation; import lombok.Data; import javax.validation.constraints.*; import java.math.BigDecimal; import java.time.LocalDate; import java.util.List; @Data public class User { @NotNull(message = \"名字不能为空\") private String name; @AssertTrue private boolean working; @Size(min = 10, max = 200, message = \"字符数应介于10和200之间（含10和200）\") private String aboutMe; @Min(value = 18, message = \"年龄不应少于18岁\") @Max(value = 150, message = \"年龄不应超过150岁\") private int age; @Email(message = \"电子邮件应该是有效的\") private String email; private List preferences; @Past(message = \"出生年月必须是一个过去的时间\") private LocalDate dateOfBirth; @DecimalMin(value = \"0.0\", inclusive = false, message = \"付款金额不能小于0\") @Digits(integer = 4, fraction = 2, message = \"付款金额必须小于{integer}位数且不能超过{fraction}位小数\") private BigDecimal price; } 示例中使用的所有注释都是标准的 JSR 注释： 常见的约束注解如下 验证注解 验证的数据类型 说明 @AssertFalse Boolean, boolean 验证注解的元素值是false @AssertTrue Boolean, boolean 验证注解的元素值是true @NotNull 任意类型 验证注解的元素值不是null @Null 任意类型 验证注解的元素值是null @Min(value=值) BigDecimal，BigInteger, byte, short, int, long，等任何Number或CharSequence（存储的是数字）子类型 验证注解的元素值大于等于@Min指定的value值 @Max（value=值） 和@Min要求一样 验证注解的元素值小于等于@Max指定的value值 @DecimalMin(value=值) 和@Min要求一样 验证注解的元素值大于等于@ DecimalMin指定的value值 @DecimalMax(value=值) 和@Min要求一样 验证注解的元素值小于等于@ DecimalMax指定的value值 @Digits(integer=整数位数, fraction=小数位数) 和@Min要求一样 验证注解的元素值的整数位数和小数位数上限 @Size(min=下限, max=上限) 字符串、Collection、Map、数组等 验证注解的元素值的在min和max（包含）指定区间之内，如字符长度、集合大小 @Past java.util. Date, java.util. Calendar; Joda Time类库的日期类型 验证注解的元素值（日期类型）比当前时间早 @Future 与@Past要求一样 验证注解的元素值（日期类型）比当前时间晚 @NotBlank CharSequence子类型 验证注解的元素值不为空（不为null、去除首位空格后长度为0），不同于@NotEmpty，@NotBlank只应用于字符串且在比较时会去除字符串的首位空格 @Length(min=下限, max=上限) CharSequence子类型 验证注解的元素值长度在min和max区间内 @NotEmpty CharSequence子类型、Collection、Map、数组 验证注解的元素值不为null且不为空（字符串长度不为0、集合大小不为0） @Range(min=最小值, max=最大值) BigDecimal, BigInteger, CharSequence, byte, short, int, long等原子类型和包装类型 验证注解的元素值在最小值和最大值之间 @Email(regexp=正则表达式, flag=标志的模式) CharSequence子类型（如String） 验证注解的元素值是Email，也可以通过regexp和flag指定自定义的email格式 @Pattern(regexp=正则表达式, flag=标志的模式) String，任何CharSequence的子类型 验证注解的元素值与指定的正则表达式匹配 @Valid 任何非原子类型 指定递归验证关联的对象如用户对象中有个地址对象属性，如果想在验证用户对象时一起验证地址对象的话，在地址对象上加@Valid注解即可级联验证 @Positive 和@Min要求一样 适用于数值并验证它们是严格的正数 @PositiveOrZero 和@Min要求一样 适用于数值并验证它们是严格的正数，包括 0 @Negative 和@Min要求一样 适用于数值并验证它们是严格负数 @NegativeOrZero 和@Min要求一样 适用于数值并验证它们是严格负数，包括0 @PastOrPresent java.util. Date, java.util. Calendar; Joda Time类库的日期类型 验证日期值是过去还是过去，包括现在；可以应用于日期类型，包括在 Java 8 中添加的日期类型。 @FutureOrPresent java.util. Date, java.util. Calendar; Joda Time类库的日期类型 验证日期值是在未来，包括现在 验证注释也可以应用于集合的元素 private List preferences; 支持Java 8 中的新Optional类型 @Past(message = \"出生年月必须是一个过去的时间\") private LocalDate dateOfBirth; public Optional getDateOfBirth() { return Optional.of(dateOfBirth); } 程序验证 在框架中（例如：Spring）具有通过使用注释来进行验证，现在主要通过单元测试以编码方式进行设置 package com.java.xval.val; import com.java.xval.val.beanvalidation.User; import org.junit.Before; import org.junit.Test; import javax.validation.ConstraintViolation; import javax.validation.Validation; import javax.validation.Validator; import javax.validation.ValidatorFactory; import java.util.Set; public class ValidationTest { private Validator validator; @Before public void setup() { ValidatorFactory factory = Validation.buildDefaultValidatorFactory(); validator = factory.getValidator(); } @Test public void ifNameIsNull() { User user = new User(); user.setWorking(true); user.setAboutMe(\"me\"); user.setAge(50); // validate方法来验证我们的 UserBean User对象中定义的约束都将作为Set返回 Set> violations = validator.validate(user); for (ConstraintViolation violation : violations) { // getMessage方法获取所有违规消息 System.out.println(violation.getMessage()); } } } 示例如下图所示 总结 上面介绍Java验证API的简单传递，使用javax.validation注释和API进行bean验证的基础知识，代码片段的实现都可以在 GitHub 上找到 三、Bean验证中@NotNull、@NotEmpty和@NotBlank约束之间的差异 概述差异 [!note] 上面整体上使用bean验证实现，比较简单，但是一些实现这些约束还是有相关的差异，在项目中使用的时候经常会看到大家使用的比较混淆。 @NotNull受约束的CharSequence、Collection、Map或Array只要不为空就有效，但可以为空。 @NotEmpty受约束的CharSequence、Collection、Map或Array是有效的，只要它不为空，并且其大小/长度大于零。 @NotBlank约束字符串只要不为空就有效，并且修剪后的长度大于零。 SpringBoot中集成参数校验 前言概述 在验证用户输入方面，Spring Boot为这种常见但关键的任务提供了强大的支持 尽管Spring Boot支持与自定义验证器的无缝集成，但执行验证的事实上的标准是Hibernate Validator 应用分层 [!note] Java业务应用程序有不同的形式和类型。根据这些标准和形式，我们的程序需要确定在那些层进行参数验证需求。 消费者层或Web层是Web应用程序的最顶层，主要是负责用户的输入并提供相应的响应，Web层是应用程序的入口，负责身份验证并作为防止未经授权用户的第一道防线。 服务层验证 [!note] 服务层是应用程序中Web层和持久层之前通信的层，业务逻辑存在服务器中，也包括验证逻辑等。当验证不绑定到Web层，并允许使用任何可用的验证器。同时客户端数据的输入并不总是WebREST层控制的。如果不在服务层进行验证，数据可能流转到持久层，从而导致问题，在服务层也可以使用标准的 Java JSR-303 验证 package com.java.xval.val.service.impl; import com.baomidou.mybatisplus.extension.service.impl.ServiceImpl; import com.java.xval.val.common.utils.ValidatorUtil; import com.java.xval.val.mapper.PmsSkuStockMapper; import com.java.xval.val.model.PmsSkuStock; import com.java.xval.val.service.PmsSkuStockService; import org.springframework.stereotype.Service; import org.springframework.util.CollectionUtils; import javax.annotation.Resource; import javax.validation.*; import java.util.Set; /** * * sku的库存 服务实现类 * * * @author fangyang * @since 2021-09-16 */ @Service public class PmsSkuStockServiceImpl extends ServiceImpl implements PmsSkuStockService { @Override public void addPmsSkuStock(PmsSkuStock pmsSkuStock) { Set> validate = ValidatorUtil.getValidator().validate(pmsSkuStock); if (!CollectionUtils.isEmpty(validate)) { StringBuilder sb = new StringBuilder(); for (ConstraintViolation constraintViolation : validate) { sb.append(constraintViolation.getMessage()); } throw new ConstraintViolationException(\"Error occurred: \" + sb, validate); } save(pmsSkuStock); } } springBoot Rest验证 开始引入依赖 从 Boot 2.3 开始，我们还需要显式添加spring-boot-starter-validation依赖项： org.springframework.boot spring-boot-starter-web org.springframework.boot spring-boot-starter-validation 定义要参数校验的实体类 package com.java.xval.val.model; import java.math.BigDecimal; import com.baomidou.mybatisplus.annotation.TableName; import com.baomidou.mybatisplus.annotation.IdType; import com.baomidou.mybatisplus.annotation.TableId; import java.io.Serializable; import io.swagger.annotations.ApiModel; import io.swagger.annotations.ApiModelProperty; import lombok.Data; import lombok.EqualsAndHashCode; import javax.validation.constraints.*; /** * sku的库存 * * @author fangyang * @since 2021-09-16 */ @Data @EqualsAndHashCode(callSuper = false) @TableName(\"pms_sku_stock\") @ApiModel(value = \"PmsSkuStock对象\", description = \"sku的库存\") public class PmsSkuStock implements Serializable { private static final long serialVersionUID = 1L; @TableId(value = \"id\", type = IdType.AUTO) private Long id; private Long productId; @ApiModelProperty(value = \"sku编码\") @NotBlank(message = \"sku编码编码不能为空\") private String skuCode; @NotNull(message = \"付款金额不能为空\") @DecimalMin(value = \"0.0\", inclusive = false, message = \"付款金额不能小于0\") @Digits(integer = 4, fraction = 2, message = \"付款金额必须小于{integer}位数且不能超过{fraction}位小数\") private BigDecimal price; @PositiveOrZero(message = \"库存不能小于0\") @ApiModelProperty(value = \"库存\") private Integer stock; @ApiModelProperty(value = \"预警库存\") @Positive(message = \"预警库存必须大于0\") private Integer lowStock; @ApiModelProperty(value = \"销售属性1\") private String sp1; private String sp2; private String sp3; @ApiModelProperty(value = \"展示图片\") private String pic; @ApiModelProperty(value = \"销量\") @PositiveOrZero(message = \"库存不能为负数\") private Integer sale; @ApiModelProperty(value = \"单品促销价格\") @DecimalMin(value = \"0\", message = \"单品促销价格必须大于0\") private BigDecimal promotionPrice; @ApiModelProperty(value = \"锁定库存\") @Min(value = 0, message = \"锁定库存必须大于0\") private Integer lockStock; } [!note] 这里我列举了商品的sku的库存表展示了如何使用 Bean Validation 约束bean对象的属性，以上就是一个商品库存属性的基本定义。 实现一个REST控制器 [!note] 需要实现一个层，允许获取分配给商品库存约束字段的值，可以进一步验证它们根据验证结果执行下一步的任务。 Spring Boot通过 REST 控制器的实现使这个看似复杂的过程变得非常简单 package com.java.xval.val.controller; import com.java.xval.val.common.api.CommonResult; import com.java.xval.val.model.PmsSkuStock; import org.springframework.web.bind.annotation.PostMapping; import org.springframework.web.bind.annotation.RequestBody; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; import javax.validation.Valid; /** * sku的库存 前端控制器 * * @author fangyang * @since 2021-09-16 */ @RestController @RequestMapping(\"/val/pmsSkuStock\") public class PmsSkuStockController { @PostMapping(\"/add\") CommonResult addPmsSkuStock(@Valid @RequestBody PmsSkuStock pmsSkuStock) { return CommonResult.success(\"pmsSkuStock is valid\"); } } 在spring REST中 addPmsSkuStock()方法的实现是增加商品库存信息，其中在验证参数过程中，最相关的部分是@Valid注释的使用。 当 Spring Boot 找到一个用@Valid注释的参数时，它会自动引导默认的JSR380实现Hibernate Validator——并验证该参数。 当目标参数验证失败时，Spring Boot 会抛出MethodArgumentNotValidException异常 @ExceptionHandler @ExceptionHandler注解允许我们通过一个单一的方法处理特定类型的异常 package com.java.xval.val.common.exception; import com.java.xval.val.common.api.CommonResult; import lombok.extern.slf4j.Slf4j; import org.springframework.validation.BindingResult; import org.springframework.validation.FieldError; import org.springframework.web.bind.MethodArgumentNotValidException; import org.springframework.web.bind.annotation.ControllerAdvice; import org.springframework.web.bind.annotation.ExceptionHandler; import org.springframework.web.bind.annotation.ResponseBody; /** * 全局异常处理 */ @Slf4j @ControllerAdvice public class GlobalExceptionHandler { @ResponseBody @ExceptionHandler(value = MethodArgumentNotValidException.class) public CommonResult handleValidException(MethodArgumentNotValidException e) { BindingResult bindingResult = e.getBindingResult(); return getCommonResult(bindingResult); } /** * 异常数据封装. * * @param bindingResult 验证框架 * @return the CommonResult */ private CommonResult getCommonResult(BindingResult bindingResult) { String message = null; if (bindingResult.hasErrors()) { FieldError fieldError = bindingResult.getFieldError(); if (fieldError != null) { message = fieldError.getField() + fieldError.getDefaultMessage(); } } return CommonResult.validateFailed(message); } } 指定MethodArgumentNotValidException异常作为 要处理的异常 。因此，当指定的PmsSkuStock对象无效时，SpringBoot将调用此方法. 该方法将无效的字段和验证后错误信息封装被全局异常 (GlobalExceptionHandler) 拦截后将错误消息填充在自定义对象CommonResult作为JSON表示返回到客户端进一步处理。 总之、REST 控制器允许处理不同情况的请求、验证商品库存对象以JSON格式响应返回。 测试REST控制器 使用单元测试验证 目前springBoot只需要测试到web层，使用@WebMvcTest注释。允许MockMvcRequestBuilders和MockMvcResultMatchers类实现的方法进行单元测试请求和响应 package com.java.xval.val; import org.junit.Test; import org.junit.runner.RunWith; import org.springframework.boot.test.autoconfigure.web.servlet.AutoConfigureMockMvc; import org.springframework.boot.test.autoconfigure.web.servlet.WebMvcTest; import org.springframework.http.MediaType; import org.springframework.test.context.junit4.SpringRunner; import org.springframework.test.web.servlet.MockMvc; import org.springframework.test.web.servlet.request.MockMvcRequestBuilders; import org.springframework.test.web.servlet.result.MockMvcResultMatchers; import javax.annotation.Resource; import java.nio.charset.StandardCharsets; @RunWith(SpringRunner.class) @WebMvcTest @AutoConfigureMockMvc public class PmsSkuStockControllerIntegrationTest { @Resource private MockMvc mockMvc; @Test public void pmsSkuStock() throws Exception { MediaType textPlainUtf8 = new MediaType(MediaType.TEXT_PLAIN, StandardCharsets.UTF_8); String pmsSkuStock = \"{\\\"price\\\": \\\"-12\\\", \\\"skuCode\\\" : \\\"bob\\\"}\"; mockMvc.perform(MockMvcRequestBuilders.post(\"/val/pmsSkuStock/add\") .content(pmsSkuStock) .contentType(MediaType.APPLICATION_JSON_UTF8)) .andExpect(MockMvcResultMatchers.status().isOk()) .andExpect(MockMvcResultMatchers.content() .contentType(textPlainUtf8)); } } 单元测试如下 [!note] 从上图可以看到、验证拦截生效 返回 {\"code\":404, \"message\":\"price付款金额不能小于0\", \"data\":null} 使用 Postmen 来测试REST控制器API 公司项目中如果对单元测试的覆盖率或者没有要求需要进行单元测试（ps: 个人认为如果单元测试是有必要的、能够减少代码的bug率、即时发现项目中的问题暴露出来。但是目前我个人除了必要的逻辑复杂模块进行单元测试，大部分还是使用Postmen） [!note] 使用postMen测试返回 price付款金额不能小于0 @Valid和@Validated注解的区别 @Valid和@Validated注解 @Valid(javax.validation) : 是Bean Validation 中的标准注解，表示对需要校验的 【字段/方法/入参】 进行校验标记 @Validated (org.springframework.validation.annotation) : 是Spring对@Valid扩展后的变体，支持分组校验 分组验证代码示例 首先使用SpringBoot开发简单的用户订单表。我们只存在用户一些基础信息如下: package com.java.xval.val.model.request; import io.swagger.annotations.ApiModel; import io.swagger.annotations.ApiModelProperty; import lombok.Data; import javax.validation.constraints.NotBlank; import javax.validation.constraints.Null; /** * 订单表 */ @Data @ApiModel public class OrderDTO { @ApiModelProperty(\"id,新增不必传递,修改必须传递\") @Null(message = \"id必须为null或空\") private Integer id; @ApiModelProperty(value = \"购物账号\", required = true) @NotBlank(message = \"购物账号不能为空\") private String account; @ApiModelProperty(value = \"订单号\") private String orderNum; @ApiModelProperty(value = \"邮箱\") @Email(message = \"邮件格式不正确\") private String email; @ApiModelProperty(value = \"地址\") private String address; @ApiModelProperty(value = \"备注\") private String remark; } REST控制器。在这里，将使用带有@Valid注释的addEmergency方法来验证用户输入的订单 package com.java.xval.val.controller; import com.java.xval.val.common.api.CommonResult; import com.java.xval.val.model.request.OrderDTO; import io.swagger.annotations.Api; import io.swagger.annotations.ApiOperation; import io.swagger.annotations.ApiParam; import lombok.extern.slf4j.Slf4j; import org.springframework.web.bind.annotation.PostMapping; import org.springframework.web.bind.annotation.RequestBody; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; import javax.validation.Valid; /** * 描述: * 〈购物账号模块〉 * * @author fangyang * @since 2021-09-16 */ @Slf4j @Api(tags = \"【后端】订单模块\") @RestController @RequestMapping(value = \"/admin/order\") public class OrderController { @PostMapping(value = \"add\") @ApiOperation(httpMethod = \"POST\", value = \"添加\", response = Boolean.class) public CommonResult addEmergency(@ApiParam(required = true) @RequestBody @Valid OrderDTO orderDTO) { return CommonResult.success(\"添加订单成功\"); } } 如果这个时候我们需要将这个功能进行扩展，需要添加后台管理员一个修改订单备注的功能。还是同样的对象我们需要进行扩展，订单id和订单备注在修改的时候不能为空的验证，为了支持这种行为，我们需要分组验证和@Validated注释。 我们需要对字段进行分组，创建两个不同的组。首先，需要创建两个标记接口。每个组单独一个, 新增（AddParam)和修改(UpdateParam). AddParam package com.java.xval.val.model.request.validation; import javax.validation.groups.Default; public interface AddParam extends Default { } UpdateParam package com.java.xval.val.model.request.validation; import javax.validation.groups.Default; public interface UpdateParam extends Default { } 订单bean实体类 package com.java.xval.val.model.request; import com.java.xval.val.model.request.validation.AddParam; import com.java.xval.val.model.request.validation.UpdateParam; import io.swagger.annotations.ApiModel; import io.swagger.annotations.ApiModelProperty; import lombok.Data; import javax.validation.constraints.NotBlank; import javax.validation.constraints.NotNull; import javax.validation.constraints.Null; /** * 订单表 */ @Data @ApiModel public class OrderDTO { @ApiModelProperty(\"id,新增不必传递,修改必须传递\") @Null(message = \"id必须为null或空\", groups = {AddParam.class}) @NotNull(message = \"id不能为空\", groups = {UpdateParam.class}) private Integer id; @ApiModelProperty(value = \"购物账号\", required = true) @NotBlank(message = \"购物账号不能为空\", groups = {AddParam.class}) private String account; @ApiModelProperty(value = \"订单号\") private String orderNum; @ApiModelProperty(value = \"邮箱\") @Email(message = \"邮件格式不正确\") private String email; @ApiModelProperty(value = \"地址\") private String address; @ApiModelProperty(value = \"备注\") @NotNull(message = \"备注不能为空\", groups = {UpdateParam.class}) private String remark; } 对webController进行改造 package com.java.xval.val.controller; import com.java.xval.val.common.api.CommonResult; import com.java.xval.val.model.request.OrderDTO; import com.java.xval.val.model.request.validation.AddParam; import com.java.xval.val.model.request.validation.UpdateParam; import io.swagger.annotations.Api; import io.swagger.annotations.ApiOperation; import io.swagger.annotations.ApiParam; import lombok.extern.slf4j.Slf4j; import org.springframework.validation.annotation.Validated; import org.springframework.web.bind.annotation.PostMapping; import org.springframework.web.bind.annotation.RequestBody; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; /** * 描述: * 〈购物账号模块〉 * * @author fangyang * @since 2021-09-16 */ @Slf4j @Api(tags = \"【后端】订单模块\") @RestController @RequestMapping(value = \"/admin/order\") public class OrderController { @PostMapping(value = \"add\") @ApiOperation(httpMethod = \"POST\", value = \"添加\", response = Boolean.class) public CommonResult addEmergency(@ApiParam(required = true) @RequestBody @Validated({AddParam.class}) OrderDTO orderDTO) { return CommonResult.success(\"添加订单成功\"); } @PostMapping(value = \"update\") @ApiOperation(httpMethod = \"POST\", value = \"修改\", response = Boolean.class) public CommonResult updateEmergency(@ApiParam(required = true) @RequestBody @Validated({UpdateParam.class}) OrderDTO orderDTO) { return CommonResult.success(\"修改订单成功\"); } } 以上可以自己进行验证，可以看到@Validated的使用 对于组验证至关重要 使用@Valid注解标记嵌套对象 所述@Valid注释用于标记尤其嵌套属性。这会触发嵌套对象的验证。例如，在我们当前的场景中，让我们创建一个 OrderNextCardDTO 礼品卡集合对象： /** * 订单表 */ @Data @ApiModel public class OrderDTO { //... @Valid @NotNull(message = \"礼品卡不能为空\", groups = {AddParam.class}) @ApiModelProperty(value = \"礼品卡集合\") List orderNextCardDTOList; } package com.java.xval.val.model.request; import io.swagger.annotations.ApiModel; import io.swagger.annotations.ApiModelProperty; import lombok.Data; import javax.validation.constraints.DecimalMin; import javax.validation.constraints.NotNull; import java.math.BigDecimal; /** * * 订单子表-->礼品卡 * */ @Data @ApiModel public class OrderNextCardDTO { @ApiModelProperty(value = \"礼品卡id\") @NotNull(message = \"礼品卡id为空\", groups = {AddParam.class}) private Integer cardId; @ApiModelProperty(value = \"使用金额\") @DecimalMin(value = \"0\", message = \"使用金额最小为0\", groups = {AddParam.class}) private BigDecimal amount; } 新增接口测试图例 修改接口测试图例 对比总结 [!note] @Valid注释保证了整个对象的验证。重要的是，它执行整个对象的验证。这会为仅需要部分验证的场景带来问题. 可以使用@Validated 进行组验证，包括上面的部分验证 枚举类型的验证 验证枚举简介 下面我将使用自定义注解为枚举构建验证，在JSR 380bean验证注解中，大多数标准注解不能应用于enums 当然也可以使用@Pattern注释，但是在匹配的时候也不够全面。唯一可以应用于枚举的标准注释是@NotNull和@Null 验证字符串是否匹配枚举的值 创建一个注解来检查字符串对于特定枚举是否有效。 package com.joyowo.smarthr.social.common.util.validator; import javax.validation.Constraint; import javax.validation.Payload; import java.lang.annotation.ElementType; import java.lang.annotation.Retention; import java.lang.annotation.RetentionPolicy; import java.lang.annotation.Target; /** * 验证状态是否在指定范围内的注解 */ @Target({ElementType.METHOD, ElementType.FIELD, ElementType.ANNOTATION_TYPE}) @Retention(RetentionPolicy.RUNTIME) @Constraint(validatedBy = EnumValidatorClass.class) public @interface EnumValue { Class[] groups() default {}; Class[] payload() default {}; /** * @return 枚举类 */ Class> enumClass(); /** * @return 枚举校验的方法 */ String enumMethod() default \"isValidEnum\"; /** * @return 默认提示文字 */ String message() default \"传参错误,对应枚举未找到\"; /** * @return 默认返回为false */ boolean allowNull() default false; } 可以将此注解添加到String字段，可以传递任何枚举值 /** * 订单表 */ @Data @ApiModel public class OrderDTO { //... /** * 下单网站 */ @ValueOfEnum(enumClass = OrderWebsiteEnum.class, groups = {AddParam.class}, message = \"对应的下单网站不存在\") private String orderWebsite; } 定义ValueOfEnumValidator来检查字符串（或任何CharSequence）是否包含在 enum 中： package com.java.xval.val.common.constraints.validator; import com.java.xval.val.common.constraints.ValueOfEnum; import javax.validation.ConstraintValidator; import javax.validation.ConstraintValidatorContext; import java.lang.reflect.Method; import java.util.ArrayList; import java.util.List; public class ValueOfEnumValidator implements ConstraintValidator { private List acceptedValues; @Override public void initialize(ValueOfEnum annotation) { Method getMessage; List list = new ArrayList<>(); try { getMessage = annotation.enumClass().getMethod(annotation.enumMethod()); for (Enum en : annotation.enumClass().getEnumConstants()) { String invoke = (String) getMessage.invoke(en); list.add(invoke); acceptedValues = list; } } catch (Exception e) { acceptedValues = null; } } @Override public boolean isValid(CharSequence value, ConstraintValidatorContext context) { if (value == null) { return true; } if (acceptedValues == null) { return false; } return acceptedValues.contains(value.toString()); } } 实际验证中将值映射到String, 而不是将值映射到枚举。然后将使用定义的验证器来检查它是否与任何枚举值匹配。 枚举接口测试图例 总结 回顾 [!note] 参数验证在目前的实际开发中使用频率非常多，但是还停留在简单的使用上，比如分组校验，自定义注解参数验证还没怎么用到过，项目中如果要进行对象参数验证，会建立多了VO用于接收Create，Update场景的情况，比较荣誉和繁琐。上面做了相关的说明和用例测试。 多种常用校验注解 单个参数校验 全局异常处理自动组装校验异常 分组验证 嵌套验证 自定义注解验证 excel导入和关联参数验证 目前项目中excel导入数据源占用的比例很大，在项目中可以使用 Hibernate Validator对基础的参数进行验证，但是对于一些关联的参数验证，比如政策变更申请导入列验证 停止执行年月 需晚于等于执行开始时间 追溯对象不为空的情况下、应该与缴纳主体一致 企缴固定金额（元）收费频率等于按月 缴纳主体等于企业或者全部 当且仅当“当月缴企缴规则等于按固定值”时必填 个缴固定金额（元）收费频率等于按月 缴纳主体等于个人或者全部 当且仅当“月缴个缴规则等于按固定值”时必填 企缴最低基数（元):收费频率为月,月缴企缴计算规则等于缴基数比例,缴纳主体等于企业或者全部时必填 ......等100多个需要验证的逻辑 面对这样可以使用阿里来源的项目QLExpress脚本引擎进行优化，github地址：https://github.com/alibaba/QLExpress。介于目前篇幅比较长，后续再单独介绍脚本引擎在导入中的使用。如果感兴趣的可以先提前了解下。 "},"chapter1/section7.html":{"url":"chapter1/section7.html","title":"1.7 Feign集成OKHttp","keywords":"","body":"Feign集成OKHttp OkHttp官方API说明 [!note] 参考: https://square.github.io/okhttp/ Feign 1、在Feign中，Client是一个非常重要的组件，Feign最终发送Request请求以及接收Response响应都是由Client组件来完成的。Client在Feign源码中是一个接口，在默认情况下，Client的实现类是Client. Default。Client. Default是由HttpURLConnection来实现网络请求的。另外, Client还支持HttpClient和OkHttp3来进行网络请求。 2、HttpURLConnection没有连接池，但是对每个地址会保持一个长连接。可以用Apache的HTTP Client替换Feign原始的http client, 从而获取连接池、超时时间等与性能息息相关的控制能力。 OkHttp的优点 1、支持HTTP/2 , 当多个请求对应同一host地址时，可共用同一个socket； 2、连接池可减少请求延迟（如果HTTP/2不可用）； 3、支持GZIP压缩，减少网络传输的数据大小； 4、支持Response数据缓存，避免重复网络请求； Feign使用Okhttp 集成项目github地址 https://github.com/BenjaminFyang/frameService-platform.git 项目结构 ├── HELP.md ├── seata-service │ ├── accountService (账号微服务) │ ├── orderService （订单微服务） │ ├── pom.xml │ ├── seata-service.iml │ └── storageService （库存微服务） ├── services-traceId.iml ├── servicesTraceId.iml ├── traceId-commons (工具包) │ ├── feignOkHttp （feign集成OkHttp） │ ├── pom.xml │ ├── traceId-common-core （核心工具类） │ ├── traceId-commons.iml │ ├── traceId-log-springcloud-starter （日志工具类） │ └── traceId-rocketmq-starter (Rocketmq工具类) ├── traceId-eureka （注册中心） │ ├── pom.xml │ ├── src │ ├── target │ └── traceId-eureka.iml ├── traceId-gateway （网关微服务） │ ├── pom.xml │ ├── src │ ├── target │ └── traceId-gateway.iml └── traceId-loadbalancer （负载均衡） ├── pom.xml ├── src ├── target └── traceId-loadbalancer.iml 引入pom文件 io.github.openfeign feign-okhttp 11.0 引入yml # 在配置文件中禁用默认的URLHttpConnection，启动okhttp feign: # 开启okhttp okhttp: enabled: true httpclient: connectionTimeout: 5000 followRedirects: true client: config: default: readTimeout: 5000 writeTimeout: 5000 添加FeignOkHttpConfig.java package com.example.feignokhttp; import okhttp3.ConnectionPool; import org.springframework.boot.autoconfigure.condition.ConditionalOnMissingBean; import org.springframework.cloud.commons.httpclient.OkHttpClientConnectionPoolFactory; import org.springframework.cloud.commons.httpclient.OkHttpClientFactory; import org.springframework.cloud.openfeign.FeignClientProperties; import org.springframework.cloud.openfeign.support.FeignHttpClientProperties; import org.springframework.context.annotation.Bean; import javax.annotation.PreDestroy; import java.util.concurrent.TimeUnit; @ConditionalOnMissingBean(okhttp3.OkHttpClient.class) public class FeignOkHttpConfig { private okhttp3.OkHttpClient okHttpClient; @Bean @ConditionalOnMissingBean(ConnectionPool.class) public ConnectionPool httpClientConnectionPool(FeignHttpClientProperties httpClientProperties, OkHttpClientConnectionPoolFactory connectionPoolFactory) { int maxTotalConnections = httpClientProperties.getMaxConnections(); long timeToLive = httpClientProperties.getTimeToLive(); TimeUnit ttlUnit = httpClientProperties.getTimeToLiveUnit(); return connectionPoolFactory.create(maxTotalConnections, timeToLive, ttlUnit); } @Bean @ConditionalOnMissingBean(okhttp3.OkHttpClient.class) public okhttp3.OkHttpClient okHttpClient(OkHttpClientFactory httpClientFactory, ConnectionPool connectionPool, FeignClientProperties feignClientProperties, FeignHttpClientProperties feignHttpClientProperties) { FeignClientProperties.FeignClientConfiguration defaultConfig = feignClientProperties.getConfig().get(\"default\"); int connectionTimeout = feignHttpClientProperties.getConnectionTimeout(); int readTimeout = defaultConfig.getReadTimeout(); boolean disableSslValidation = feignHttpClientProperties.isDisableSslValidation(); boolean followRedirects = feignHttpClientProperties.isFollowRedirects(); this.okHttpClient = httpClientFactory.createBuilder(disableSslValidation) // 设置读超时 .readTimeout(readTimeout, TimeUnit.MILLISECONDS) //设置连接超时 .connectTimeout(connectionTimeout, TimeUnit.MILLISECONDS) .followRedirects(followRedirects) .connectionPool(connectionPool) // 这里设置我们自定义的拦截器 .addInterceptor(new MyOkhttpInterceptor()) //设置写超时 .writeTimeout(10, TimeUnit.SECONDS) //是否自动重连 .retryOnConnectionFailure(true) .build(); return this.okHttpClient; } @PreDestroy public void destroy() { if (this.okHttpClient != null) { this.okHttpClient.dispatcher().executorService().shutdown(); this.okHttpClient.connectionPool().evictAll(); } } } 添加feign拦截器 package com.example.feignokhttp; import okhttp3.Interceptor; import okhttp3.Request; import okhttp3.Response; import okhttp3.ResponseBody; import org.apache.commons.lang3.StringUtils; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import java.io.IOException; /** * 对feign微服务调用的拦截 自定义返回结果. */ public class MyOkhttpInterceptor implements Interceptor { Logger logger = LoggerFactory.getLogger(MyOkhttpInterceptor.class); public Response intercept(Chain chain) { Request originRequest = chain.request(); Request request = originRequest.newBuilder().build(); if (StringUtils.isNotEmpty(originRequest.header(\"Accept-Encoding\"))) { request = originRequest.newBuilder().removeHeader(\"Accept-Encoding\").build(); } long doTime = System.nanoTime(); Response response = null; try { response = chain.proceed(request); ResponseBody responseBody = response.peekBody(1024 * 1024); long currentTime = System.nanoTime(); logger.info(String.format(\"接收响应: [%s] %n返回json:【%s】 %.1fms%n\", response.request().url(), responseBody.string(), (currentTime - doTime) / 1e6d)); } catch (IOException e) { logger.error(\"MyOkhttpInterceptor调用微服务异常需处理\", e); } return response; } } 微服务引用 package com.example.orderservice.config; import com.example.feignokhttp.FeignOkHttpConfig; import org.springframework.context.annotation.Configuration; @Configuration(proxyBeanMethods = false) public class OrderFeignOkHttpConfig extends FeignOkHttpConfig { } 微服务项目启动 请求接口 curl --location --request POST 'http://localhost:8180/order/create' \\ --header 'Content-Type: application/json' \\ --data-raw '{ \"userId\": 22, \"money\": 22, \"status\": 2 }' 日志打印 [seata-order-service:192.168.130.167:8180] 2021-12-02 11:32:15.305 INFO 35216 [DED5839FF006473690890B1D7C5936B7] [ConsumeMessageThread_1] c.e.o.rocketMqConsumer.Demo01Consumer Consumer-获取消息-主题topic为=DEMO_01, 消费消息为={\"id\":null,\"userId\":22,\"productId\":null,\"count\":null,\"money\":22,\"status\":2} [seata-order-service:192.168.130.167:8180] 2021-12-02 11:32:15.309 INFO 35216 [DED5839FF006473690890B1D7C5936B7] [ConsumeMessageThread_1] c.e.o.rocketMqConsumer.Demo01Consumer 接受到消息通知order={\"money\":22,\"status\":2,\"userId\":22} [seata-order-service:192.168.130.167:8180] 2021-12-02 11:32:18.641 INFO 35216 [DED5839FF006473690890B1D7C5936B7] [http-nio-8180-exec-1] c.e.feignokhttp.MyOkhttpInterceptor 接收响应: [http://192.168.130.167:8181/storage/decrease] 返回json:【{\"code\":200,\"message\":\"操作成功\",\"data\":\"扣减库存成功！\"}】 3174.9ms [seata-order-service:192.168.130.167:8180] 2021-12-02 11:32:18.650 INFO 35216 [DED5839FF006473690890B1D7C5936B7] [http-nio-8180-exec-1] c.e.o.service.impl.OrderServiceImpl ------->order-service中扣减库存结束 [seata-order-service:192.168.130.167:8180] 2021-12-02 11:32:18.650 INFO 35216 [DED5839FF006473690890B1D7C5936B7] [http-nio-8180-exec-1] c.e.o.service.impl.OrderServiceImpl ------->order-service中扣减余额开始 [seata-order-service:192.168.130.167:8180] 2021-12-02 11:32:18.652 INFO 35216 [DED5839FF006473690890B1D7C5936B7] [http-nio-8180-exec-1] c.c.log.trace.FeignTraceInterceptor FeignTraceInterceptor.request: /account/decrease?userId=22&money=22 [seata-order-service:192.168.130.167:8180] 2021-12-02 11:32:21.835 INFO 35216 [DED5839FF006473690890B1D7C5936B7] [http-nio-8180-exec-1] c.e.feignokhttp.MyOkhttpInterceptor 接收响应: [http://192.168.130.167:8182/account/decrease?userId=22&money=22] 返回json:【{\"code\":200,\"message\":\"操作成功\",\"data\":\"扣减账户余额成功！\"}】 3162.5ms jmeter压测对比 todo "},"chapter1/section8.html":{"url":"chapter1/section8.html","title":"1.8 消息队列RocketMQ梳理","keywords":"","body":"消息队列梳理 系统中为什么使用消息队列 [!note] 消息队列使用的场景主要的核心有三个：解耦、异步、削峰 解耦 比方、之前项目中我负责模块遇到这样一个场景。A兼职系统用户报名兼职，会调用B商家报名单系统查看商家的报名单（招聘道具）是否充足，如果不足需要通知A兼职服务（mysql）、C兼职搜索引擎(ES)系统暂停该商家下所有的招聘进行中的兼职，同时需要推送系统D将商家招聘道具不足进行推送、和短信系统E通知给商家手机上。最后将数据同步给CRM销售系统F进行同步。 目前我来梳理下这个场景。A系统查询给B系统，B系统同步回调A、C、D、E、F五个系统，都是通过接口调用发送。现在会发生这样场景 新增G系统也需要这个数据？那如果D系统现在不需要了呢？B系统负责人几乎崩溃...... 同样也无法维护迭代的成本很大 在上面这个场景中，B系统与其他的系统严重耦合，B系统反馈商家报名单不足比较的信息，很多系统都需要B系统将这个信息同步过去。B系统需要关注A、C、D、E、F这五个系统挂了怎么办。需要做事务补偿或者重发，比较复杂了。 如果使用MQ，B系统产生一条数据，发送到MQ里面去，对应的系统需要数据自己去MQ里面消费。如果新系统E需要通知，直接从MQ里面消费即可；如果某个系统不需要这条数据了，就取消对MQ消息的消费即可。这样下来，B系统不需要去考虑要给谁发送数据，不需要维护这个代码，也不需要考虑人家是否调用成功、失败超时等情况。 总结: 通过一个 MQ，Pub/Sub 发布订阅消息这么一个模型，B系统就跟其它系统彻底解耦了 异步 在互联网中，对于用户直接的操作，要求都是在400ms以内处理完成，这样对用户的几乎是无感知的。 使用MQ，那么A系统联系发送2条消息到MQ队列中，假设耗时5ms，A系统从接受一个请求到返回响应给用户，总时长是3+5=8ms，对于用户而言，就好像只点了一个按钮，8ms以后就直接返回了，第一反应就是这个APP或者网站做的真好 哈哈！！（ps: 反正我平时就是这么评价App的） 削峰 正常情况下, 系统比较稳当。并发量并不是特别大，但是如果做活动或者第三方引流（支付宝引流）, 每秒并发请求量会增到8k+, 但是系统存储是直接基于MYSQL的，大量的请求涌入到Mysql，每秒钟对MYSQL执行8K条SQL. 一般情况下mysql扛到每秒2K并发量就到达瓶颈了。如果请求量直接打到8K，可能直接MYSQL挂掉了，导致整个系统崩溃。 但是一般到了中午12:00～14:00，就达到一个低峰期。请求量比较少对系统几乎没有任何压力. 使用MQ，当每秒8K个请求写入MQ，系统每秒最多处理2K个请求，主要是在Mysql瓶颈上面。系统从MQ中慢慢拉取请求，每秒就能拉取2k个请求。就算在高峰时候，系统也绝对不会挂掉。 MQ每秒钟5k个请求进来，其中2k个请求出去，积压的请求在高峰期过去后，系统会快速将积压的消息给解决掉。 引入MQ后业务系统处理能力有限，将压力转嫁到MQ,消息堆积到MQ后可以慢慢进行消费. 消息队列有优缺点 优点 [!note] 在特定场景下的好处，解耦、异步、削峰 缺点 系统的可用性降低 [!note] 系统引入的外部依赖越多，越容易挂掉。本来B系统调用 CDEFG 四个系统的接口就好了，加个 MQ 进来，万一MQ挂了，整套系统崩溃。需要保证消息队列的高可用，在引入MQ之后是需要考虑的。 系统复杂度提高 [!note] MQ进来，需要保证消息没有重复消费？怎么处理消息丢失的情况？怎么保证消息传递的顺序性等等问题。 一致性问题 [!note] B系统处理完了直接返回成功了，以为这个请求就成功了；但是问题是，要是CDEFG四个系统那里，CDE三个系统写库成功了，结果FG系统写库失败了，这数据就不一致了。 RocketMQ基本概念 消息模型 （Message Model） RocketMQ主要由 Producer、Broker、Consumer 三部分组成，其中Producer 负责生产消息，Consumer 负责消费消息，Broker 负责存储消息。Broker 在实际部署过程中对应一台服务器，每个Broker可以存储多个Topic的消息，每个Topic的消息也可以分片存储于不同的 Broker。Message Queue 用于存储消息的物理地址，每个Topic中的消息地址存储于多个 Message Queue 中。ConsumerGroup 由多个Consumer 实例构成。 主题 （Topic） 表示一类消息的集合，每个主题包含若干条消息，每条消息只能属于一个主题，是RocketMQ进行消息订阅的基本单位。 广播消费 （Broadcasting） 广播消费模式下，相同Consumer Group的每个Consumer实例都接收全量的消息。 普通顺序消息 （Normal Ordered Message） 普通顺序消费模式下，消费者通过同一个消息队列（ Topic 分区，称作 Message Queue） 收到的消息是有顺序的，不同消息队列收到的消息则可能是无顺序的。 严格顺序消息 （Strictly Ordered Message） 严格顺序消息模式下，消费者收到的所有消息均是有顺序的。 消息 (Messsge) 消息系统所传输信息的物理载体，生产和消费数据的最小单位，每条消息必须属于一个主题。RocketMQ中每个消息拥有唯一的Message ID，且可以携带具有业务标识的Key。系统提供了通过Message ID和Key查询消息的功能。 RocketMQ结构设计 架构图 说明 [!note] RocketMQ架构主要分为四个部分: Producer 消息发布的角色，支持分布式集群方式部署。Producer通过MQ的负载均衡模块选择相应的Broker集群队列进行消息投递，投递的过程支持快速失败并且低延迟。 Consumer 消息消费的角色，支持分布式集群方式部署。支持以push推，pull拉两种模式对消息进行消费。同时也支持集群方式和广播方式的消费，提供实时消息订阅机制，满足大多数用户需求。 NameServer NameServicer是一个非常简单的Topic路由注册中心，其角色相当于Dubbo中的zookeeper（SpringCloud中的Eureka）, 支持Broker的动态注册与发现。主要包括两个功能: Broker管理，NameService接受Broker集群的注册信息并且保存下来作为路由信息的基本数据。然后提供心跳检测机制，检查Broker是否还存活；路由信息管理，每个NameService将保存关于Broker集群的整个路由信息和用于客户端查询的队列信息。然后Producer和Conumser通过NameServer就可以知道整个Broker集群的路由信息，从而进行消息的投递和消费。NameServer通常也是集群的方式部署，各实例间相互不进行信息通讯。Broker是向每一台NameServer注册自己的路由信息，所以每一个NameServer实例上面都保存一份完整的路由信息。当某个NameServer因某种原因下线了，Broker仍然可以向其它NameServer同步其路由信息，Producer, Consumer仍然可以动态感知Broker的路由的信息。 BrokerServer [!note] Broker主要负责消息的存储、投递和查询以及服务高可用保证，为了实现这些功能，Broker包含了以下几个重要子模块。 Remoting Module：整个Broker的实体，负责处理来自clients端的请求。 Remoting Module：整个Broker的实体，负责处理来自clients端的请求。 Client Manager：负责管理客户端(Producer/Consumer)和维护Consumer的Topic订阅信息 Store Service：提供方便简单的API接口处理消息存储到物理硬盘和查询功能。 HA Service：高可用服务，提供Master Broker 和 Slave Broker之间的数据同步功能。 Index Service：根据特定的Message key对投递到Broker的消息进行索引服务，以提供消息的快速查询。 利用docker安装RocketMQ 安装namesrv [!note] 我们可以去docker官方网站，查找对应的rocketmq的镜像的地址。 https://hub.docker.com/r/rocketmqinc/rocketmq 查询有哪些可用的rocketmq docker search rocketmq 拉取镜像 docker pull rocketmqinc/rocketmq 启动namesrv服务(新建文件路径/opt/mydata/rocketmq) ## /opt/mydata/rocketmq 目录根据实际服务器中创建文件存放的日志和数据的地方 docker run -d -p 9876:9876 -v /opt/mydata/rocketmq/logs:/root/logs -v /opt/mydata/rocketmq/data:/root/store --name rmqnamesrv -e \"MAX_POSSIBLE_HEAP=100000000\" 09bbc30a03b6 sh mqnamesrv 安装broker 创建配置文件 broker.conf [!note] 特别注意 ⚠️ brokerIP1,此处的坑比较大，设置的时候需要特别小心，对于mac电脑设置broker节点所在服务器的ip地址、物理ip，不能用127.0.0.1、localhost、docker内网ip 。可利用ifconfig的命令查看自己的电脑的服务的ip 1 # 所属集群名称，如果节点较多可以配置多个 2 brokerClusterName = DefaultCluster 3 #broker名称，master和slave使用相同的名称，表明他们的主从关系 4 brokerName = broker-a 5 #0表示Master，大于0表示不同的slave 6 brokerId = 0 7 #表示几点做消息删除动作，默认是凌晨4点 8 deleteWhen = 04 9 #在磁盘上保留消息的时长，单位是小时 10 fileReservedTime = 48 11 #有三个值：SYNC_MASTER，ASYNC_MASTER，SLAVE；同步和异步表示Master和Slave之间同步数据的机制； 12 brokerRole = ASYNC_MASTER 13 #刷盘策略，取值为：ASYNC_FLUSH，SYNC_FLUSH表示同步刷盘和异步刷盘；SYNC_FLUSH消息写入磁盘后才返回成功 14 状态，ASYNC_FLUSH不需要； 15 flushDiskType = ASYNC_FLUSH 16 # 设置broker节点所在服务器的ip地址、物理ip，不能用127.0.0.1、localhost、docker内网ip 17 brokerIP1 = 192.168.123.127 启动broker容器 docker run -d -p 10911:10911 -p 10909:10909 -v /opt/mydata/rocketmq/logs:/root/logs -v /opt/mydata/rocketmq/data:/root/store -v /opt/mydata/rocketmq/conf/broker.conf:/opt/rocketmq/conf/broker.conf --name rmqbroker --link rmqnamesrv:namesrv -e \"NAMESRV_ADDR=namesrv:9876\" -e \"JAVA_OPTS=-Duser.home=/opt\" -e \"JAVA_OPT_EXT=-server -Xms1024m -Xmx1024m\" rocketmqinc/rocketmq sh mqbroker -c /opt/rocketmq/conf/broker.conf 安装控制台 rocket-console 拉取rocket-console镜像 docker pull styletang/rocketmq-console-ng 运行rocket-console镜像 docker run -e \"JAVA_OPTS=-Drocketmq.config.namesrvAddr=192.168.123.127:9876 -Drocketmq.config.isVIPChannel=false\" -p 9993:8080 -t styletang/rocketmq-console-ng [!note] 暴露端口号:9876、8080 rocketmq控制台访问 gif动态图 SpringBoot引入RocketMq 引入maven库 org.apache.rocketmq rocketmq-spring-boot-starter 2.1.1 org.apache.rocketmq rocketmq-client 4.8.0 org.apache.rocketmq rocketmq-common 4.8.0 封装配置文件 package com.java.xval.val.common.config; import com.java.xval.val.common.RocketMqHelper; import org.springframework.boot.autoconfigure.condition.ConditionalOnWebApplication; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; @ConditionalOnWebApplication @Configuration(proxyBeanMethods = false) public class RocketMqAutoConfiguration { @Bean public RocketMqHelper rocketMqHelper() { return new RocketMqHelper(); } } 配置启动的注解 package com.java.xval.val.common.constraints; import com.java.xval.val.common.config.RocketMqAutoConfiguration; import org.springframework.context.annotation.Import; import java.lang.annotation.*; /** * 开启RocketMq注解 */ @Documented @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.TYPE) @Import({RocketMqAutoConfiguration.class}) public @interface EnableHyhRocketMq { } 在SpringBoot启动类上添加注解启动 package com.java.xval.val; import com.java.xval.val.common.constraints.EnableHyhRocketMq; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; @SpringBootApplication @EnableHyhRocketMq public class ValApplication { public static void main(String[] args) { SpringApplication.run(ValApplication.class, args); } } 封装RocketMq工具类 package com.java.xval.val.common; import org.apache.rocketmq.client.producer.SendCallback; import org.apache.rocketmq.client.producer.SendResult; import org.apache.rocketmq.spring.core.RocketMQTemplate; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.messaging.Message; import javax.annotation.PostConstruct; import javax.annotation.PreDestroy; import javax.annotation.Resource; /** * 描述: * 〈RocketMq封装工具类〉 * * @author fangyang * @since 2021-10-20 */ public class RocketMqHelper { /** * 日志 */ private static final Logger LOG = LoggerFactory.getLogger(RocketMqHelper.class); /** * rocketmq模板注入 */ @Resource private RocketMQTemplate rocketMQTemplate; @PostConstruct public void init() { LOG.info(\"RocketMq开始实例化\"); } /** * 发送异步消息 * * @param topic 消息Topic * @param message 消息实体 */ public void asyncSend(Enum topic, Message message) { asyncSend(topic.name(), message, getDefaultSendCallBack()); } /** * 发送异步消息 * * @param topic 消息Topic * @param message 消息实体 * @param sendCallback 回调函数 */ public void asyncSend(Enum topic, Message message, SendCallback sendCallback) { asyncSend(topic.name(), message, sendCallback); } /** * 发送异步消息 * * @param topic 消息Topic * @param message 消息实体 */ public void asyncSend(String topic, Message message) { rocketMQTemplate.asyncSend(topic, message, getDefaultSendCallBack()); } /** * 发送异步消息 * * @param topic 消息Topic * @param message 消息实体 * @param sendCallback 回调函数 */ public void asyncSend(String topic, Message message, SendCallback sendCallback) { rocketMQTemplate.asyncSend(topic, message, sendCallback); } /** * 发送异步消息 * * @param topic 消息Topic * @param message 消息实体 * @param sendCallback 回调函数 * @param timeout 超时时间 */ public void asyncSend(String topic, Message message, SendCallback sendCallback, long timeout) { rocketMQTemplate.asyncSend(topic, message, sendCallback, timeout); } /** * 发送异步消息 * * @param topic 消息Topic * @param message 消息实体 * @param sendCallback 回调函数 * @param timeout 超时时间 * @param delayLevel 延迟消息的级别 */ public void asyncSend(String topic, Message message, SendCallback sendCallback, long timeout, int delayLevel) { rocketMQTemplate.asyncSend(topic, message, sendCallback, timeout, delayLevel); } /** * 发送顺序消息 * * @param message 消息实体 * @param topic 消息Topic * @param hashKey 为了保证到同一个队列中，将消息发送到orderTopic主题上 * 他的hash值计算发送到哪一个队列，用的是同一个值,那么他们的hash一样就可以保证发送到同一个队列里 */ public void syncSendOrderly(Enum topic, Message message, String hashKey) { syncSendOrderly(topic.name(), message, hashKey); } /** * 发送顺序消息 * * @param message 消息实体 * @param topic 消息Topic * @param hashKey 为了保证到同一个队列中，将消息发送到orderTopic主题上 * 他的hash值计算发送到哪一个队列，用的是同一个值,那么他们的hash一样就可以保证发送到同一个队列里 */ public void syncSendOrderly(String topic, Message message, String hashKey) { LOG.info(\"发送顺序消息，topic:\" + topic + \",hashKey:\" + hashKey); rocketMQTemplate.syncSendOrderly(topic, message, hashKey); } /** * 发送顺序消息 * * @param message 消息实体 * @param topic 消息Topic * @param hashKey 为了保证到同一个队列中，将消息发送到orderTopic主题上 * 他的hash值计算发送到哪一个队列，用的是同一个值,那么他们的hash一样就可以保证发送到同一个队列里 * @param timeout 延时时间 */ public void syncSendOrderly(String topic, Message message, String hashKey, long timeout) { LOG.info(\"发送顺序消息，topic:\" + topic + \",hashKey:\" + hashKey + \",timeout:\" + timeout); rocketMQTemplate.syncSendOrderly(topic, message, hashKey, timeout); } /** * 默认CallBack函数 * * @return SendCallback */ private SendCallback getDefaultSendCallBack() { return new SendCallback() { @Override public void onSuccess(SendResult sendResult) { LOG.info(\"---发送MQ成功---\"); } @Override public void onException(Throwable throwable) { LOG.error(\"---发送MQ失败---\" + throwable.getMessage(), throwable.getMessage()); } }; } @PreDestroy public void destroy() { LOG.info(\"---RocketMq注销---\"); } } 添加配置文件 #rocketmq配置 rocketmq: name-server: localhost:9876 # 生产者配置 producer: isOnOff: on # 发送同一类消息的设置为同一个group，保证唯一 group: hyh-rocketmq-group groupName: hyh-rocketmq-group # 服务地址 namesrvAddr: localhost:9876 # 消息最大长度 默认1024*4(4M) maxMessageSize: 4096 # 发送消息超时时间,默认3000 sendMsgTimeout: 3000 # 发送消息失败重试次数，默认2 retryTimesWhenSendFailed: 2 测试功能需求 消息发送测试代码如下（示例） package com.java.xval.val.controller; import com.java.xval.val.common.RocketMqHelper; import com.java.xval.val.common.api.CommonResult; import com.java.xval.val.model.Person; import org.springframework.messaging.support.MessageBuilder; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RequestMethod; import org.springframework.web.bind.annotation.RestController; import javax.annotation.Resource; @RestController @RequestMapping(value = \"/message/send\") public class RocketMqController { @Resource private RocketMqHelper rocketMqHelper; private static final Integer NUM = 10; /** * 发送异步消息 * * @return the CommonResult */ @RequestMapping(value = \"/asyncSend\", method = RequestMethod.GET) public CommonResult asyncSend() { Person person = new Person(); person.setName(\"Java开发\"); person.setAge(25); rocketMqHelper.asyncSend(\"PERSON_ADD\", MessageBuilder.withPayload(person).build()); return CommonResult.success(\"发送异步消息发送成功\"); } /** * 发送同步有序的消息. * * @return CommonResult */ @RequestMapping(value = \"/syncSendOrderly\", method = RequestMethod.GET) public CommonResult syncSendOrderly() { String message = \"orderly message: \"; for (int i = 0; i 消息监听代码如下（示例） 异步消息接收代码 package com.java.xval.val.common.listener; import com.java.xval.val.model.Person; import lombok.extern.slf4j.Slf4j; import org.apache.rocketmq.spring.annotation.RocketMQMessageListener; import org.apache.rocketmq.spring.core.RocketMQListener; import org.springframework.stereotype.Component; @Slf4j @Component @RocketMQMessageListener(consumerGroup = \"${rocketmq.producer.groupName}\", topic = \"PERSON_ADD\") public class PersonMqListener implements RocketMQListener { @Override public void onMessage(Person person) { log.info(\"#PersonMqListener接收到消息，开始消费..name:\" + person.getName() + \",age:\" + person.getAge()); } } 同步有序的消息代码 package com.java.xval.val.common.listener; import lombok.extern.slf4j.Slf4j; import org.apache.rocketmq.spring.annotation.ConsumeMode; import org.apache.rocketmq.spring.annotation.RocketMQMessageListener; import org.apache.rocketmq.spring.core.RocketMQListener; import org.springframework.stereotype.Component; @Slf4j @Component @RocketMQMessageListener(topic = \"topic-orderly\", consumerGroup = \"orderly-consumer-group\", consumeMode = ConsumeMode.ORDERLY) public class OrderMqListener implements RocketMQListener { @Override public void onMessage(String s) { log.info(\"#OrderMqListener接收到消息，开始消费.message={}:\", s); } } 请求示例图 "},"chapter1/section9.html":{"url":"chapter1/section9.html","title":"1.9 RocketMQ分布式事务","keywords":"","body":"RocketMQ分布式事务 分布式事务概念 [!note] 1.在微服务架构下，由于数据库和应用服务的拆分，导致原本一个事务单元中的多个DML操作，变成了跨服务、跨数据库的多个事务单元的多个DML操作，而传统的数据库事务无法解决这类的问题，所以就引出了分布式事务的概念。 2.分布式事务本质上要解决的就是跨网络节点的多个事务的数据一致性问题，业内常见的解决方法有两种 （1）强一致性，就是所有的事务参与者要么全部成功，要么全部失败，全局事务协调者需要知道每个事务参与者的执行状态，再根据状态来决定数据的提交或者回滚！ （2）最终一致性，也叫弱一致性，也就是多个网络节点的数据允许出现不一致的情况，但是在最终的某个时间点会达成数据一致。基于CAP定理我们可以知道，强一致性方案对于应用的性能和可用性会有影响，所以对于数据一致性要求不高的场景，就会采用最终一致性算法。 3.在分布式事务的实现上，对于强一致性，我们可以通过基于XA协议下的二阶段提交来实现，对于弱一致性，可以基于TCC事务模型、消息队列模型等方案来实现。 4.市面上有很多针对这些理论模型实现的分布式事务框架，我们可以在应用中集成这些框架来实现分布式事务。 分布式事务就是指事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于不同的分布式系统的不同节点之上 简单的来说，就是一次大的操作由不同的小操作组成，这些小的操作那么全部成功，要么全部失败。分布式事务就是为了保证不同的数据库的数据一致性. 前言 目前分布式事务是还没有彻底的解决的难题，在考虑到实现方案前。需要考虑到当前项目是不是真的需要追求强的一致性。参考BASE理论，在分布式系统中，允许不同的服务节点在同步过程中存在延时，但可以经过一段时间修复，能达到数据的最终一致性。 **此文是依赖已有代码基础。本地代码已上传 [**远程仓库**](https://github.com/BenjaminFyang/javaVal.git) ** 强一致性 考虑XA协议，通过二阶段提交或者三阶段提交来保证。实现起来对代码侵入性比较强 最终一致性 考虑采用 TCC 模式，补偿模式，或者基于消息队列的模式。基于消息队列模式，可以采用 RocketMQ，下面我将介绍RocketMQ在分布式系统中事务中的使用。 **重点: Rocketmq考虑的是数据最终一致性。上游服务提交之后，下游服务最终只能成功，做不到回滚上游数据** 比如有个订单服务，订单服务下面存在积分服务、商品服务、优惠券服务等。下订单的同时需要通知积分服务增加积分、商品服务减少预售库存、去优惠券服务查询订单是否有可用的优惠券。使用消息队列最终一致性可能有这么一种情况，积分服务和优惠券服务调用成功，但是对应的后台服务商品库存不足为0扣减失败情况下、如何回滚订单、积分、优惠券服务数据。消息队列下游服务最终只能成功，做不到回滚上游数据。显然可以看出使用消息队列最终数据最终一致性，是存在使用局限的。 阿里开源的Seata 不过我个人安利推荐使用下阿里开源Seata，是一款开源的分布式事务解决方案，致力于提供高性能和简单易用的分布式事务服务。Seata 将为用户提供了AT、TCC、SAGA 和XA事务模式 麒麟系统架构图 如上图所示目前操作一次麒麟系统流程是需要跨各个不同的服务进行交互。要保证这些不同的系统之间操作的数据要么全部成功要么全部失败，控制好分布式事务是很重要的。下面主要是讲解RocketMQ事务分布式事务的处理原理和方式。 RocketMQ事务消息 Apache RocketMQ在4.3.0版中已经支持分布式事务消息，这里RocketMQ采用了2PC的思想来实现了提交事务消息，同时增加一个补偿逻辑来处理二阶段超时或者失败的消息，如下图所示 RocketMQ事务消息流程概要 上图说明了事务消息的大致方案, 其中分为两个流程: 正常事务消息的发送及提交、事务消息的补偿流程。 事务消息发送及提交 1、发送消息（half消息）. 2、服务端响应消息写入结果。 3、根据发送结果执行本地事务（如果写入失败，此时half消息对业务不可见，本地逻辑不执行） 4、根据本地事务状态执行Commit或者Rollback（Commit操作生成消息索引， 消息对消费者可见） 补偿流程 5、对没有Commit/Rollback的事务消息（pending状态的消息），定时任务从服务端发起一次“回查”。 6、Producer收到回查消息，检查回查消息对应的本地事务的状态。 7、根据本地事务状态，重新Commit或者Rollback。 其中、补偿阶段用于解决消息Commit或者Rollback发生超时或者失败的情况。 RocketMQ事务消息设计 一阶段：Prepared阶段（预备阶段）事务消息在一阶段对用户不可见 发送half消息，将备份原消息的主题与消息消费队列，然后改变主题为RMQ_SYS_TRANS_HALF_TOPIC 消费组未订阅该主题，故消费端无法消费half类型的消息，然后RocketMQ会开启一个定时任务，从Topic为RMQ_SYS_TRANS_HALF_TOPIC中拉取消息进行消费，根据生产者组获取一个服务提供者发送回查事务状态请求，根据事务状态来决定是提交或回滚消息。 二阶段：Commit和Rollback操作（确认阶段） Commit : 在完成一阶段写入一条对用户不可见的消息后，二阶段如果是Commit操作，则需要让消息对用户可见； Rollback : 需要撤销一阶段的消息。对于Rollback，本身一阶段的消息对用户是不可见的，其实不需要真正撤销消息。 RocketMQ 引入了Op消息 的概念，用Op消息标识事务消息已经确定状态 （Commit或者Rollback）。如果一条事务消息没有对应的Op消息，说明这个事务的状态还无法确定（可能是二阶段失败了）。引入Op消息后，事务消息无论是Commit或者Rollback都会记录一个Op操作。Commit相对于Rollback只是在写入Op消息前创建Half消息的索引（可以被消费者消费到）。 Op消息的存储和对应关系 RocketMQ将Op消息写入到全局一个特定的Topic中通过源码中的方法—TransactionalMessageUtil.buildOpTopic()；这个Topic是一个内部的Topic（像Half消息的Topic一样），不会被用户消费。Op消息的内容为对应的Half消息的存储的Offset，这样通过Op消息能索引到Half消息进行后续的回查操作. Half消息的索引构建 在执行二阶段Commmit操作时，需要构建出Half消息的消息的索引。一阶段的Half消息由于是写入到一个特殊的Topic，所以二阶段构建索引时需要读取出Half消息，并将Topic和Queue替换成真正的目标的Topic和Queue，之后通过一次普通的写入操作来生成一条对用户可见的消息。所以RocketMQ事务消息二阶段其实是利用了一阶段储存的消息的内容，在二阶段时恢复出一条完整的普通消息，然后走一遍消息写入流程。 如何处理二阶段失败的消息？ 如果在RocketMQ事务消息的二阶段过程中失败了, 例如在做Commit操作时，出现网络问题导致Commit失败，那么需要通过一定的策略使这条消息最终被Commit。RocketMQ采用了一种补偿机制，称为“回查”。Broker端对未确定状态的消息发起回查，将消息发送到对应的Producer端（同一个Group的Producer），由Producer根据消息来检查本地事务的状态，进而执行Commit或者Rollback。Broker端通过对比Half消息和Op消息进行事务消息的回查并且推进CheckPoint（记录那些事务消息的状态是确定的）。 **Rocketmq并不会无休止的的信息事务状态回查，默认回查15次，如果15次回查还是无法得知事务状态，rocketmq默认回滚该消息。** RocketMQ事务方案 下单流程示意图 下单代码就以 订单服务、积分服务为例子 首先看下具体的业务场景: 用户购买商品后，需要生成对应的订单和增加对应的会员积分 流程梳理 1、在下单之前，先发送预备消息 2、发送预备消息成功后, 执行本地下单事务 3、本地下单成功后，在发送确认消息 4、消息端（积分业务）可以看到确认消息，消费消息，进行增加积分 消息异常情况 异常一 发送预备消息失败，下面的流程不会走下去；这个是正常的 异常二 发送预备消息成功，但是执行本地事务失败；这个也是正常的，预备消息不会被消费端订阅到，消费端不会执行业务= 异常三 如果发送预备消息成功，执行本地事务成功，但是发送确认消息失败，这个就是问题。例: 用户下订单成功了，但是用户对应的积分却没有增加。出现了数据不一致 RocketMq回查 RocketMq利用了 状态回查来解决异常三出现的情况，也就是说RocketMq会定时遍历commitlog中的预备消息。 预备消息最终会变成变为commit消息或Rollback消息，在定时执行遍历预备消息回查本地业务的执行状态，如果发现本地业务没有执行成功就rollBack，如果执行成功就发送commit消息 对于上面的异常3，发送预备消息成功，本地就创建订单，但是发送确认消息失败；因为 RocketMq会进行回查预备消息，在回查过程中发现 本地的订单已经创建成功了，就补发发送commit确认消息，后续的积分系统就可以订阅到此消息了。同样在异常2的情况中发现本地订单事务没有执行成功，就会触发RollBack确认消息，把消息进行删除。 SpringBoot整合RocketMQ 订单服务 事务日志表 CREATE TABLE `transaction_log` ( `id` varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_bin NOT NULL COMMENT '事务ID', `business` varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_bin NOT NULL COMMENT '业务标识', `foreign_key` varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_bin NOT NULL COMMENT '对应业务表中的主键', PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin; transaction_log主要是用于事务的回查。当提交业务数据时候，会向这张表也插入一条数据。是出于同一个本地的事务中。通过事务ID查询该表，如果返回记录，则证明本地事务已提交；如果未返回记录，则本地事务可能是未知状态或者是回滚状态。 事务发送实例 主要就是创建事务消息的发送者。在这里，我们重点关注 OrderTransactionListener，它负责执行本地事务和事务状态回查。 package com.java.xval.val.mq; import com.java.xval.val.service.listenerTransaction.OrderTransactionListener; import org.springframework.stereotype.Component; import javax.annotation.PostConstruct; import javax.annotation.Resource; import java.util.concurrent.ArrayBlockingQueue; import java.util.concurrent.ExecutorService; import java.util.concurrent.ThreadPoolExecutor; import java.util.concurrent.TimeUnit; /** * 订单事务监听器. */ @Component public class OrderTransactionProducer extends TransactionProducer { // 用于执行本地事务和事务状态回查的监听器 需要自定义事务监听器 用于事务的二次确认和事务回查 @Resource private OrderTransactionListener orderTransactionListener; // 官方建议自定义线程 给线程取自定义名称 发现问题更好排查 private final ExecutorService executorService = new ThreadPoolExecutor(2, 5, 100, TimeUnit.SECONDS, new ArrayBlockingQueue<>(200), r -> { Thread thread = new Thread(r); thread.setName(\"client-transaction-producer-check-thread\"); return thread; }); // Spring容器启动的时候初始化订单事务监听器. @PostConstruct public void buildInit() { init(orderTransactionListener, executorService); } } package com.java.xval.val.mq; import com.java.xval.val.common.config.RocketMqDataConfig; import org.apache.rocketmq.client.exception.MQClientException; import org.apache.rocketmq.client.producer.TransactionListener; import org.apache.rocketmq.client.producer.TransactionMQProducer; import org.apache.rocketmq.client.producer.TransactionSendResult; import org.apache.rocketmq.common.message.Message; import org.springframework.stereotype.Component; import javax.annotation.Resource; import java.util.concurrent.ExecutorService; @Component public class TransactionProducer { private TransactionMQProducer transactionMQProducer; @Resource private RocketMqDataConfig rocketMqDataConfig; /** * 启动监听器 * * @param transactionListener 事务监听器 * @param executorService 自定义线程池 */ public void init(TransactionListener transactionListener, ExecutorService executorService) { transactionMQProducer = new TransactionMQProducer(rocketMqDataConfig.getOrderTopic()); transactionMQProducer.setNamesrvAddr(rocketMqDataConfig.getNameServer()); transactionMQProducer.setSendMsgTimeout(Integer.MAX_VALUE); transactionMQProducer.setExecutorService(executorService); transactionMQProducer.setTransactionListener(transactionListener); this.start(); } /** * 启动 * 对象在使用之前必须要调用一次，只能初始化一次 */ private void start() { try { this.transactionMQProducer.start(); } catch (MQClientException e) { e.printStackTrace(); } } /** * 事务消息发送 * * @param data 消息发送对象. * @param topic 消息队列的主题. * @return the TransactionSendResult * @throws MQClientException 对应的异常的抛出. */ public TransactionSendResult send(String data, String topic) throws MQClientException { Message message = new Message(topic, data.getBytes()); return this.transactionMQProducer.sendMessageInTransaction(message, null); } } 自定义事务监听器 package com.java.xval.val.service.listenerTransaction; import com.alibaba.fastjson.JSON; import com.alibaba.fastjson.JSONObject; import com.java.xval.val.model.Order; import com.java.xval.val.service.OrderService; import com.java.xval.val.service.TransactionLogService; import org.apache.commons.lang3.StringUtils; import org.apache.rocketmq.client.producer.LocalTransactionState; import org.apache.rocketmq.client.producer.TransactionListener; import org.apache.rocketmq.common.message.Message; import org.apache.rocketmq.common.message.MessageExt; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.stereotype.Component; import javax.annotation.Resource; /** * 订单分布式事务RocketMQ 生产者 */ @Component public class OrderTransactionListener implements TransactionListener { @Resource private OrderService orderService; @Resource private TransactionLogService transactionLogService; Logger logger = LoggerFactory.getLogger(this.getClass()); @Override public LocalTransactionState executeLocalTransaction(Message message, Object o) { // 本地事务执行会有三种可能 // 1、commit 成功 // 2、Rollback 失败 // 3、网络等原因服务宕机收不到返回结果 // 执行创建订单的本地事务，这里完成订单数据和事务日志的插入. logger.info(\"OrderTransactionListener开始执行本地事务message={}....\", JSON.toJSONString(message)); LocalTransactionState state; try { String body = new String(message.getBody()); Order order = JSONObject.parseObject(body, Order.class); orderService.create(order, message.getTransactionId()); state = LocalTransactionState.COMMIT_MESSAGE; logger.info(\"OrderTransactionListener本地事务已提交。{}\", message.getTransactionId()); } catch (Exception e) { logger.info(\"OrderTransactionListener执行本地事务失败\", e); state = LocalTransactionState.ROLLBACK_MESSAGE; } return state; } /** * 只有上面接口返回 LocalTransactionState.UNKNOW 才会调用查接口被调用 * * @param messageExt the messageExt * @return LocalTransactionState 事务状态. * @see org.apache.rocketmq.client.producer.LocalTransactionState */ @Override public LocalTransactionState checkLocalTransaction(MessageExt messageExt) { // 因为有种情况就是：上面本地事务执行成功了，但是return LocalTransactionState.COMMIT_MESSAG的时候服务挂了，那么最终 Brock还未收到消息的二次确定，还是个预消息，所以当重新启动的时候还是回调这个回调接口。 // 如果不先查询上面本地事务的执行情况 直接在执行本地事务，那么就相当于成功执行了两次本地事务了。 logger.info(\"OrderTransactionListener开始回查本地事务状态{}\", messageExt.getTransactionId()); LocalTransactionState state; String transactionId = messageExt.getTransactionId(); if (StringUtils.isNotBlank(transactionLogService.get(transactionId))) { state = LocalTransactionState.COMMIT_MESSAGE; } else { state = LocalTransactionState.UNKNOW; } logger.info(\"OrderTransactionListener结束本地事务状态查询：{}\", state); return state; } } 通过transactionMQProducer.sendMessageInTransaction消息发送成功后，会调用executeLocalTransaction(Message message, Object o)方法，执行本地事务，订单数据和事务日志在这里完成插入. LocalTransactionState本地事务状态枚举解析 1、COMMIT_MESSAGE: 提交事务消息，消费者可以看到此消息 2、ROLLBACK_MESSAGE: 回滚事务消息，消费者不会看到此消息 3、UNKNOW: 事务未知状态，需要调用事务状态回查，确定此消息是提交还是回滚 checkLocalTransaction(MessageExt messageExt)方法就是用于事务状态的查询，上面的例子中通过事务的ID查询表transaction_log，如果可以查询到结果，就提交事务消息；如果没有查询到，就返回事务未知状态。 业务订单实现类 package com.java.xval.val.service.impl; import com.alibaba.fastjson.JSON; import com.java.xval.val.mapper.OrderMapper; import com.java.xval.val.mapper.TransactionLogMapper; import com.java.xval.val.model.Order; import com.java.xval.val.model.TransactionLog; import com.java.xval.val.mq.MqConstant; import com.java.xval.val.mq.OrderTransactionProducer; import com.java.xval.val.service.OrderService; import org.apache.rocketmq.client.exception.MQClientException; import org.apache.rocketmq.client.producer.TransactionSendResult; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.stereotype.Service; import org.springframework.transaction.annotation.Transactional; import javax.annotation.Resource; /** * 订单业务实现类 */ @Service public class OrderServiceImpl implements OrderService { private static final Logger LOGGER = LoggerFactory.getLogger(OrderServiceImpl.class); @Resource private OrderMapper orderMapper; @Resource private TransactionLogMapper transactionLogMapper; @Resource private OrderTransactionProducer orderTransactionProducer; Logger logger = LoggerFactory.getLogger(this.getClass()); @Override @Transactional(rollbackFor = Exception.class) public void create(Order order, String transactionId) { LOGGER.info(\"OrderServiceImpl开始进行下单的操作={},transactionId={}\", JSON.toJSONString(order), transactionId); // 1、本应用创建订单 orderMapper.create(order); // 2.写入事务日志 TransactionLog log = new TransactionLog(); log.setId(transactionId); log.setBusiness(MqConstant.Top.USER_ORDER_TOPIC); log.setForeignKey(String.valueOf(order.getId())); transactionLogMapper.insert(log); logger.info(\"OrderServiceImpl订单创建完成={}\", order); } @Override public void createOrder(Order order) throws MQClientException { TransactionSendResult transactionSendResult = orderTransactionProducer.send(JSON.toJSONString(order), MqConstant.Top.USER_ORDER_TOPIC); transactionSendResult.getSendStatus(); } } 积分系统 积分对应的订单的消费者监听启动 package com.java.xval.val.mq; import com.java.xval.val.common.config.RocketMqDataConfig; import com.java.xval.val.service.listenerTransaction.PointTransactionListener; import org.apache.rocketmq.client.consumer.DefaultMQPushConsumer; import org.apache.rocketmq.client.exception.MQClientException; import org.springframework.stereotype.Component; import javax.annotation.PostConstruct; import javax.annotation.Resource; /** * 订单消费者监听 */ @Component public class PointProductConsumer { @Resource private RocketMqDataConfig rocketMqDataConfig; @Resource private PointTransactionListener orderListener; @PostConstruct public void init() throws MQClientException { DefaultMQPushConsumer defaultMQPushConsumer = new DefaultMQPushConsumer(MqConstant.ConsumeGroup.USER_ORDER_GROUP); defaultMQPushConsumer.setNamesrvAddr(rocketMqDataConfig.getNameServer()); defaultMQPushConsumer.subscribe(MqConstant.Top.USER_ORDER_TOPIC, \"*\"); defaultMQPushConsumer.registerMessageListener(orderListener); defaultMQPushConsumer.start(); } } 需要指定一个消费的topic和监听器就好了. 积分消费者监听器 package com.java.xval.val.service.listenerTransaction; import com.alibaba.fastjson.JSONObject; import com.java.xval.val.model.Order; import org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyContext; import org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyStatus; import org.apache.rocketmq.client.consumer.listener.MessageListenerConcurrently; import org.apache.rocketmq.common.message.MessageExt; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.stereotype.Component; import java.util.List; @Component public class PointTransactionListener implements MessageListenerConcurrently { Logger logger = LoggerFactory.getLogger(this.getClass()); @Override public ConsumeConcurrentlyStatus consumeMessage(List list, ConsumeConcurrentlyContext context) { logger.info(\"消费者线程监听到消息。\"); try { for (MessageExt message : list) { logger.info(\"开始处理订单数据，准备增加积分....\"); Order order = JSONObject.parseObject(message.getBody(), Order.class); if (!processor(message)) { return ConsumeConcurrentlyStatus.RECONSUME_LATER; } // todo 开始插入对应的积分数据. logger.info(\"开始插入积分数据，增加积分....\"); } return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; } catch (Exception e) { logger.error(\"处理消费者数据发生异常\", e); return ConsumeConcurrentlyStatus.RECONSUME_LATER; } } /** * 消息处理，第3次处理失败后，发送邮件或者短信通知人工介入 * * @param message the message * @return boolean */ private boolean processor(MessageExt message) { String body = new String(message.getBody()); try { logger.info(\"PointTransactionListener消息处理....{}\", body); int k = 1 / 0; return true; } catch (Exception e) { if (message.getReconsumeTimes() >= 3) { logger.error(\"PointTransactionListener消息重试已达最大次数，将通知业务人员排查问题。{}\", message.getMsgId()); // todo 发送短信或者邮件通知. return true; } return false; } } } 幂等性 1、执行前可以先查询此订单是否已经执行过 2、额外增加一张表来进行记录 3、放到redis缓存里，在入库之前先查询缓存 消费异常 消费者处理失败后会返回 RECONSUME_LATER ，让消息来重试，默认最多重试16次 可以在消费者端设置这个次数。 //设置消息重试最大次数 consumer.setMaxReconsumeTimes(3); 查看RocketMQ控制台情况 重点 RocketMQ处理事务的局限性 1、Rocketmq考虑的是数据最终一致性。上游服务提交之后，下游服务最终只能成功，做不到回滚上游数据。 2、创建订单➕扣减库存，比如producer端是订单的创建，创建好发送消息到库存服务，库存扣减，但是库存为0扣减失败。这个时候RocketMQ是不支持数据TCC回滚的。针对这样的情况可以考虑使用阿里的Seata "},"chapter1/section10.html":{"url":"chapter1/section10.html","title":"1.10 DDD领域驱动架构模型分析","keywords":"","body":"DDD领域驱动架构模型分析 [!note] 目前公司都是做业务开发的，基本上采用的是基于MVC三层架构模式开发的。虽然这种开发已经成为标准的Web项目开发模式。但是违反面向对象编程风格，也是一种面向过程的编程风格。 微服务除了监控、调用链追踪、API 网关等服务治理系统的开发之外，微服务还有另外一个更加重要的工作，那就是针对公司的业务，合理地做微服务拆分。而领域驱动设计恰好就是用来指导划分服务的。所以，微服务加速了领域驱动设计的盛行。 贫血模式传统开发 目前采用的前后端分离的，后端负责暴露接口给前端调用。这种情况下，一般就将后端项目分为 Repository 层、Service层、Controller层。其中，Repository层负责数据访问，Service层负责业务逻辑，Controller层负责暴露接口。目前几乎已有的业务后端系统，都是基于贫血模型。如下 public class UserController { private UserService userService; public UserVo getUserById(Long userId) { UserBo userBo = userService.getUserById(userId); UserVo userVo = ... ; return userVo; } } public class UserVo { //省略其他属性、get/set/construct方法 private Long id; private String name; private String cellphone; } @Service public class UserService { @Resource private UserRepository userRepository; public UserBo getUserById(Long userId) { UserEntity userEntity = userRepository.getUserById(userId); UserBo userBo = [...convert userEntity to userBo...]; return userBo; } } public class UserBo { private Long id; private String name; private String cellphone; } public class UserRepository { public UserEntity getUserById(Long userId) { //... } } public class UserEntity { private Long id; private String name; private String cellphone; } 代码结构分析 像上面的UserBO这样，只包含数据，不包含逻辑的类。就叫做贫血模式。UserEntity、UserVo都是贫血模型设计，这种贫血模型将数据鱼操作分析，破坏了面向对象的封装特性。就是一种面向过程的编程风格. 基于充血模型DDD开发模式 1、充血模型 充血模型就是将数据和对应的业务逻辑封装到同一个类中。这种充血模型满足面向对象的封装特性，是面向对象编程风格. 2、领域模型设计 领域模型设计，即DDD,主要是用来指导如何解耦业务系统，划分业务模块，定义业务领域模型及其交互。比如微服务就是基于这一个概念兴起。 微服务除了监控、调用链追踪、API 网关等服务治理系统的开发之外，微服务还有另外一个更加重要的工作，那就是针对公司的业务，合理地做微服务拆分。而领域驱动设计恰好就是用来指导划分服务的。所以，微服务加速了领域驱动设计的盛行。 领域模型驱动设计是需要对业务熟悉程度。即使对领域驱动了解的再清楚，但是对业务不熟悉，也不一定做出合理的领域设计。 3、基于充血模型的DDD开发 充血模型的DDD开发模式也是按照MVC三层架构分层。他跟基于贫血模型的传统开发模式的区别主要是在Service层。 在基于充血模型的 DDD 开发模式中，Service层包含Service类和Domain类两部分。Domain 就相当于贫血模型中的 BO。Domain与BO的区别在于它是基于充血模型开发的，既包含数据，也包含业务逻辑。而 Service 类变得非常单薄. 总结: 基于贫血模型的传统的开发模式，重Service轻BO；基于充血模型的DDD开发模式，轻Service重Domain。 项目中应该如何使用基于充血模型的DDD开发模式 贫血模式比较适合业务表简单的系统开发。相对应的，基于充血模型的DDD开发模式，更适合业务负责的系统开发。比如社保计算模型，订单付款等复杂的金融财务系统。 现有的开发模式解析 1、大部分开发人员都是SQL驱动（SQL-Driven）开发模式。 2、后端接到接口的开发需求时候，首先查看需要对应的数据库，需要那些表，然后思考如何编写SQL语句来获取数据。之后就是定义 Entity、BO、VO，然后模板式地往对应的 Repository、Service、Controller类中添加代码。 3、在这个过程中，很少会去应用领域模型，OOP(面向对象)的概念，所以很少有代码复用的想法。对于复杂业务系统开发，这样开发模式会让代码越来月混乱，最后导致无法维护。 4、敏捷开发导致项目开发前期缺少完整的业务调研、需求调研、系统之间的流程梳理。各个业务模型建立（对象建模、用例分析）的缺失。然后在业务模块划分是混淆。敏捷开发削弱这个职责，只基于流程表面场景去分析。导致模块耦合严重。 DDD架构模型优势 1、在这种模型的开发下，需要先理清楚相应的业务，定义领域模型所包含的属性和方法。领域模型相当于可服用的业务中间层。 2、复杂系统，对代码的复用性、易维护性要求就越高，需要花费更多的时间和精力在前期的设计上。充血模式的DDD开发模式，正需要前期做大量业务调研、领域模型设计，所以更合适复杂系统的开发。业务流程和场景变化的时候，很难去应对这种变更或者是扩展 项目实战 设计一个钱包的功能，支持用户充值、提现、支付、冻结、透支、转增、查询账户余额、查询交易流水等操作。 DDD领域模型代码demo 钱包VirtualWallet类设计成一个充血的 Domain 领域模型，并且将原来在 Service 类中的部分业务逻辑移动到 VirtualWallet 类中 // Domain领域模型（充血模型） @Data public class VirtualWallet { private Long id; private Long createTime = System.currentTimeMillis(); private BigDecimal balance = BigDecimal.ZERO; // 是否允许透支 private boolean isAllowedOverdraft = true; // 可透支金额 private BigDecimal overdraftAmount = BigDecimal.ZERO; // 冻结金额 private BigDecimal frozenAmount = BigDecimal.ZERO; public VirtualWallet() { } public VirtualWallet(Long preAllocatedId) { this.id = preAllocatedId; } /** * 冻结 * * @param amount 冻结金额 */ public void freeze(BigDecimal amount) { } public void unfreeze(BigDecimal amount) { // todo } /** * 增加透支金额 * * @param amount 金额 */ public void increaseOverdraftAmount(BigDecimal amount) { // todo } /** * 减少透支金额 * * @param amount 金额 */ public void decreaseOverdraftAmount(BigDecimal amount) { // todo } /** * 关闭信用度透支 */ public void closeOverdraft() { // todo } /** * 打开信用度透支 */ public void openOverdraft() { // todo } public BigDecimal balance() { return this.balance; } /** * 获得账户的余额 * * @return 余额 */ public BigDecimal getAvailableBalance() { BigDecimal totalAvailableBalance = this.balance.subtract(this.frozenAmount); if (isAllowedOverdraft) { totalAvailableBalance = this.overdraftAmount.add(totalAvailableBalance); } return totalAvailableBalance; } /** * 出账 开始扣减金额. * * @param amount 剩余账户的余额 */ public void debit(BigDecimal amount) { BigDecimal totalAvailableBalance = getAvailableBalance(); if (totalAvailableBalance.compareTo(amount) 领域模型说明 [!note] 在领域模型VirtualWallet类中可以实现冻结钱包、解冻钱包、增加透支金额、减少透支金额、打开信用度透支、关闭信用度透支、获得账户的余额、扣减金额等逻辑。随着业务功能的迭代扩张，可以细化透支金额和冻结的策略。也就值得设计成充血模型. 充血模型的 DDD 开发模式中，将业务逻辑移动到 Domain 中，Service 类变得很薄。 负责余数据层Repository交互（从 DB 中取数据、映射数据） 负责跨领域模型的业务聚合功能 负责一些非功能性及与三方系统交互的工作（幂等、事务、发邮件、发消息、记录日志、RPC 接口） 总结 1、DDD模型将原来重的service逻辑转移到 Domain领域层中，可以是代码可读性提升。 2、模型充血后，基于模型业务在后续的迭代中越发明确，细节也会越开越精确。通过充血后的代码，能够快速了解模块业务，提升开发效率。 3、在维护性上来说，如果项目新进了开发人员。充血模型，直接阅读充血模型的行为方法，起码能够很快理解70%左右的业务逻辑，因为充血模型可以说是业务的精准抽象，也就是领域驱动DDD模式带来的效果。 "},"chapter1/section11.html":{"url":"chapter1/section11.html","title":"1.11 分布式日志链路跟踪","keywords":"","body":"分布式日志链路跟踪 🎨 需求场景 目前开发排查问题用的比较多的就是系统日志，在分布式环境中使用 ELK 来统一手机日志，但是在并发大时候使用日志定位比较麻烦。大量的用户、其他线程、定时器、消息队列也在一起输出很难筛选出指定的日志，以及下游线程、服务对应的日志. 参考: https://github.com/alibaba/transmittable-thread-local 👉 解决方式 每个请求都使用一个唯一标识来追踪全部的链路显示在日志中，并且不修改原有的打印方式(代码无入侵) 使用Logback的MDC机制日志模板中加入traceId标识，取值方式为%X{traceId} [!note] MDC（Mapped Diagnostic Context，映射调试上下文）是log4j和logback提供的一种方便在多线程条件下记录日志的功能。MDC 可以看成是一个与当前线程绑定的Map，可以往其中添加键值对。MDC中包含的内容可以被同一线程中执行的代码所访问。当前线程的子线程会继承其父线程中的 MDC 的内容。当需要记录日志时，只需要从MDC中获取所需的信息即可。MDC 的内容则由程序在适当的时候保存进去。对于一个 Web 应用来说，通常是在请求被处理的最开始保存这些数据。 🔨 实现方式 由于MDC内部使用的是ThreadLocal所以只有本线程才有效，子线程和下游的服务MDC里的值会丢失；所以方案主要的难点是解决值的传递问题，主要包括以几下部分： API网关中的MDC数据怎么传递给下游. 微服务之前调用其他远程服务如何传递接受数据. 异步情况下（线程池）怎么样传递给子线程. 消息队列生产者与消费者怎么传递和接受消息. 查看项目结构 . |-- HELP.md |-- seata-service | |-- accountService (账号微服务) | |-- orderService （订单微服务） | `-- storageService（库存微服务） |-- traceId-commons (工具包) | |-- traceId-common-core （核心工具类） | `-- traceId-log-springCloud-starter （日志工具类） |-- traceId-eureka（注册中心） | |-- traceId-gateway（网关微服务） | `-- traceId-loadbalancer（负载均衡） 1、增加日志模版 logback配置文件日志格式添加该标识 [%X{traceId}] 2、APIGateWay网关增加过滤器 生成traceId并通过header传递给下游服务 package com.example.traceidgateway.filter; import cn.hutool.core.util.IdUtil; import com.central.common.constant.CommonConstant; import com.central.log.properties.TraceProperties; import org.slf4j.MDC; import org.springframework.cloud.gateway.filter.GatewayFilterChain; import org.springframework.cloud.gateway.filter.GlobalFilter; import org.springframework.core.Ordered; import org.springframework.http.server.reactive.ServerHttpRequest; import org.springframework.stereotype.Component; import org.springframework.web.server.ServerWebExchange; import reactor.core.publisher.Mono; import javax.annotation.Resource; /** * 生成日志链路追踪id，并传入header中 */ @Component public class TraceFilter implements GlobalFilter, Ordered { @Resource private TraceProperties traceProperties; @Override public Mono filter(ServerWebExchange exchange, GatewayFilterChain chain) { // 判断是否开启了链路追踪. if (traceProperties.getEnable()) { //链路追踪id String traceId = IdUtil.fastSimpleUUID(); MDC.put(CommonConstant.LOG_TRACE_ID, traceId); ServerHttpRequest serverHttpRequest = exchange.getRequest().mutate() .headers(h -> h.add(CommonConstant.TRACE_ID_HEADER, traceId)) .build(); ServerWebExchange build = exchange.mutate().request(serverHttpRequest).build(); return chain.filter(build); } return chain.filter(exchange); } @Override public int getOrder() { // Spring IOC容器中Bean的执行顺序的优先级 return Ordered.HIGHEST_PRECEDENCE; } } 3、下游微服务增加拦截器 接收并保存traceId的值 package com.central.log.trace; import com.central.log.properties.TraceProperties; import org.springframework.boot.autoconfigure.condition.ConditionalOnClass; import org.springframework.core.annotation.Order; import org.springframework.util.StringUtils; import org.springframework.web.filter.OncePerRequestFilter; import javax.annotation.Resource; import javax.servlet.FilterChain; import javax.servlet.ServletException; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; import java.io.IOException; /** * web过滤器，生成日志链路追踪id，并赋值MDC */ @ConditionalOnClass(value = {HttpServletRequest.class, OncePerRequestFilter.class}) @Order(value = MDCTraceUtils.FILTER_ORDER) public class WebTraceFilter extends OncePerRequestFilter { @Resource private TraceProperties traceProperties; @Override protected boolean shouldNotFilter(HttpServletRequest request) { return !traceProperties.getEnable(); } @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain filterChain) throws IOException, ServletException { try { String traceId = request.getHeader(MDCTraceUtils.TRACE_ID_HEADER); if (StringUtils.isEmpty(traceId)) { MDCTraceUtils.addTraceId(); } else { MDCTraceUtils.putTraceId(traceId); } filterChain.doFilter(request, response); } finally { MDCTraceUtils.removeTraceId(); } } } 4、下游服务增加feign拦截器 package com.central.log.trace; import com.central.log.properties.TraceProperties; import feign.RequestInterceptor; import feign.RequestTemplate; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.util.StringUtils; import javax.annotation.Resource; /** * @see https://cloud.tencent.com/developer/article/1600718 * Feign的拦截器RequestInterceptor * SpringCloud的微服务使用Feign进行服务间调用的时候可以使用RequestInterceptor统一拦截请求来完成设置header等相关请求， */ public class FeignTraceInterceptor implements RequestInterceptor { private static final Logger LOGGER = LoggerFactory.getLogger(FeignTraceInterceptor.class); @Resource private TraceProperties traceProperties; @Override public void apply(RequestTemplate requestTemplate) { LOGGER.info(\"FeignTraceInterceptor.request: {}\", requestTemplate.url()); if (traceProperties.getEnable()) { //传递日志traceId String traceId = MDCTraceUtils.getTraceId(); if (!StringUtils.isEmpty(traceId)) { requestTemplate.header(MDCTraceUtils.TRACE_ID_HEADER, traceId); } } } } 5、解决父子线程传递问题 主要针对业务会使用线程池(异步、并行处理) 重写logback的LogbackMDCAdapter 由于logback的MDC实现内部使用的是ThreadLocal不能传递子线程，所以需要重写替换为阿里的TransmittableThreadLocal。TransmittableThreadLocal 是Alibaba开源的、用于解决 “在使用线程池等会缓存线程的组件情况下传递ThreadLocal” 问题的 https://github.com/alibaba/transmittable-thread-local /** * 重构{@link LogbackMDCAdapter}类，搭配TransmittableThreadLocal实现父子线程之间的数据传递 */ public class TtlMDCAdapter implements MDCAdapter { private final ThreadLocal> copyOnInheritThreadLocal = new TransmittableThreadLocal<>(); private static final int WRITE_OPERATION = 1; private static final int MAP_COPY_OPERATION = 2; private static TtlMDCAdapter mtcMDCAdapter; /** * keeps track of the last operation performed */ private final ThreadLocal lastOperation = new ThreadLocal<>(); static { mtcMDCAdapter = new TtlMDCAdapter(); MDC.mdcAdapter = mtcMDCAdapter; } public static MDCAdapter getInstance() { return mtcMDCAdapter; } } TtlMDCAdapterInitializer类用于程序启动时加载自己的mdcAdapter实现 /** * 初始化TtlMDCAdapter实例，并替换MDC中的adapter对象 */ public class TtlMDCAdapterInitializer implements ApplicationContextInitializer { @Override public void initialize(ConfigurableApplicationContext applicationContext) { //加载TtlMDCAdapter实例 TtlMDCAdapter.getInstance(); } } 扩展线程池实现 package com.example.orderservice.thread; import com.alibaba.ttl.threadpool.TtlExecutors; import com.central.common.utils.CustomThreadPoolTaskExecutor; import com.google.common.util.concurrent.ThreadFactoryBuilder; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor; import java.util.concurrent.ArrayBlockingQueue; import java.util.concurrent.ExecutorService; import java.util.concurrent.ThreadFactory; import java.util.concurrent.TimeUnit; /** * * * @author fangyang * @since 1.0.0 */ @Configuration public class TreadPoolConfig { // 核心线程数 private static final int CORE_POOL_SIZE = 5; // 最大的线程数. private static final int MAX_POOL_SIZE = 20; // 最大的的队列的数量. private static final int QUEUE_CAPACITY = 30000; // 线程生存时间. private static final Long KEEP_ALIVE_TIME = 3L; /** * 政策包导入初始化全局的线程池. * 初始化一个全局的线程池. * * @return the ExecutorService */ @Bean(value = \"consumerQueueThreadPool\") public ExecutorService buildConsumerQueueThreadPool() { ThreadFactory namedThreadFactory = new ThreadFactoryBuilder(). setNameFormat(\"consumer-queue_one-thread-%d\") .build(); ExecutorService executorService = buildExecutor(namedThreadFactory); return TtlExecutors.getTtlExecutorService(executorService); } private static ExecutorService buildExecutor(ThreadFactory namedThreadFactory) { // 通过ThreadPoolExecutor构造函数自定义参数创建 // 当任务添加到线程池中被拒绝时，会在线程池当前正在运行的Thread线程池中处理被拒绝的任务。 return ExecutorBuilder.create().setCorePoolSize(CORE_POOL_SIZE) .setMaxPoolSize(MAX_POOL_SIZE) .setKeepAliveTime(KEEP_ALIVE_TIME, TimeUnit.MINUTES) .setWorkQueue(new ArrayBlockingQueue<>(QUEUE_CAPACITY)) .setThreadFactory(namedThreadFactory) .setHandler(RejectPolicyEnum.ABORT.getValue()) .build(); } } 6、消息队列传递问题 消息队列模版抽象类 package com.example.traceIdRocketmq.template; import com.alibaba.fastjson.JSON; import com.central.common.constant.CommonConstant; import com.central.log.trace.MDCTraceUtils; import org.apache.rocketmq.common.message.MessageExt; import org.apache.rocketmq.spring.core.RocketMQListener; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import java.nio.charset.StandardCharsets; public abstract class AbstractRocketListener implements RocketMQListener { private final Class tClass; public AbstractRocketListener(Class tClass) { this.tClass = tClass; } private final Logger logger = LoggerFactory.getLogger(getClass()); @Override public void onMessage(MessageExt messageExt) { String traceId = messageExt.getProperty(CommonConstant.TRACE_ID_HEADER); MDCTraceUtils.putTraceId(traceId); String body = new String(messageExt.getBody(), StandardCharsets.UTF_8); logger.info(\"Consumer-获取消息-主题topic为={}, 消费消息为={}\", messageExt.getTopic(), body); doJob(JSON.parseObject(body, tClass)); } /** * 模版方法 业务消息处理 * * @param t the Object */ public abstract void doJob(T t); } 消息队列接受实现类 package com.example.orderservice.rocketMqConsumer; import com.alibaba.fastjson.JSON; import com.example.orderservice.domain.Demo01Message; import com.example.orderservice.domain.Order; import com.example.traceIdRocketmq.template.AbstractRocketListener; import org.apache.rocketmq.spring.annotation.RocketMQMessageListener; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.stereotype.Component; @Component @RocketMQMessageListener(topic = Demo01Message.TOPIC, consumerGroup = \"demo01-consumer-group-\" + Demo01Message.TOPIC) public class Demo01Consumer extends AbstractRocketListener { private final Logger logger = LoggerFactory.getLogger(getClass()); public Demo01Consumer() { super(Order.class); } @Override public void doJob(Order body) { logger.info(\"接受到消息通知order={}\", JSON.toJSONString(body)); } } 🔌 测试场景 测试代码如下 api网关打印的日志 [seata-order-service:192.168.130.167:8180] 2021-12-02 14:09:44.122 INFO 37872 [E38DA5A1E9DA40EBB249CFE6612CC49C] [consumer-queue_one-thread-0] c.e.o.service.impl.OrderServiceImpl 11下单异步数据统计 [seata-order-service:192.168.130.167:8180] 2021-12-02 14:09:44.122 INFO 37872 [E38DA5A1E9DA40EBB249CFE6612CC49C] [consumer-queue_one-thread-2] c.e.o.service.impl.OrderServiceImpl 11下单异步数据统计 [seata-order-service:192.168.130.167:8180] 2021-12-02 14:09:44.122 INFO 37872 [E38DA5A1E9DA40EBB249CFE6612CC49C] [consumer-queue_one-thread-1] c.e.o.service.impl.OrderServiceImpl 11下单异步数据统计 [seata-order-service:192.168.130.167:8180] 2021-12-02 14:09:44.123 INFO 37872 [E38DA5A1E9DA40EBB249CFE6612CC49C] [http-nio-8180-exec-1] c.e.o.service.impl.OrderServiceImpl integerList=[22, 22, 22] [seata-order-service:192.168.130.167:8180] 2021-12-02 14:09:44.147 INFO 37872 [E38DA5A1E9DA40EBB249CFE6612CC49C] [http-nio-8180-exec-1] c.e.t.template.RocketMQTemplateProducer 同步发送消息完成：message = Order(id=null, userId=22, productId=null, count=null, money=22, status=2), sendResult = SendResult [sendStatus=SEND_OK, msgId=7F00000193F018B4AAC2083050BB001F, offsetMsgId=AC10101E00002A9F00000000001BA574, messageQueue=MessageQueue [topic=DEMO_01, brokerName=broker-a, queueId=0], queueOffset=21] [seata-order-service:192.168.130.167:8180] 2021-12-02 14:09:44.147 INFO 37872 [E38DA5A1E9DA40EBB249CFE6612CC49C] [http-nio-8180-exec-1] c.e.o.service.impl.OrderServiceImpl ------->下单开始 [seata-order-service:192.168.130.167:8180] 2021-12-02 14:09:44.147 INFO 37872 [E38DA5A1E9DA40EBB249CFE6612CC49C] [http-nio-8180-exec-1] c.e.o.service.impl.OrderServiceImpl ------->order-service中创建订单 [seata-order-service:192.168.130.167:8180] 2021-12-02 14:09:44.147 INFO 37872 [E38DA5A1E9DA40EBB249CFE6612CC49C] [http-nio-8180-exec-1] c.e.o.service.impl.OrderServiceImpl ------->order-service中扣减库存开始 [seata-order-service:192.168.130.167:8180] 2021-12-02 14:09:44.147 INFO 37872 [E38DA5A1E9DA40EBB249CFE6612CC49C] [http-nio-8180-exec-1] c.c.log.trace.FeignTraceInterceptor FeignTraceInterceptor.request: /storage/decrease [seata-order-service:192.168.130.167:8180] 2021-12-02 14:09:44.147 INFO 37872 [E38DA5A1E9DA40EBB249CFE6612CC49C] [ConsumeMessageThread_6] c.e.o.rocketMqConsumer.Demo01Consumer Consumer-获取消息-主题topic为=DEMO_01, 消费消息为={\"id\":null,\"userId\":22,\"productId\":null,\"count\":null,\"money\":22,\"status\":2} [seata-order-service:192.168.130.167:8180] 2021-12-02 14:09:44.147 INFO 37872 [E38DA5A1E9DA40EBB249CFE6612CC49C] [ConsumeMessageThread_6] c.e.o.rocketMqConsumer.Demo01Consumer 接受到消息通知order={\"money\":22,\"status\":2,\"userId\":22} [seata-order-service:192.168.130.167:8180] 2021-12-02 14:09:47.158 INFO 37872 [E38DA5A1E9DA40EBB249CFE6612CC49C] [http-nio-8180-exec-1] c.e.feignokhttp.MyOkhttpInterceptor 接收响应: [http://192.168.130.167:8181/storage/decrease] 返回json:【{\"code\":200,\"message\":\"操作成功\",\"data\":\"扣减库存成功！\"}】 3010.2ms [seata-order-service:192.168.130.167:8180] 2021-12-02 14:09:47.159 INFO 37872 [E38DA5A1E9DA40EBB249CFE6612CC49C] [http-nio-8180-exec-1] c.e.o.service.impl.OrderServiceImpl ------->order-service中扣减库存结束 [seata-order-service:192.168.130.167:8180] 2021-12-02 14:09:47.159 INFO 37872 [E38DA5A1E9DA40EBB249CFE6612CC49C] [http-nio-8180-exec-1] c.e.o.service.impl.OrderServiceImpl ------->order-service中扣减余额开始 [seata-order-service:192.168.130.167:8180] 2021-12-02 14:09:47.159 INFO 37872 [E38DA5A1E9DA40EBB249CFE6612CC49C] [http-nio-8180-exec-1] c.c.log.trace.FeignTraceInterceptor FeignTraceInterceptor.request: /account/decrease?userId=22&money=22 [seata-order-service:192.168.130.167:8180] 2021-12-02 14:09:50.170 INFO 37872 [E38DA5A1E9DA40EBB249CFE6612CC49C] [http-nio-8180-exec-1] c.e.feignokhttp.MyOkhttpInterceptor 接收响应: [http://192.168.130.167:8182/account/decrease?userId=22&money=22] 返回json:【{\"code\":200,\"message\":\"操作成功\",\"data\":\"扣减账户余额成功！\"}】 3009.3ms [seata-order-service:192.168.130.167:8180] 2021-12-02 14:09:50.170 INFO 37872 [E38DA5A1E9DA40EBB249CFE6612CC49C] [http-nio-8180-exec-1] c.e.o.service.impl.OrderServiceImpl ------->order-service中扣减余额结束 [seata-order-service:192.168.130.167:8180] 2021-12-02 14:09:50.170 INFO 37872 [E38DA5A1E9DA40EBB249CFE6612CC49C] [http-nio-8180-exec-1] c.e.o.service.impl.OrderServiceImpl ------->order-service中修改订单状态开始 [seata-order-service:192.168.130.167:8180] 2021-12-02 14:09:50.170 INFO 37872 [E38DA5A1E9DA40EBB249CFE6612CC49C] [http-nio-8180-exec-1] c.e.o.service.impl.OrderServiceImpl ------->order-service中修改订单状态中 [seata-order-service:192.168.130.167:8180] 2021-12-02 14:09:50.170 INFO 37872 [E38DA5A1E9DA40EBB249CFE6612CC49C] [http-nio-8180-exec-1] c.e.o.service.impl.OrderServiceImpl ------->order-service中修改订单状态结束 [seata-order-service:192.168.130.167:8180] 2021-12-02 14:09:50.170 INFO 37872 [E38DA5A1E9DA40EBB249CFE6612CC49C] [http-nio-8180-exec-1] c.e.o.service.impl.OrderServiceImpl ------->下单结束 网关生成traceId值为E38DA5A1E9DA40EBB249CFE6612CC49C "},"chapter1/section12.html":{"url":"chapter1/section12.html","title":"1.12 ELK搭建日志收集系统","keywords":"","body":"ELK搭建日志收集系统 概述 [!note] 利用docker容器化以后，需要考虑如何采集位于Docker容器中的应用程序的打印日志供运维分析。比如SpringBoot应用的日志收集。利用ELK日志中心来收集容器化应用程序所产生的日志，并且可以用可视化的方式对日志进行查询与分析，其架构如下图所示 架构图 环境搭建 基础环境依赖 组件 版本号 Mysql 5.7 Elasticsearch 7.6.2 Logstash 7.6.2 Kibana 7.6.2 docker安装 (不同的操作系统可以参考 https://yeasy.gitbook.io/docker_practice/install) 安装yum-utils（安装docker-ce所需依赖） yum install -y yum-utils device-mapper-persistent-data lvm2 为yum源添加docker仓库位置 yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo yum.repos.d # 仓库源存放的位置 cd /etc/yum.repos.d vim docker-ce.repo 安装docker ⚠️注意 docker-ce与docker两个仓库版本有差异（本人爬坑比较多 docker不支持文件的挂载比较老的版本） yum install docker-ce # 如果报错以下信息 errors during downloading metadata for repository 'base': - Curl error (28): Timeout was reached for http://mirrors.aliyuncs.com/centos/3/os/x86_64/repodata/repomd.xml [Connection timed out after 30001 milliseconds] - Status code: 404 for http://mirrors.cloud.aliyuncs.com/centos/3/os/x86_64/repodata/repomd.xml (IP: 100.100.2.148) - Status code: 404 for http://mirrors.aliyun.com/centos/3/os/x86_64/repodata/repomd.xml (IP: 39.96.118.193) Error: Failed to download metadata for repo 'base': Cannot download repomd.xml: Cannot download repodata/repomd.xml: All mirrors were tried # 将/etc/yum.repos.d/docker-ce.repo的地址进行修改 # 将数据源替换成版本7 不然下载的时候会报错 链接地址不存在. baseurl=https://download.docker.com/linux/centos/7/debug-$basearch/stable 启动docker systemctl start docker 利用docker安装对应的服务 Elasticsearch安装 使用如下命令启动Elasticsearch服务 docker run -p 9200:9200 -p 9300:9300 --name elasticsearch \\ -e \"discovery.type=single-node\" \\ -e \"cluster.name=elasticsearch\" \\ -v /mydata/elasticsearch/plugins:/usr/share/elasticsearch/plugins \\ -v /mydata/elasticsearch/data:/usr/share/elasticsearch/data \\ -d elasticsearch:7.6.2 启动的时候会报错 OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release. {\"type\": \"server\", \"timestamp\": \"2021-06-03T11:24:02,468Z\", \"level\": \"ERROR\", \"component\": \"o.e.b.ElasticsearchUncaughtExceptionHandler\", \"cluster.name\": \"elasticsearch\", \"node.name\": \"4f5aaf7716c0\", \"message\": \"uncaught exception in thread [main]\", \"stacktrace\": [\"org.elasticsearch.bootstrap.StartupException: ElasticsearchException[failed to bind service]; nested: AccessDeniedException[/usr/share/elasticsearch/data/nodes];\", \"at org.elasticsearch.bootstrap.Elasticsearch.init(Elasticsearch.java:174) ~[elasticsearch-7.6.2.jar:7.6.2]\", \"at org.elasticsearch.bootstrap.Elasticsearch.execute(Elasticsearch.java:161) ~[elasticsearch-7.6.2.jar:7.6.2]\", \"at org.elasticsearch.cli.EnvironmentAwareCommand.execute(EnvironmentAwareCommand.java:86) ~[elasticsearch-7.6.2.jar:7.6.2]\", \"at org.elasticsearch.cli.Command.mainWithoutErrorHandling(Command.java:125) ~[elasticsearch-cli-7.6.2.jar:7.6.2]\", \"at org.elasticsearch.cli.Command.main(Command.java:90) ~[elasticsearch-cli-7.6.2.jar:7.6.2]\", \"at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:126) ~[elasticsearch-7.6.2.jar:7.6.2]\", \"at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:92) ~[elasticsearch-7.6.2.jar:7.6.2]\", \"Caused by: org.elasticsearch.ElasticsearchException: failed to bind service\", \"at org.elasticsearch.node.Node.(Node.java:615) ~[elasticsearch-7.6.2.jar:7.6.2]\", \"at org.elasticsearch.node.Node.(Node.java:257) ~[elasticsearch-7.6.2.jar:7.6.2]\", \"at org.elasticsearch.bootstrap.Bootstrap$5.(Bootstrap.java:221) ~[elasticsearch-7.6.2.jar:7.6.2]\", \"at org.elasticsearch.bootstrap.Bootstrap.setup(Bootstrap.java:221) ~[elasticsearch-7.6.2.jar:7.6.2]\", \"at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:349) ~[elasticsearch-7.6.2.jar:7.6.2]\", \"at org.elasticsearch.bootstrap.Elasticsearch.init(Elasticsearch.java:170) ~[elasticsearch-7.6.2.jar:7.6.2]\", \"... 6 more\", \"Caused by: java.nio.file.AccessDeniedException: /usr/share/elasticsearch/data/nodes\", \"at sun.nio.fs.UnixException.translateToIOException(UnixException.java:90) ~[?:?]\", \"at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111) ~[?:?]\", \"at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:116) ~[?:?]\", \"at sun.nio.fs.UnixFileSystemProvider.createDirectory(UnixFileSystemProvider.java:389) ~[?:?]\", \"at java.nio.file.Files.createDirectory(Files.java:693) ~[?:?]\", \"at java.nio.file.Files.createAndCheckIsDirectory(Files.java:800) ~[?:?]\", \"at java.nio.file.Files.createDirectories(Files.java:786) ~[?:?]\", \"at org.elasticsearch.env.NodeEnvironment.lambda$new$0(NodeEnvironment.java:274) ~[elasticsearch-7.6.2.jar:7.6.2]\", \"at org.elasticsearch.env.NodeEnvironment$NodeLock.(NodeEnvironment.java:211) ~[elasticsearch-7.6.2.jar:7.6.2]\", \"at org.elasticsearch.env.NodeEnvironment.(NodeEnvironment.java:271) ~[elasticsearch-7.6.2.jar:7.6.2]\", \"at org.elasticsearch.node.Node.(Node.java:277) ~[elasticsearch-7.6.2.jar:7.6.2]\", \"at org.elasticsearch.node.Node.(Node.java:257) ~[elasticsearch-7.6.2.jar:7.6.2]\", \"at org.elasticsearch.bootstrap.Bootstrap$5.(Bootstrap.java:221) ~[elasticsearch-7.6.2.jar:7.6.2]\", \"at org.elasticsearch.bootstrap.Bootstrap.setup(Bootstrap.java:221) ~[elasticsearch-7.6.2.jar:7.6.2]\", \"at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:349) ~[elasticsearch-7.6.2.jar:7.6.2]\", \"at org.elasticsearch.bootstrap.Elasticsearch.init(Elasticsearch.java:170) ~[elasticsearch-7.6.2.jar:7.6.2]\", \"... 6 more\"] } uncaught exception in thread [main] 启动时会发现/usr/share/elasticsearch/data目录没有访问权限，只需要修改/mydata/elasticsearch/data目录的权限，再重新启动即可 chmod 777 /mydata/elasticsearch/data/ 安装中文分词器IKAnalyzer，并重新启动 # 进入docker容器中 docker exec -it elasticsearch /bin/bash #此命令需要在容器中运行 elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.6.2/elasticsearch-analysis-ik-7.6.2.zip -> Installing https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.6.2/elasticsearch-analysis-ik-7.6.2.zip -> Downloading https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.6.2/elasticsearch-analysis-ik-7.6.2.zip [=================================================] 100%?? @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ @ WARNING: plugin requires additional permissions @ @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ * java.net.SocketPermission * connect,resolve See http://docs.oracle.com/javase/8/docs/technotes/guides/security/permissions.html for descriptions of what these permissions allow and the associated risks. Continue with installation? [y/N]y -> Installed analysis-ik # 退出去后重启生效 docker restart elasticsearch 访问会返回版本信息：http://39.103.203.41:9200/ { \"name\" : \"4f5aaf7716c0\", \"cluster_name\" : \"elasticsearch\", \"cluster_uuid\" : \"PBB0ZytDStO-9SJjAarNyw\", \"version\" : { \"number\" : \"7.6.2\", \"build_flavor\" : \"default\", \"build_type\" : \"docker\", \"build_hash\" : \"ef48eb35cf30adf4db14086e8aabd07ef6fb113f\", \"build_date\" : \"2020-03-26T06:34:37.794943Z\", \"build_snapshot\" : false, \"lucene_version\" : \"8.4.0\", \"minimum_wire_compatibility_version\" : \"6.8.0\", \"minimum_index_compatibility_version\" : \"6.0.0-beta1\" }, \"tagline\" : \"You Know, for Search\" } Logstash安装 下载Logstash7.6.2的docker镜像 docker pull logstash:7.6.2 如下配置文件logstash.conf input { tcp { mode => \"server\" host => \"0.0.0.0\" port => 4560 codec => json_lines type => \"debug\" } tcp { mode => \"server\" host => \"0.0.0.0\" port => 4561 codec => json_lines type => \"error\" } tcp { mode => \"server\" host => \"0.0.0.0\" port => 4562 codec => json_lines type => \"business\" } tcp { mode => \"server\" host => \"0.0.0.0\" port => 4563 codec => json_lines type => \"record\" } } filter{ if [type] == \"record\" { mutate { remove_field => \"port\" remove_field => \"host\" remove_field => \"@version\" } json { source => \"message\" remove_field => [\"message\"] } } } output { elasticsearch { hosts => \"39.103.203.41:9200\" index => \"mall-%{type}-%{+YYYY.MM.dd}\" } } 创建/mydata/logstash目录，并将Logstash的配置文件logstash.conf拷贝到该目录 mkdir /mydata/logstash 使用如下命令启动Logstash服务 docker run --name logstash -p 4560:4560 -p 4561:4561 -p 4562:4562 -p 4563:4563 \\ --link elasticsearch:es \\ -v /mydata/logstash/logstash.conf:/usr/share/logstash/pipeline/logstash.conf \\ -d logstash:7.6.2 在logstash中安装json_lines插件 # 进入logstash容器 docker exec -it logstash /bin/bash # 进入bin目录 cd /bin/ # 安装插件 logstash-plugin install logstash-codec-json_lines OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release. WARNING: An illegal reflective access operation has occurred WARNING: Illegal reflective access by com.headius.backport9.modules.Modules to method sun.nio.ch.NativeThread.signal(long) WARNING: Please consider reporting this to the maintainers of com.headius.backport9.modules.Modules WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations WARNING: All illegal access operations will be denied in a future release Validating logstash-codec-json_lines Installing logstash-codec-json_lines Installation successful # 退出容器 exit # 重启logstash服务 docker restart logstash Kibana安装 下载Kibana7.6.2的docker镜像 7.6.2: Pulling from library/kibana ab5ef0e58194: Already exists c64d415fc4c4: Pull complete 40a228497f87: Pull complete 047cebeb3d2b: Pull complete a1e90407e522: Pull complete b665bda75e65: Pull complete 12bc27d9cfdc: Pull complete 2611a8427d9d: Pull complete 12efd486dee3: Pull complete d2dfc5062b56: Pull complete Digest: sha256:097e2b7f33f353a8fc19bbf2a6558431c63637113fdc625e6d34fc46f96c0130 Status: Downloaded newer image for kibana:7.6.2 docker.io/library/kibana:7.6.2 使用如下命令启动Kibana服务 docker run --name kibana -p 5601:5601 \\ --link elasticsearch:es \\ -e \"elasticsearch.hosts=http://es:9200\" \\ -d kibana:7.6.2 访问地址进行测试 http://39.103.203.41:5601/ SpringBoot应用集成Logstash net.logstash.logback logstash-logback-encoder 5.3 添加配置文件logback-spring.xml让logback的日志输出到logstash 注意appender节点下的destination需要改成你自己的logstash服务地址，例如我自己的是：39.103.203.41:4560 ${APP_NAME} ${LOG_FILE_PATH}/${APP_NAME}-%d{yyyy-MM-dd}.log 30 ${FILE_LOG_PATTERN} 39.103.203.41:4560 运行SpringBoot应用 package com.macro.mall.tiny; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; @SpringBootApplication public class MallApplication { public static void main(String[] args) { SpringApplication.run(MallApplication.class, args); } } 在kibana中查看日志信息 创建index pattern 调用该接口并查看日志 "},"chapter1/section13.html":{"url":"chapter1/section13.html","title":"1.13 Docker学习常用命令汇总","keywords":"","body":"Docker学习常用命令汇总 主要是总结日常开发中常用的docker的命令 Docker介绍 Docker 是一个开源的应用容器引擎。 Docker 可以让开发者打包他们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的Linux 机器上，也可以实现虚拟化。 容器是完全使用沙箱机制（类似iPhone的app）,更重要的是容器性能开销极低. 容器共享机器的操作系统内核，因此每个应用程序不需要操作系统，从而提高服务器效率并降低服务器和许可成本, 提供业界最强的默认隔离能力. Docker组织架构图 Docker的安装 mac版本安装 通过官网 https://www.docker.com/get-started选择对应的版本进行安装 Linux环境安装 安装yum-utils yum install -y yum-utils device-mapper-persistent-data lvm2 为yum源添加docker仓库位置 yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo 安装docker服务 yum install docker-ce 启动docker服务 systemctl start docker Docker镜像常用命令 搜索镜像 docker search ➜ dockerImages docker search nginx NAME DESCRIPTION STARS OFFICIAL AUTOMATED nginx Official build of Nginx. 14999 [OK] jwilder/nginx-proxy Automated Nginx reverse proxy for docker con… 2033 [OK] richarvey/nginx-php-fpm Container running Nginx + PHP-FPM capable of… 814 [OK] 下载镜像 docker pull 查看镜像的历史版本 https://hub.docker.com/ docker search命令只能查找出是否有该镜像，不能找到该镜像支持的版本.需要进入docker官网进行查看（https://hub.docker.com/） 查看镜像的历史版本 进行镜像的下载操作 docker pull mysql:8.0.25 列出镜像 docker images ➜ dockerImages docker images REPOSITORY TAG IMAGE ID CREATED SIZE redis 5 59fbd83692ee 4 weeks ago 98.4MB mysql 5.7 2c9028880e58 4 weeks ago 447MB mongo 4.2.5 fddee5bccba3 14 months ago 388MB logstash 7.6.2 fa5b3b1e9757 14 months ago 813MB kibana 7.6.2 f70986bc5191 14 months ago 1.01GB elasticsearch 7.6.2 f29a1ee41030 14 months ago 791MB 删除镜像 docker rmi 指定名称删除镜像 docker rmi mysql:5.7 指定名称删除镜像（强制) docker rmi -f mysql:5.7 删除所有没有引用的镜像 docker rmi `docker images | grep none | awk '{print $3}'` 强制删除所有镜像 docker rmi -f $(docker images) 打包镜像 docker build -t # -t 表示指定镜像仓库名称/镜像名称:镜像标签 .表示使用当前目录下的Dockerfile文件 docker build -t mall/mall:1.1.0-SNAPSHOT . 推送镜像 # 登录Docker Hub docker login # 给本地镜像打标签为远程仓库名称 docker tag mall/mall:1.1.0-SNAPSHOT fy/mall:1.1.0-SNAPSHOT # 推送到远程仓库 docker push fy/mall:1.1.0-SNAPSHOT Docker容器常用命令 新建并启动容器 docker run -p 80:80 --name nginx \\ -e TZ=\"Asia/Shanghai\" \\ -v /mydata/nginx/html:/usr/share/nginx/html \\ -d nginx:1.10 -p: 将宿主机和容器端口进行映射，格式为：宿主机端口:容器端口； --name: 指定容器名称，之后可以通过容器名称来操作容器 -e: 设置容器的环境变量，这里设置的是时区； -v: 将宿主机上的文件挂载容器上，格式为：宿主机文件目录:容器文件目录 -d: 表示容器以后台方式运行 列出容器 展示运行中的容器 docker ps ➜ dockerImages docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES e8be56dcb1f7 logstash:7.6.2 \"/usr/local/bin/dock…\" 2 hours ago Up 2 hours 5044/tcp, 0.0.0.0:4560-4563->4560-4563/tcp, :::4560-4563->4560-4563/tcp, 9600/tcp logstash 72123ac57300 kibana:7.6.2 \"/usr/local/bin/dumb…\" 2 hours ago Up 2 hours 0.0.0.0:5601->5601/tcp, :::5601->5601/tcp kibana 375c89abf1ee elasticsearch:7.6.2 \"/usr/local/bin/dock…\" 2 hours ago Up 2 hours 0.0.0.0:9200->9200/tcp, :::9200->9200/tcp, 0.0.0.0:9300->9300/tcp, :::9300->9300/tcp elasticsearch 2b73a2694943 mysql:5.7 \"docker-entrypoint.s…\" 20 hours ago Up 6 hours 0.0.0.0:3306->3306/tcp, :::3306->3306/tcp, 33060/tcp mysql 展示所有的容器 docker ps -a ➜ dockerImages docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES e8be56dcb1f7 logstash:7.6.2 \"/usr/local/bin/dock…\" 2 hours ago Up 2 hours 5044/tcp, 0.0.0.0:4560-4563->4560-4563/tcp, :::4560-4563->4560-4563/tcp, 9600/tcp logstash 72123ac57300 kibana:7.6.2 \"/usr/local/bin/dumb…\" 2 hours ago Up 2 hours 0.0.0.0:5601->5601/tcp, :::5601->5601/tcp kibana 375c89abf1ee elasticsearch:7.6.2 \"/usr/local/bin/dock…\" 2 hours ago Up 2 hours 0.0.0.0:9200->9200/tcp, :::9200->9200/tcp, 0.0.0.0:9300->9300/tcp, :::9300->9300/tcp elasticsearch 029b5496bb2b nginx:1.10 \"nginx -g 'daemon of…\" 5 hours ago Created 80/tcp, 443/tcp nginx 2b73a2694943 mysql:5.7 \"docker-entrypoint.s…\" 20 hours ago Up 6 hours 0.0.0.0:3306->3306/tcp, :::3306->3306/tcp, 33060/tcp mysql 停止容器 docker stop ## 容器名称 docker stop mysql #或者容器id docker stop 2b73a2694943 强制停止容器 docker kill ## 容器名称 docker kill mysql 启动容器 docker start ## 容器名称 docker start mysql 进入容器 docker exec -it $ContainerName /bin/bash docker exec -it mysql /bin/bash 删除容器 docker rm 删除指定容器： docker rm $ContainerName 强制删除所有容器； docker rm -f $(docker ps -a -q) 查看容器的日志 查看容器产生的全部日志 docker rm $ContainerName ➜ dockerImages docker logs elasticsearch OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release. {\"type\": \"server\", \"timestamp\": \"2021-06-12T15:15:29,435+08:00\", \"level\": \"INFO\", \"component\": \"o.e.e.NodeEnvironment\", \"cluster.name\": \"elasticsearch\", \"node.name\": \"375c89abf1ee\", \"message\": \"using [1] data paths, mounts [[/usr/share/elasticsearch/data (grpcfuse)]], net usable_space [373.2gb], net total_space [465.6gb], types [fuse.grpcfuse]\" } {\"type\": \"server\", \"timestamp\": \"2021-06-12T15:15:29,438+08:00\", \"level\": \"INFO\", \"component\": \"o.e.e.NodeEnvironment\", \"cluster.name\": \"elasticsearch\", \"node.name\": \"375c89abf1ee\", \"message\": \"heap size [494.9mb], compressed ordinary object pointers [true]\" } 动态查看容器产生的日志 docker logs -f $ContainerName 同步宿主机时间到容器 docker cp /etc/localtime $ContainerName:/etc/ 指定容器时区 docker run -p 80:80 --name nginx \\ -e TZ=\"Asia/Shanghai\" \\ -d nginx:1.10 查看容器资源占用情况 docker status 查看指定容器资源占用状况，比如cpu、内存、网络、io状态 docker stats $ContainerName ➜ dockerImages docker stats elasticsearch CONTAINER ID NAME CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDS 375c89abf1ee elasticsearch 1.21% 939.5MiB / 9.732GiB 9.43% 19.1MB / 7.4MB 45.1kB / 246kB 95 查看所有容器资源占用情况 docker stats -a ➜ dockerImages docker stats -a CONTAINER ID NAME CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDS e8be56dcb1f7 logstash 4.85% 852.9MiB / 9.732GiB 8.56% 856kB / 7.24MB 12.3kB / 418kB 93 72123ac57300 kibana 0.48% 409.3MiB / 9.732GiB 4.11% 7.17MB / 12.3MB 58.4MB / 4.1kB 12 375c89abf1ee elasticsearch 1.55% 939.6MiB / 9.732GiB 9.43% 19.3MB / 7.44MB 45.1kB / 246kB 95 029b5496bb2b nginx 0.00% 0B / 0B 0.00% 0B / 0B 0B / 0B 0 2b73a2694943 mysql 0.21% 201MiB / 9.732GiB 2.02% 19.1kB / 0B 31.9MB / 8.19kB 27 2bb6eacfc945 redis 0.00% 0B / 0B 0.00% 0B / 0B 0B / 0B 0 查看容器磁盘使用情况 docker system df ➜ dockerImages docker system df TYPE TOTAL ACTIVE SIZE RECLAIMABLE Images 11 6 4.431GB 1.84GB (41%) Containers 6 4 137.3MB 11B (0%) Local Volumes 6 0 175.4MB 175.4MB (100%) Build Cache 0 0 0B 0B 指定账号进入容器内部 # 使用root账号进入容器内部 docker exec -it --user root $ContainerName /bin/bash Docker容器清理 删除所有关闭的容器 # 使用root账号进入容器内部 docker ps -a | grep Exit | cut -d ' ' -f 1 | xargs docker rm "},"chapter2/":{"url":"chapter2/","title":"2.技术方案与性能优化","keywords":"","body":"技术方案与性能优化 [!note] 主要是记录一些线上问题的bug汇总以及解决方案 "},"chapter2/section1.html":{"url":"chapter2/section1.html","title":"2.1 技术方案实例","keywords":"","body":"技术方案示例 [!note] 本次政策服务网点迭代主要迭代功能 增加【残保金比例】参数 政策包的险种类型等于残保金时显示，且必填 增加【所有险种统一】参数 政策包的险种类型=社保或公积金时显示，且必选一个 修改增加【参保时公积金是否必缴参数】改为【参保时公积金按户籍性质设置】参数 参保时公积金按户籍性质设置: 均必缴、均可选、自主设置，默认为均必缴 【必缴户籍】 选择自主设置时，【必缴户籍】参数显示 历史数据处理 社保接单导入支持险种异常导入 待申报 申报中 派单异常 反馈异常，消息通知 社保服务用例图 注：蓝色表示本次迭代需要修改的用例、红色代表目前暂时不作修改的用例 社保服务网点用例图 社保增加接单用例图 数据库模型图 社保服务网点数据模型图 社保增员派单接单模型图 社保服务列表 社保服务表 ADD COLUMN `disability_proportion` decimal(18) UNSIGNED NOT NULL DEFAULT 0.00 COMMENT '残保金比例' AFTER `reconciliation_manner`, ALTER TABLE `smarthr-service`.`soc_service_info` ADD COLUMN is_mandatory int(11) NULL COMMENT '参保时公积金按户籍性质设置：0-均可选,1-均必缴,2-自主设置'; ADD COLUMN `insurance_agreement` int(3) NOT NULL DEFAULT 0 COMMENT '是否所有险种统一 0:否 1:是' AFTER `disability_proportion`, CREATE TABLE `soc_service_info_census` ( `id` bigint(20) NOT NULL COMMENT '主键', `service_id` bigint(20) NOT NULL COMMENT '社保服务网点ID', `census_id` bigint(20) NOT NULL COMMENT '户籍性质ID 对应census_info-ID', `census_name` varchar(64) DEFAULT NULL COMMENT '户籍性质', `hidden_memo` varchar(255) DEFAULT '' COMMENT '备注，对项目隐藏，仅在数据库中可见', `create_staff_id` bigint(20) NOT NULL DEFAULT '-1' COMMENT '创建人staffId', `create_time` datetime DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间', `update_staff_id` bigint(20) DEFAULT '-1' COMMENT '更新者staffId', `update_time` datetime DEFAULT CURRENT_TIMESTAMP COMMENT '更新时间', PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='必缴纳的户籍信息表'; 管理端展现 四、社保预计开发时间 "},"chapter2/section2.html":{"url":"chapter2/section2.html","title":"2.2 ArthasTrace工具性能优化","keywords":"","body":"Arthas Trace 化接口性能 🎨 需求背景 模块场景 社保政策包导入处理的数据量比较大，其中导入涉及查询和插入的表多达27张，但是又需要确保导入的数据的完整性所以加上导入之前需要做的业务逻辑验证有280多条之多。模块比较复杂。年前做过一波优化，导入500条数据能控制在10秒左右，但是目前业务反馈导入500条政策包数据需要将近50多秒。本文记录如何利用 Arthas ，将接口优化到5秒左右。 测试环境 本地MacOs 社保导入时序图 温馨提示 :代码逻辑可以不用看，没有上下文的情况下很难明白接口什么意思。主要看Arthas Trace的结果与优化思路。可以直接跳过下面的时序图 导入设计技术点 1、阿里规则引擎qlexpress https://github.com/alibaba/QLExpress.git 2、EasyExcel https://github.com/alibaba/easyexcel.git 3、Validation自定义参数验证 4、CompletableFuture Java8新的异步编程 5、引入线程池 优化需要的工具 具体的安装操作命令我就不在详细说明、下面给出了官方文档可以学习。 Arthas https://arthas.aliyun.com/doc/ 🎨 优化过程 Arthas Trace的链路基本命令 1、启动Arthas（阿尔萨斯） ➜ webApp java -jar arthas-boot.jar [INFO] arthas-boot version: 3.5.4 [INFO] Process 64966 already using port 3658 [INFO] Process 64966 already using port 8563 [INFO] Found existing java process, please choose one and input the serial number of the process, eg : 1. Then hit ENTER. * [1]: 64966 com.joyowo.smarthr.social.app.SocialSecurityApplication [2]: 84225 org.jetbrains.jps.cmdline.Launcher [3]: 63942 org.elasticsearch.bootstrap.Elasticsearch [4]: 88406 com.central.SCGatewayApp [5]: 5783 org.logstash.Logstash [6]: 82760 org.jetbrains.idea.maven.server.RemoteMavenServer36 [7]: 40202 [8]: 13835 com.macro.mall.tiny.MallTinyApplication 2、可以看到目前运行java程序有8个，对应的社保服务为 [1]: 64966 3、输入1监控社保服务 1 [INFO] arthas home: /Users/apple/.arthas/lib/3.5.4/arthas [INFO] The target process already listen port 3658, skip attach. [INFO] arthas-client connect 127.0.0.1 3658 ,---. ,------. ,--------.,--. ,--. ,---. ,---. / O \\ | .--. ''--. .--'| '--' | / O \\ ' .-' | .-. || '--'.' | | | .--. || .-. |`. `-. | | | || |\\ \\ | | | | | || | | |.-' | `--' `--'`--' '--' `--' `--' `--'`--' `--'`-----' wiki https://arthas.aliyun.com/doc tutorials https://arthas.aliyun.com/doc/arthas-tutorials.html version 3.5.4 main_class com.joyowo.smarthr.social.app.SocialSecurityApplication pid 64966 time 2021-12-20 14:20:25 4、输入需要监控的类方法名 trace -E com.joyowo.smarthr.social.app.controller.soc.SocPolicyPackageImportController|com.joyowo.smarthr.social.app.service.soc.service.excel.excelImpl.SocImportInsurancePolicyServiceImpl inputPolicyData|fileImportLogic -n 5 5、利用postMen调用接口开始监控 `---ts=2021-12-20 16:50:49;thread_name=http-nio-9130-exec-6;id=d1;is_daemon=true;priority=5;TCCL=org.springframework.boot.web.embedded.tomcat.TomcatEmbeddedWebappClassLoader@6444ee23 `---[41715.350639ms] com.joyowo.smarthr.social.app.service.soc.service.excel.excelImpl.SocImportInsurancePolicyServiceImpl$$EnhancerBySpringCGLIB$$e1a7a7ec:fileImportLogic() `---[41715.26805ms] org.springframework.cglib.proxy.MethodInterceptor:intercept() `---[41715.183862ms] com.joyowo.smarthr.social.app.service.soc.service.excel.excelImpl.SocImportInsurancePolicyServiceImpl:fileImportLogic() +---[108.65751ms] com.joyowo.smarthr.social.common.util.ConvertUtil:convertList() #116 +---[0.013542ms] org.apache.commons.collections.CollectionUtils:isEmpty() #117 +---[0.041739ms] java.util.List:parallelStream() #124 +---[0.024564ms] java.util.stream.Stream:peek() #125 +---[0.012501ms] java.util.stream.Stream:filter() #130 +---[0.013719ms] java.util.stream.Collectors:toList() #131 +---[0.904377ms] java.util.stream.Stream:collect() #131 +---[0.006979ms] java.util.ArrayList:() #134 +---[0.012424ms] java.util.List:get() #137 +---[0.005452ms] com.joyowo.smarthr.social.infra.vo.soc.incr.InsurancePolicyImportQuery:getVersion() #138 +---[0.005392ms] org.apache.commons.lang3.StringUtils:isNotEmpty() #139 +---[0.003361ms] java.util.List:parallelStream() #147 +---[0.004242ms] java.util.stream.Stream:filter() #148 +---[0.03109ms] java.util.stream.Collectors:groupingBy() #149 +---[0.373782ms] java.util.stream.Stream:collect() #149 +---[0.088922ms] java.util.Map:forEach() #150 +---[0.010076ms] java.lang.System:currentTimeMillis() #153 +---[0.010491ms] java.util.List:stream() #156 +---[0.013278ms] java.util.stream.Stream:map() #157 +---[0.003152ms] java.util.stream.Collectors:toList() #158 +---[0.678801ms] java.util.stream.Stream:collect() #158 +---[0.003608ms] java.util.List:stream() #161 +---[0.004828ms] java.util.stream.Stream:map() #162 +---[0.047344ms] java.util.stream.Stream:flatMap() #162 +---[0.005207ms] java.util.stream.Collectors:toList() #163 +---[14983.270241ms] java.util.stream.Stream:collect() #163 +---[0.00341ms] java.lang.StringBuilder:() #164 +---[min=0.001995ms,max=0.02124ms,total=0.026597ms,count=3] java.lang.StringBuilder:append() #164 +---[0.003568ms] java.lang.System:currentTimeMillis() #164 +---[0.002694ms] java.lang.StringBuilder:toString() #164 +---[0.08997ms] org.slf4j.Logger:info() #164 +---[0.003315ms] java.lang.System:currentTimeMillis() #166 +---[3.971702ms] com.joyowo.smarthr.social.app.service.soc.service.excel.excelImpl.SocImportInsurancePolicyServiceImpl:checkInsuredType() #169 +---[0.003303ms] java.lang.StringBuilder:() #171 +---[min=0.002061ms,max=0.005269ms,total=0.010399ms,count=3] java.lang.StringBuilder:append() #171 +---[0.003186ms] java.lang.System:currentTimeMillis() #171 +---[0.002907ms] java.lang.StringBuilder:toString() #171 +---[0.057445ms] org.slf4j.Logger:info() #171 +---[0.005981ms] java.util.List:addAll() #174 +---[26613.044218ms] com.joyowo.smarthr.social.app.service.soc.service.SocImportMiddlePolicyService:insertSocImportMiddleExcel() #175 `---[0.017433ms] com.joyowo.smarthr.social.infra.dto.soc.socserviceinfo.ImportServiceResDto:() #177 从上面的监控结果可以看出+---[14983.270241ms] java.util.stream.Stream:collect() #163 与 +---[26613.044218ms] com.joyowo.smarthr.social.app.service.soc.service.SocImportMiddlePolicyService:insertSocImportMiddleExcel() #175 这两快处理的时间比较长14秒与26秒 7、[14983.270241ms] java.util.stream.Stream:collect() #1633 优化 定位代码 // 同步线程池处理分别处理 单个政策包险种明细集合. List>> completableFutureList = insurancePolicyImportQueryListNew .stream() .map(insurancePolicyImportList -> CompletableFuture.supplyAsync(() -> builderPolicyImportQuery(insurancePolicyImportList, staffId), executorServiceThreadPool)) .collect(Collectors.toList()); // 线程池数据流汇总 List policyImportQueryList = completableFutureList.stream() .map(CompletableFuture::join).flatMap(Collection::stream) .collect(Collectors.toList()); 从代码上面看异步线程CompletableFuture流消耗了比较长的时间，这块我已经用了线程池处理了但是还是需要14秒的时间。下面我定位下具体的性能瓶颈在那一块 执行命令 ### 查看builderPolicyImportQuery最近500次调用消耗的时间 tt -t com.joyowo.smarthr.social.app.service.soc.service.excel.excelImpl.SocImportInsurancePolicyServiceImpl builderPolicyImportQuery -n 500 INDEX TIMESTAMP COST(ms) IS-RET IS-EXP OBJECT CLASS METHOD ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ 1005 2021-12-20 16:56:51 156.198211 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1006 2021-12-20 16:56:52 559.348797 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1007 2021-12-20 16:56:52 569.815901 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1008 2021-12-20 16:56:52 421.197444 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1009 2021-12-20 16:56:52 582.496309 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1010 2021-12-20 16:56:52 588.031464 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1011 2021-12-20 16:56:52 139.14546 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1012 2021-12-20 16:56:52 256.157896 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1013 2021-12-20 16:56:52 506.299105 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1014 2021-12-20 16:56:53 823.741301 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1015 2021-12-20 16:56:53 882.290655 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1016 2021-12-20 16:56:53 1052.131126 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1017 2021-12-20 16:56:53 662.626201 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1018 2021-12-20 16:56:53 211.884633 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1019 2021-12-20 16:56:53 647.383149 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1020 2021-12-20 16:56:53 439.697766 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1021 2021-12-20 16:56:53 207.636597 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1022 2021-12-20 16:56:53 493.055679 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1023 2021-12-20 16:56:53 117.143492 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1024 2021-12-20 16:56:53 534.628504 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1025 2021-12-20 16:56:53 501.005884 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1026 2021-12-20 16:56:53 473.501408 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1027 2021-12-20 16:56:54 140.610755 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1028 2021-12-20 16:56:54 133.576507 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1029 2021-12-20 16:56:54 352.980987 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1030 2021-12-20 16:56:54 389.299099 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1031 2021-12-20 16:56:54 675.418435 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1032 2021-12-20 16:56:54 604.228142 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1033 2021-12-20 16:56:54 145.504299 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1034 2021-12-20 16:56:54 664.244686 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1035 2021-12-20 16:56:54 515.78755 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1036 2021-12-20 16:56:54 511.892287 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1037 2021-12-20 16:56:54 260.505313 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1038 2021-12-20 16:56:55 711.800169 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1039 2021-12-20 16:56:55 851.01159 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1040 2021-12-20 16:56:55 847.755956 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1041 2021-12-20 16:56:55 996.35076 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1042 2021-12-20 16:56:56 275.979225 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1043 2021-12-20 16:56:56 677.394178 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1044 2021-12-20 16:56:56 1155.758544 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1045 2021-12-20 16:56:56 649.718017 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1046 2021-12-20 16:56:56 561.551393 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1047 2021-12-20 16:56:56 376.715522 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1048 2021-12-20 16:56:56 409.12387 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1049 2021-12-20 16:56:56 424.200906 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1050 2021-12-20 16:56:56 416.129167 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1051 2021-12-20 16:56:56 397.683419 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1052 2021-12-20 16:56:56 199.520089 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1053 2021-12-20 16:56:56 199.541889 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1054 2021-12-20 16:56:56 127.332295 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1055 2021-12-20 16:56:56 128.146418 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1056 2021-12-20 16:56:57 555.03217 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1057 2021-12-20 16:56:57 603.304011 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1058 2021-12-20 16:56:57 727.218251 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1059 2021-12-20 16:56:57 748.817439 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1060 2021-12-20 16:56:57 429.241338 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1061 2021-12-20 16:56:57 408.41402 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1062 2021-12-20 16:56:57 348.346705 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1063 2021-12-20 16:56:57 383.235937 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1064 2021-12-20 16:56:57 406.197608 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1065 2021-12-20 16:56:57 187.260667 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1066 2021-12-20 16:56:57 418.535668 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1067 2021-12-20 16:56:57 370.246684 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1068 2021-12-20 16:56:58 399.736148 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1069 2021-12-20 16:56:58 431.076321 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1070 2021-12-20 16:56:58 568.676063 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1071 2021-12-20 16:56:58 484.667405 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1072 2021-12-20 16:56:58 499.288637 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1073 2021-12-20 16:56:58 311.684799 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1074 2021-12-20 16:56:58 117.612873 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1075 2021-12-20 16:56:58 428.263849 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1076 2021-12-20 16:56:58 658.919487 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1077 2021-12-20 16:56:59 787.732449 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1078 2021-12-20 16:56:59 911.645046 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1079 2021-12-20 16:56:59 735.019036 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1080 2021-12-20 16:56:59 890.92491 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1081 2021-12-20 16:56:59 120.465664 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1082 2021-12-20 16:56:59 535.779343 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1083 2021-12-20 16:56:59 339.609844 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1084 2021-12-20 16:56:59 451.043089 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1085 2021-12-20 16:56:59 432.077921 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1086 2021-12-20 16:56:59 429.262895 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1087 2021-12-20 16:56:59 432.023935 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1088 2021-12-20 16:57:00 529.162614 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1089 2021-12-20 16:57:00 546.750688 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1091 2021-12-20 16:57:00 650.361298 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1090 2021-12-20 16:57:00 691.807741 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1092 2021-12-20 16:57:00 771.424599 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1093 2021-12-20 16:57:00 701.501705 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1094 2021-12-20 16:57:00 578.724 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1095 2021-12-20 16:57:00 324.075264 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1096 2021-12-20 16:57:01 549.158852 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1097 2021-12-20 16:57:01 388.971617 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1098 2021-12-20 16:57:01 700.969975 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1099 2021-12-20 16:57:01 272.819632 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1100 2021-12-20 16:57:01 600.302636 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1101 2021-12-20 16:57:01 146.323093 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1102 2021-12-20 16:57:01 220.823071 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1103 2021-12-20 16:57:01 187.723078 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1104 2021-12-20 16:57:01 426.163659 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1105 2021-12-20 16:57:01 161.651799 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1106 2021-12-20 16:57:01 215.692463 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1107 2021-12-20 16:57:01 236.421642 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1108 2021-12-20 16:57:01 279.777291 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1109 2021-12-20 16:57:01 136.03506 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1110 2021-12-20 16:57:02 375.909926 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1111 2021-12-20 16:57:02 751.352407 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1112 2021-12-20 16:57:02 780.499661 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1113 2021-12-20 16:57:02 371.019642 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1114 2021-12-20 16:57:02 954.038269 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1115 2021-12-20 16:57:02 234.74004 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1116 2021-12-20 16:57:03 899.032271 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1117 2021-12-20 16:57:03 801.408514 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1118 2021-12-20 16:57:03 1769.934957 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1119 2021-12-20 16:57:03 1196.529583 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1120 2021-12-20 16:57:03 707.24919 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1121 2021-12-20 16:57:03 442.303587 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1122 2021-12-20 16:57:04 657.802616 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1123 2021-12-20 16:57:04 697.023453 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1124 2021-12-20 16:57:04 947.249422 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1125 2021-12-20 16:57:04 928.698927 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1126 2021-12-20 16:57:04 877.01401 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1127 2021-12-20 16:57:04 585.528493 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1128 2021-12-20 16:57:04 537.837003 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1129 2021-12-20 16:57:04 402.441286 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1130 2021-12-20 16:57:04 420.973766 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1131 2021-12-20 16:57:05 340.704898 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1132 2021-12-20 16:57:05 135.479258 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1133 2021-12-20 16:57:05 935.354655 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1134 2021-12-20 16:57:05 912.185536 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1135 2021-12-20 16:57:05 918.861673 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1136 2021-12-20 16:57:05 1215.071462 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1137 2021-12-20 16:57:06 710.389417 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1138 2021-12-20 16:57:06 572.092564 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1139 2021-12-20 16:57:06 600.60913 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1140 2021-12-20 16:57:06 312.879781 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1141 2021-12-20 16:57:06 493.355215 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1142 2021-12-20 16:57:06 492.064888 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1143 2021-12-20 16:57:06 611.985171 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1144 2021-12-20 16:57:06 591.307317 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1145 2021-12-20 16:57:06 242.383294 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1146 2021-12-20 16:57:06 570.557541 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1147 2021-12-20 16:57:06 567.69116 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1148 2021-12-20 16:57:06 170.721323 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1149 2021-12-20 16:57:07 418.166728 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1150 2021-12-20 16:57:07 451.995443 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 1151 2021-12-20 16:57:07 544.764398 true false 0x63e1155d SocImportInsurancePolicyServiceImpl builderPolicyImportQuery 从上面的执行记录列表来看调用消耗时间最长的为id 1118 消耗的时间为1769.934957 但是远远没有14秒这么长。这个时间我就开始怀疑是不是自定的线程池的核心线程数不够，导致线程排队阻塞等待消耗了过长的时间。 将核心线程数改为12（这个需要根据实际服务器CPU进行定义、因为我的电脑能同时并行运行12个线程，所以进行修改测试） [arthas@63089]$ trace com.joyowo.smarthr.social.app.service.soc.service.excel.excelImpl.SocImportInsurancePolicyServiceImpl fileImportLogic -n 5 --skipJDKMethod false Press Q or Ctrl+C to abort. Affect(class count: 2 , method count: 2) cost in 301 ms, listenerId: 1 `---ts=2021-12-20 17:11:26;thread_name=http-nio-9130-exec-2;id=cc;is_daemon=true;priority=5;TCCL=org.springframework.boot.web.embedded.tomcat.TomcatEmbeddedWebappClassLoader@2eb217bb `---[45325.494296ms] com.joyowo.smarthr.social.app.service.soc.service.excel.excelImpl.SocImportInsurancePolicyServiceImpl$$EnhancerBySpringCGLIB$$71b2bc42:fileImportLogic() `---[45325.217732ms] org.springframework.cglib.proxy.MethodInterceptor:intercept() `---[45324.163449ms] com.joyowo.smarthr.social.app.service.soc.service.excel.excelImpl.SocImportInsurancePolicyServiceImpl:fileImportLogic() +---[200.346805ms] com.joyowo.smarthr.social.common.util.ConvertUtil:convertList() #116 +---[3.090551ms] org.apache.commons.collections.CollectionUtils:isEmpty() #117 +---[0.028626ms] java.util.List:parallelStream() #124 +---[0.142501ms] java.util.stream.Stream:peek() #125 +---[0.017361ms] java.util.stream.Stream:filter() #130 +---[0.017943ms] java.util.stream.Collectors:toList() #131 +---[2.131175ms] java.util.stream.Stream:collect() #131 +---[0.012446ms] java.util.ArrayList:() #134 +---[0.014743ms] java.util.List:get() #137 +---[0.009844ms] com.joyowo.smarthr.social.infra.vo.soc.incr.InsurancePolicyImportQuery:getVersion() #138 +---[0.009193ms] org.apache.commons.lang3.StringUtils:isNotEmpty() #139 +---[0.006981ms] java.util.List:parallelStream() #147 +---[0.009976ms] java.util.stream.Stream:filter() #148 +---[0.025218ms] java.util.stream.Collectors:groupingBy() #149 +---[0.479762ms] java.util.stream.Stream:collect() #149 +---[0.07377ms] java.util.Map:forEach() #150 +---[0.014985ms] java.lang.System:currentTimeMillis() #153 +---[0.019603ms] java.util.List:stream() #156 +---[0.019997ms] java.util.stream.Stream:map() #157 +---[0.007591ms] java.util.stream.Collectors:toList() #158 +---[6.658965ms] java.util.stream.Stream:collect() #158 +---[0.009125ms] java.util.List:stream() #161 +---[0.014407ms] java.util.stream.Stream:map() #162 +---[0.021132ms] java.util.stream.Stream:flatMap() #162 +---[0.006878ms] java.util.stream.Collectors:toList() #163 +---[14642.628763ms] java.util.stream.Stream:collect() #163 +---[0.007086ms] java.lang.StringBuilder:() #164 +---[min=0.004245ms,max=0.023373ms,total=0.033361ms,count=3] java.lang.StringBuilder:append() #164 +---[0.006404ms] java.lang.System:currentTimeMillis() #164 +---[0.004974ms] java.lang.StringBuilder:toString() #164 +---[0.154858ms] org.slf4j.Logger:info() #164 +---[0.005872ms] java.lang.System:currentTimeMillis() #166 +---[7.02309ms] com.joyowo.smarthr.social.app.service.soc.service.excel.excelImpl.SocImportInsurancePolicyServiceImpl:checkInsuredType() #169 +---[0.007092ms] java.lang.StringBuilder:() #171 +---[min=0.004313ms,max=0.007412ms,total=0.018182ms,count=3] java.lang.StringBuilder:append() #171 +---[0.005551ms] java.lang.System:currentTimeMillis() #171 +---[0.006326ms] java.lang.StringBuilder:toString() #171 +---[0.062544ms] org.slf4j.Logger:info() #171 +---[0.006236ms] java.util.List:addAll() #174 +---[30456.739038ms] com.joyowo.smarthr.social.app.service.soc.service.SocImportMiddlePolicyService:insertSocImportMiddleExcel() #175 `---[0.067713ms] com.joyowo.smarthr.social.infra.dto.soc.socserviceinfo.ImportServiceResDto:() #177 修改完核心线程数后、在进行监控发现性能并未得到提升。这样让我陷入困境。后面思考很久才反应过来虽然builderPolicyImportQuery执行的最长时间不超过1.7秒。但是一次行导入数据量太大了、不过怎么样线程阻塞时是避免不了的，但是能不能减少线程阻塞的时间让builderPolicyImportQuery运行的速度更加快。现在我用开始监控分析builderPolicyImportQuery()方法 [arthas@63089]$ trace com.joyowo.smarthr.social.app.service.soc.service.excel.excelImpl.SocImportInsurancePolicyServiceImpl builderPolicyImportQuery -n 5 --skipJDKMethod false Press Q or Ctrl+C to abort. `---ts=2021-12-20 17:27:50;thread_name=consumer-queue_one-thread-3;id=107;is_daemon=false;priority=5;TCCL=org.springframework.boot.web.embedded.tomcat.TomcatEmbeddedWebappClassLoader@2eb217bb `---[616.425333ms] com.joyowo.smarthr.social.app.service.soc.service.excel.excelImpl.SocImportInsurancePolicyServiceImpl:builderPolicyImportQuery() +---[84.994047ms] com.joyowo.smarthr.social.app.service.soc.service.excel.excelImpl.SocImportInsurancePolicyServiceImpl:buildValidateServiceName() #266 +---[0.011161ms] com.joyowo.smarthr.social.infra.dto.soc.socPolicyPackageImport.InsurancePolicyImportResultDTO:getInsurancePolicyImportQueryList() #267 +---[0.008431ms] com.joyowo.smarthr.social.infra.dto.soc.socPolicyPackageImport.InsurancePolicyImportResultDTO:getValidateCode() #268 +---[207.762527ms] com.joyowo.smarthr.social.app.service.soc.service.excel.excelImpl.SocImportInsurancePolicyServiceImpl:verificationInsurancePolicy() #273 +---[0.006818ms] com.joyowo.smarthr.social.infra.dto.soc.socPolicyPackageImport.InsurancePolicyImportResultDTO:getInsurancePolicyImportQueryList() #274 +---[0.005635ms] com.joyowo.smarthr.social.infra.dto.soc.socPolicyPackageImport.InsurancePolicyImportResultDTO:getValidateCode() #275 +---[0.029254ms] com.joyowo.smarthr.social.app.service.soc.service.excel.excelImpl.SocImportInsurancePolicyServiceImpl:JudgeBasicInformation() #280 +---[0.04544ms] com.joyowo.smarthr.social.app.service.soc.service.excel.excelImpl.SocImportInsurancePolicyServiceImpl:validationSuccessfulData() #285 +---[0.00473ms] com.joyowo.smarthr.social.infra.dto.soc.socPolicyPackageImport.InsurancePolicyImportResultDTO:getInsurancePolicyImportQueryList() #286 +---[0.004546ms] com.joyowo.smarthr.social.infra.dto.soc.socPolicyPackageImport.InsurancePolicyImportResultDTO:getValidateCode() #287 +---[323.311175ms] com.joyowo.smarthr.social.app.service.soc.service.excel.excelImpl.SocImportInsurancePolicyServiceImpl:validSeasonYearPayment() #293 +---[0.006555ms] com.joyowo.smarthr.social.infra.dto.soc.socPolicyPackageImport.InsurancePolicyImportResultDTO:getInsurancePolicyImportQueryList() #294 `---[0.004222ms] com.joyowo.smarthr.social.infra.dto.soc.socPolicyPackageImport.InsurancePolicyImportResultDTO:getValidateCode() #295 [207.762527ms] com.joyowo.smarthr.social.app.service.soc.service.excel.excelImpl.SocImportInsurancePolicyServiceImpl:verificationInsurancePolicy() #273 这块涉及的表查询比较多暂时先放着 看下+---[323.311175ms] com.joyowo.smarthr.social.app.service.soc.service.excel.excelImpl.SocImportInsurancePolicyServiceImpl:validSeasonYearPayment() #293 里面的主体方法为 public static String check(Object obj) { Class clazz = obj.getClass(); Field[] fields = clazz.getDeclaredFields(); DataCheckBus bus = new DataCheckBus(); // 可以进行优化. try { for (Field field : fields) { boolean fieldHasAnno = field.isAnnotationPresent(DataCheckAno.class); field.setAccessible(true); if (field.getName().equals(\"subject\")) { bus.addCtxValue(\"缴纳主体\", field.get(obj)); } if (fieldHasAnno) { DataCheckAno dataCheckAno = field.getAnnotation(DataCheckAno.class); boolean isExcelProperty = field.isAnnotationPresent(ExcelProperty.class); String msg = dataCheckAno.errMsg(); if (isExcelProperty) { ExcelProperty excelProperty = field.getAnnotation(ExcelProperty.class); if (StringUtils.isEmpty(msg)) { msg = excelProperty.value()[0] + \"有问题\"; } } Object value = field.get(obj); if (Objects.nonNull(value)) { DataCheck dataCheck = DataCheckFactory.CreateDataCheck(dataCheckAno.checkType(), getCheckElements(dataCheckAno), value.toString(), dataCheckAno.splitChar(), msg); bus.addDataCheck(field.getName(), dataCheck); } bus.addCtxValue(field.getName(), value); } } // 这里利用阿里开源的 QLExpress表达式.进行多个字段的匹配. bus.exec(); } catch (Exception e) { log.error(\"出错了\", e); return e.getMessage(); } return bus.getErrMsg(); } 线程池优化后代码 public static String check(Object obj) { Class clazz = obj.getClass(); Field[] fields = clazz.getDeclaredFields(); DataCheckBus bus = new DataCheckBus(); List> completableFutureList = Arrays.stream(fields) .map(field -> CompletableFuture.supplyAsync(() -> getDataCheckBus(obj, bus, field))) .collect(Collectors.toList()); Optional first = completableFutureList.stream().map(CompletableFuture::join) .map(DataCheckBus::getErrMsg) .findFirst(); return first.orElse(\"\"); } private static DataCheckBus getDataCheckBus(Object obj, DataCheckBus bus, Field field) { try { boolean fieldHasAnno = field.isAnnotationPresent(DataCheckAno.class); field.setAccessible(true); if (field.getName().equals(\"subject\")) { bus.addCtxValue(\"缴纳主体\", field.get(obj)); } if (fieldHasAnno) { DataCheckAno dataCheckAno = field.getAnnotation(DataCheckAno.class); boolean isExcelProperty = field.isAnnotationPresent(ExcelProperty.class); String msg = dataCheckAno.errMsg(); if (isExcelProperty) { ExcelProperty excelProperty = field.getAnnotation(ExcelProperty.class); if (StringUtils.isEmpty(msg)) { msg = excelProperty.value()[0] + \"有问题\"; } } Object value; value = field.get(obj); if (Objects.nonNull(value)) { DataCheck dataCheck = DataCheckFactory.CreateDataCheck(dataCheckAno.checkType(), getCheckElements(dataCheckAno), value.toString(), dataCheckAno.splitChar(), msg); bus.addDataCheck(field.getName(), dataCheck); } bus.addCtxValue(field.getName(), value); } } catch (Exception e) { log.error(\"出错了\", e); bus.setErrMsg(e.getMessage()); } return bus; } 执行监控脚本 `---ts=2021-12-20 17:52:00;thread_name=http-nio-9130-exec-8;id=df;is_daemon=true;priority=5;TCCL=org.springframework.boot.web.embedded.tomcat.TomcatEmbeddedWebappClassLoader@22794e83 `---[30014.605814ms] com.joyowo.smarthr.social.app.service.soc.service.excel.excelImpl.SocImportInsurancePolicyServiceImpl$$EnhancerBySpringCGLIB$$ffc811e0:fileImportLogic() `---[30014.577853ms] org.springframework.cglib.proxy.MethodInterceptor:intercept() `---[30014.535968ms] com.joyowo.smarthr.social.app.service.soc.service.excel.excelImpl.SocImportInsurancePolicyServiceImpl:fileImportLogic() +---[110.543212ms] com.joyowo.smarthr.social.common.util.ConvertUtil:convertList() #116 +---[0.006952ms] org.apache.commons.collections.CollectionUtils:isEmpty() #117 +---[0.007221ms] java.util.List:parallelStream() #124 +---[0.00729ms] java.util.stream.Stream:peek() #125 +---[0.004984ms] java.util.stream.Stream:filter() #130 +---[0.005093ms] java.util.stream.Collectors:toList() #131 +---[1.525554ms] java.util.stream.Stream:collect() #131 +---[0.006266ms] java.util.ArrayList:() #134 +---[0.020966ms] java.util.List:get() #137 +---[0.010964ms] com.joyowo.smarthr.social.infra.vo.soc.incr.InsurancePolicyImportQuery:getVersion() #138 +---[0.008972ms] org.apache.commons.lang3.StringUtils:isNotEmpty() #139 +---[0.011198ms] java.util.List:parallelStream() #147 +---[0.006467ms] java.util.stream.Stream:filter() #148 +---[0.006202ms] java.util.stream.Collectors:groupingBy() #149 +---[0.249894ms] java.util.stream.Stream:collect() #149 +---[0.033361ms] java.util.Map:forEach() #150 +---[0.005818ms] java.lang.System:currentTimeMillis() #153 +---[0.005607ms] java.util.List:stream() #156 +---[0.005114ms] java.util.stream.Stream:map() #157 +---[0.004887ms] java.util.stream.Collectors:toList() #158 +---[0.750822ms] java.util.stream.Stream:collect() #158 +---[0.006638ms] java.util.List:stream() #161 +---[0.00571ms] java.util.stream.Stream:map() #162 +---[0.006889ms] java.util.stream.Stream:flatMap() #162 +---[0.004805ms] java.util.stream.Collectors:toList() #163 +---[2313.680118ms] java.util.stream.Stream:collect() #163 +---[0.006116ms] java.lang.StringBuilder:() #164 +---[min=0.00523ms,max=0.011674ms,total=0.023571ms,count=3] java.lang.StringBuilder:append() #164 +---[0.005221ms] java.lang.System:currentTimeMillis() #164 +---[0.017401ms] java.lang.StringBuilder:toString() #164 +---[0.08629ms] org.slf4j.Logger:info() #164 +---[0.008679ms] java.lang.System:currentTimeMillis() #166 +---[2.850653ms] com.joyowo.smarthr.social.app.service.soc.service.excel.excelImpl.SocImportInsurancePolicyServiceImpl:checkInsuredType() #169 +---[0.006886ms] java.lang.StringBuilder:() #171 +---[min=0.00595ms,max=0.013286ms,total=0.028281ms,count=3] java.lang.StringBuilder:append() #171 +---[0.019469ms] java.lang.System:currentTimeMillis() #171 +---[0.007883ms] java.lang.StringBuilder:toString() #171 +---[0.103541ms] org.slf4j.Logger:info() #171 +---[0.007226ms] java.util.List:addAll() #174 +---[27583.77427ms] com.joyowo.smarthr.social.app.service.soc.service.SocImportMiddlePolicyService:insertSocImportMiddleExcel() #175 `---[0.009766ms] com.joyowo.smarthr.social.infra.dto.soc.socserviceinfo.ImportServiceResDto:() #177 从上面看 +---[2313.680118ms] java.util.stream.Stream:collect() #163 由原来的14秒降为2.5秒左右，可以看出优化后的效果很明显了,但是数据库插入还是需要优化的空间很大，插入数量需要27.5秒。还是不能容忍。 8、[26613.044218ms] com.joyowo.smarthr.social.app.service.soc.service.SocImportMiddlePolicyService:insertSocImportMiddleExcel() #175 优化 社保插入代码定位 @Override public void insertSocImportMiddleExcel(List insurancePolicyImportQueryList, Long staffId) { InsurancePolicyImportQuery insurancePolicyImportQuery01 = insurancePolicyImportQueryList.get(0); String version = insurancePolicyImportQuery01.getVersion(); // 单个政策包分组. Map, List> serviceNameMap; if (StringUtils.isEmpty(version)) { // 正常的政策包数据的导入. serviceNameMap = insurancePolicyImportQueryList .stream() .collect(Collectors.groupingBy(insurancePolicyImportQuery -> Optional.ofNullable(insurancePolicyImportQuery.getServiceName()))); } else { // 期初数据的处理 serviceNameMap = insurancePolicyImportQueryList .stream() .collect(Collectors.groupingBy(insurancePolicyImportQuery -> Optional.of(new OldInsurance(insurancePolicyImportQuery.getServiceName(), insurancePolicyImportQuery.getVersion())))); } // 批量导入政策包下面对应的险种明细. serviceNameMap.forEach((serviceName, listInsurancePolicyImportQuery) -> batchInsertPolicyDetails(listInsurancePolicyImportQuery, staffId)); } 利用Arthas进行链路监控 [arthas@2639]$ trace com.joyowo.smarthr.social.app.service.soc.service.excel.excelImpl.SocImportMiddlePolicyServiceImpl insertSocImportMiddleExcel -n 5 --skipJDKMethod false Press Q or Ctrl+C to abort. Affect(class count: 2 , method count: 2) cost in 155 ms, listenerId: 2 `---ts=2021-12-20 18:03:58;thread_name=http-nio-9130-exec-1;id=d8;is_daemon=true;priority=5;TCCL=org.springframework.boot.web.embedded.tomcat.TomcatEmbeddedWebappClassLoader@22794e83 `---[29677.192994ms] com.joyowo.smarthr.social.app.service.soc.service.excel.excelImpl.SocImportMiddlePolicyServiceImpl$$EnhancerBySpringCGLIB$$c3100da3:insertSocImportMiddleExcel() `---[29677.131038ms] org.springframework.cglib.proxy.MethodInterceptor:intercept() `---[29677.047348ms] com.joyowo.smarthr.social.app.service.soc.service.excel.excelImpl.SocImportMiddlePolicyServiceImpl:insertSocImportMiddleExcel() +---[0.034151ms] java.util.List:get() #76 +---[0.009812ms] com.joyowo.smarthr.social.infra.vo.soc.incr.InsurancePolicyImportQuery:getVersion() #77 +---[0.010957ms] org.springframework.util.StringUtils:isEmpty() #81 +---[0.013738ms] java.util.List:stream() #84 +---[0.033014ms] java.util.stream.Collectors:groupingBy() #85 +---[0.232753ms] java.util.stream.Stream:collect() #85 `---[29675.068969ms] java.util.Map:forEach() #94 可以看出为这里以单个政策包集合维度循环遍历插入，消耗了大量的时间（ps:可能有同学问为啥不直接批量插入，为啥以政策包纬度拆分成多个政策包集合循环插入，因为在开始的设计中假设专员导入20个政策包，一个政策包里面有20条数据，如果全部批量导入其中一个政策包导入有问题，会导致其他19个政策包也受到影响全部回滚，同时事物过大，也会有死锁性能瓶颈，改成单个政策包插入失败不影响其他的已经导入成功的政策包，同时也适应版本产品业务的扩展） 现在将循环插入改成异步线程同时插入进行优化 优化后的代码如下 @Override public void insertSocImportMiddleExcel(List insurancePolicyImportQueryList, Long staffId) { InsurancePolicyImportQuery insurancePolicyImportQuery01 = insurancePolicyImportQueryList.get(0); String version = insurancePolicyImportQuery01.getVersion(); // 单个政策包分组. Map, List> serviceNameMap; if (StringUtils.isEmpty(version)) { // 正常的政策包数据的导入. serviceNameMap = insurancePolicyImportQueryList .stream() .collect(Collectors.groupingBy(insurancePolicyImportQuery -> Optional.ofNullable(insurancePolicyImportQuery.getServiceName()))); } else { // 期初数据的处理 serviceNameMap = insurancePolicyImportQueryList .stream() .collect(Collectors.groupingBy(insurancePolicyImportQuery -> Optional.of(new OldInsurance(insurancePolicyImportQuery.getServiceName(), insurancePolicyImportQuery.getVersion())))); } // 批量导入政策包下面对应的险种明细. List> completableFutureList = serviceNameMap.values().stream() .map(listInsurancePolicyImportQuery -> CompletableFuture.runAsync(() -> batchInsertPolicyDetails(listInsurancePolicyImportQuery, staffId), executorServiceThreadPool)) .collect(Collectors.toList()); List collect = completableFutureList.stream() .map(CompletableFuture::join) .collect(Collectors.toList()); } 利用Arthas第二次进行链路监控 `---ts=2021-12-20 18:18:26;thread_name=http-nio-9130-exec-1;id=c9;is_daemon=true;priority=5;TCCL=org.springframework.boot.web.embedded.tomcat.TomcatEmbeddedWebappClassLoader@1dc7aa5e `---[5773.558748ms] com.joyowo.smarthr.social.app.service.soc.service.excel.excelImpl.SocImportInsurancePolicyServiceImpl$$EnhancerBySpringCGLIB$$4955362a:fileImportLogic() `---[5773.527098ms] org.springframework.cglib.proxy.MethodInterceptor:intercept() `---[5773.482916ms] com.joyowo.smarthr.social.app.service.soc.service.excel.excelImpl.SocImportInsurancePolicyServiceImpl:fileImportLogic() +---[88.971279ms] com.joyowo.smarthr.social.common.util.ConvertUtil:convertList() #116 +---[0.003749ms] org.apache.commons.collections.CollectionUtils:isEmpty() #117 +---[0.003795ms] java.util.List:parallelStream() #124 +---[0.005299ms] java.util.stream.Stream:peek() #125 +---[0.003141ms] java.util.stream.Stream:filter() #130 +---[0.003218ms] java.util.stream.Collectors:toList() #131 +---[0.30375ms] java.util.stream.Stream:collect() #131 +---[0.00307ms] java.util.ArrayList:() #134 +---[0.002584ms] java.util.List:get() #137 +---[0.003098ms] com.joyowo.smarthr.social.infra.vo.soc.incr.InsurancePolicyImportQuery:getVersion() #138 +---[0.002834ms] org.apache.commons.lang3.StringUtils:isNotEmpty() #139 +---[0.003085ms] java.util.List:parallelStream() #147 +---[0.003221ms] java.util.stream.Stream:filter() #148 +---[0.003221ms] java.util.stream.Collectors:groupingBy() #149 +---[0.10336ms] java.util.stream.Stream:collect() #149 +---[0.043665ms] java.util.Map:forEach() #150 +---[0.003108ms] java.lang.System:currentTimeMillis() #153 +---[0.002985ms] java.util.List:stream() #156 +---[0.002976ms] java.util.stream.Stream:map() #157 +---[0.002776ms] java.util.stream.Collectors:toList() #158 +---[0.385588ms] java.util.stream.Stream:collect() #158 +---[0.004416ms] java.util.List:stream() #161 +---[0.003196ms] java.util.stream.Stream:map() #162 +---[0.004249ms] java.util.stream.Stream:flatMap() #162 +---[0.00259ms] java.util.stream.Collectors:toList() #163 +---[3091.015869ms] java.util.stream.Stream:collect() #163 +---[0.007667ms] java.lang.StringBuilder:() #164 +---[min=0.003987ms,max=0.007206ms,total=0.017818ms,count=3] java.lang.StringBuilder:append() #164 +---[0.02226ms] java.lang.System:currentTimeMillis() #164 +---[0.004207ms] java.lang.StringBuilder:toString() #164 +---[0.077231ms] org.slf4j.Logger:info() #164 +---[0.004189ms] java.lang.System:currentTimeMillis() #166 +---[1.441181ms] com.joyowo.smarthr.social.app.service.soc.service.excel.excelImpl.SocImportInsurancePolicyServiceImpl:checkInsuredType() #169 +---[0.004972ms] java.lang.StringBuilder:() #171 +---[min=0.004123ms,max=0.006863ms,total=0.01571ms,count=3] java.lang.StringBuilder:append() #171 +---[0.004527ms] java.lang.System:currentTimeMillis() #171 +---[0.003641ms] java.lang.StringBuilder:toString() #171 +---[0.046302ms] org.slf4j.Logger:info() #171 +---[0.003856ms] java.util.List:addAll() #174 +---[2590.486166ms] com.joyowo.smarthr.social.app.service.soc.service.SocImportMiddlePolicyService:insertSocImportMiddleExcel() #175 `---[0.006675ms] com.joyowo.smarthr.social.infra.dto.soc.socserviceinfo.ImportServiceResDto:() #177 政策包的插入可以看出由原来的30s已经优化到2.5s,性能提升明显。 🔌 总结 性能提升7倍 原来导入500条政策包的数据由41.7秒提升至5.7秒，但是还如我刚才所说的还是有优化空间的代码。但是目前也足够支撑业务逻辑了。在就是大批量数据插入数据库也需要2.5秒也是性能瓶颈，如果需要达到秒级话，可以使用mogodb替代mysql 结论 对于性能分析和优化一定要有合适工具，才能得出有用的结论并针对性优化。一开始我以为增加核心线程数就可以异步线程编程就万事大吉了，但实际上性能消耗的大头并不在这里。还是得借助 Arthas 的 Trace 才能真正针对性地优化。 四、👉 Arthas—常用命令汇总 实战Arthas工具Trace命令排查接口调用链路将Excel政策包导入性能提升七倍 大纲 目前线上排查整个接口的调用主要还是依赖Skywalking，但是Skywalking不能很直观的统计接口中对应的每个方法调用的次数和所消耗的时间，Arthas是Alibaba开源的Java诊断工具，通过Arthas可以得到监控。下面是我在使用在使用Arthas对社保系统中政策包导入（导入过程中涉及27张表的查询和插入，整体系统逻辑比较复杂）在排查优化过程中遇到的问题的思考的方法的排查过程。在本地调试优化后将原有的500条政策包导入数据由原来的45秒压缩至5秒多。提升整体的系统性能。 代码逻辑可以不用看，没有上下文的情况下很难明白接口什么意思。主要看Arthas Trace的结果与优化思路 优化后压测结果(还有优化空间，但是目前足以满足业务需求) 500条政策包数据导入 消耗时间5.5s 1000条政策包数据导入 消耗时间10s （ps:数据库瓶瓶颈、入库消耗4.5s） 2000条政策包数据导入 消耗时间20s （ps:数据库瓶颈，入库消耗10s） "},"chapter2/section3.html":{"url":"chapter2/section3.html","title":"2.3 代码ReCoding同步钉钉考勤记录","keywords":"","body":"代码ReCoding同步钉钉考勤记录 [!note] 目前钉钉同步考勤定时执行很慢、故做此ReCoding优化 文档: https://developers.dingtalk.com/document/app/invocation-frequency-limit 钉钉第三方文档 IP维度 每个IP调用所有接口总量，最高20秒6000次。 触发限流，会禁止调用5分钟。 企业内部应用 每个应用，调用每个接口，最高频率40次/秒。触发限流，返回错误码90018。 每个应用，调用每个接口，最高频率1500次/分。触发限流，返回错误码90006。 批量处理数据 钉钉每次限制最多批量处理50条数据 涉及的表名称 1、dd_business_info 企业客户信息表 2、dd_person 每日投保项目人员表 3、dd_attendance_record 考勤记录表 4、dd_daily_insurance_person 每日投保项目人员表 性能分析优化方案 [!note] 同步钉钉考勤打卡记录. 1、目前是定时器每半个小时执行一次(是否可以减少执行频率) 2、每次都是扫描全部的钉钉人员，如果对于已经打卡成功的需要做个标识，下次定时器进来的时候。把这批数据过滤掉。减少数据量。或者吧这批数据全部放入缓存中。减少对数据库连接的压力。 3、执行完成一次的正常平均时间是2分钟。（存在2分钟的数据库表的行级锁锁定数据，占用大量服务器资源得不到释放、从而导致很卡） 4、大事物包裹@Transactional注解包裹的整个方法都是使用同一个connection连接。出现了耗时的操作，调用钉钉第三方接口调用，业务逻辑复杂，大批量数据处理等就会导致我们我们占用这个connection的时间会很长，数据库连接一直被占用不释放。一旦类似操作过多，就会导致数据库连接池耗尽。 5、 for循环嵌套的太多，性能瓶颈。 立采用了两次递归 感觉没必要。 6、采用声明式编程式事务代替原有的spring官方自带的事物注解. 7、如果需要知道这批人员的执行成功的数据，必须采用线程池进行优化。如果不需要的话，采用RocketMQ进行解耦。宁愿每个人员的执行发送一次消息，这样可以在短时间内减少对数据库链接释放时间。 8、尽量把所有的update和insert放在同一个事物中，将select剔除出去. 将整体的事物更小细粒话。不然会出现批量执行1000条数据，其中901条失败，会将前面900已经成功的数据全部回滚，导致死锁。执行时间长达30分钟 9、代码规范需要在抽象下，一些set方法可以放在对象中 代码简洁 DDD模式 10、SELECT id FROM dd_person WHERE dd_user_id = ? AND business_id = ? AND is_delete = 0 LIMIT 1 将单个索引改成组合索引 （ KEY idx_dduserid (dd_user_id) USING BTREE,KEY idx_businessid (business_id) USING BTREE）。调用数据库的次数太多，可以考虑放到缓存redis中 . EXPLAIN SELECT id FROM dd_person WHERE dd_user_id = 403243223326492142 AND business_id = 137241432330272768 AND is_delete = 0 LIMIT 1 https://www.cnblogs.com/xuanzhi201111/p/4175635.html 表结构索引建立无效、需要修改 同步钉钉考勤记录代码重构优化 重构分支地址 master_fixedFY 重构新增技术点 1、引入线程池（自己封装的在com.joyowo.util.thread. TreadPoolConfig类下面） 2、利用CompletableFuture Java8新的异步编程方式有优化 3、基于PlatformTransactionManager的编程式事务管理优化原有的大事物。减少死锁占有数据库链接的现象 4、日志系统加入了彩色日志依赖的渲染类个人习惯 logback-spring.xml 目前重构情况 已经重构了百分之80、细节方面我并不打算在进行补充。理论上按照目前的的方案。接口应该能在10秒内跑完。目前并没有线上数据库的权限。无法进行压测评估. 后续 后续的慢接口参考目前我这边的代码建议。也可以进行优化。现在主要是给做一个范例进行参考 "},"chapter2/section4.html":{"url":"chapter2/section4.html","title":"2.4 线上JVM服务器磁盘IO、CPU占用过高排查","keywords":"","body":"线上JVM服务器磁盘IO、CPU占用过高排查 前言 [!note] 前几天运维反馈社保项目业务线上服务磁盘IO占用比较高，目前是否有占用比较多的服务磁盘IO的操作，不是数据库IO. 如果单纯再从代码功能进行排查感觉点比较多，也没有切实可行证明某个功能确实占用服务器磁盘的IO。当然我们可以通过第三方服务器（腾讯云、阿里云等）自带的监控工具进行排查和合适分析问题，这块目前整体服务架构是比较欠缺的。虽然基于目前开发是没有任何相关运维服务器的账号的。但是从探讨精神上自己的已有的服务器用JVM中自带的jstack拍个片子将排查过程方法总结梳理分享下。大部分涉及到一些运维服务的操作，如果没有一些运维服务基础、理解起来可能比较难。我这边尽量把每一步的操作梳理的更加详细，方便阅读理解 JDK命令行工具 jps (JVM Process Status）: 类似 UNIX 的 ps 命令。用于查看所有 Java 进程的启动类、传入参数和 Java 虚拟机参数等信息； jstat（JVM Statistics Monitoring Tool）: 用于收集 HotSpot 虚拟机各方面的运行数据; jinfo (Configuration Info for Java) : Configuration Info for Java,显示虚拟机配置信息; jmap (Memory Map for Java) : 生成堆转储快照; jhat (JVM Heap Dump Browser) : 用于分析 heapdump 文件，它会建立一个 HTTP/HTML 服务器，让用户可以在浏览器上查看分析结果; jstack (Stack Trace for Java) : 生成虚拟机当前时刻的线程快照，线程快照就是当前虚拟机内每一条线程正在执行的方法堆栈的集合。 查询项目进程 使用 jps 命令查询项目启动的进程 jps主要用来输出JVM中运行的进程状态信息 root@social-85d74b896d-bmzsr:/# jps -m -l -v 4806 sun.tools.jmap.JMap -histo:live 7 -Dapplication.home=/opt/java/openjdk -Xms8m -Dsun.jvm.hotspot.debugger.useProcDebugger -Dsun.jvm.hotspot.debugger.useWindbgDebugger 7319 sun.tools.jps.Jps -m -l -v -Dapplication.home=/opt/java/openjdk -Xms8m 7 smarthr-social-app-1.0.0-SNAPSHOT.jar -Xms2048m -Xmx2048m -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/logs 命令行参数选项说明如下： -q 不输出类名、Jar名和传入main方法的参数 -m 输出传入main方法的参数 -l 输出main类或Jar的全限名 -v 输出传入JVM的参数 使用 ps -ef | grep java 同样可以查询进程号 root@social-85d74b896d-bmzsr:/# ps -ef | grep java root 1 0 0 Sep24 ? 00:00:00 sh -c java $JAVA_OPTS -jar *.jar root 7 1 1 Sep24 ? 06:31:36 java -Xms2048m -Xmx2048m -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/logs -jar smarthr-social-app-1.0.0-SNAPSHOT.jar root 7389 7291 0 17:12 pts/7 00:00:00 grep --color=auto java 熟悉使用使用pidstat工具 pidstat概述 pidstat是sysstat工具的一个命令，用于监控全部或指定进程的cpu、内存、线程、设备IO等系统资源的占用情况 pidstat 安装与基础命令总结 在Debian/Ubuntu系统中可以使用下面的命令来安装 apt-get install sysstat root@social-85d74b896d-bmzsr:/# apt-get install sysstat Reading package lists... Done Building dependency tree Reading state information... Done sysstat is already the newest version (11.6.1-1ubuntu0.1). 0 upgraded, 0 newly installed, 0 to remove and 51 not upgraded. root@social-85d74b896d-bmzsr:/# 查看所有进程的 CPU 使用情况（pidstat -u -p ALL） root@social-85d74b896d-bmzsr:/# pidstat Linux 4.4.237-1.el7.elrepo.x86_64 (social-85d74b896d-bmzsr) 10/13/2021 _x86_64_ (8 CPU) 05:19:53 PM UID PID %usr %system %guest %wait %CPU CPU Command 05:19:53 PM 0 7 0.09 0.06 0.00 0.00 0.15 6 java 05:19:53 PM 0 4806 0.00 0.00 0.00 0.00 0.00 5 jmap 05:19:53 PM 0 7408 0.00 0.00 0.00 0.00 0.00 2 bash 05:19:53 PM 0 29258 0.00 0.00 0.00 0.00 0.00 6 bash 05:19:53 PM 0 29787 0.00 0.00 0.00 0.00 0.00 3 top 05:19:53 PM 0 30124 0.00 0.00 0.00 0.00 0.00 4 bash cpu使用情况统计(-u) pidstat -u 内存使用情况统计(-r) pidstat -r 显示各个进程的IO使用情况（-d） pidstat -d root@social-85d74b896d-bmzsr:/# pidstat -d Linux 4.4.237-1.el7.elrepo.x86_64 (social-85d74b896d-bmzsr) 10/13/2021 _x86_64_ (8 CPU) 05:27:23 PM UID PID kB_rd/s kB_wr/s kB_ccwr/s iodelay Command 05:27:23 PM 0 7 0.00 5.41 0.00 0 java 05:27:23 PM 0 4736 0.00 0.00 0.00 0 bash 05:27:23 PM 0 4806 0.00 0.00 0.00 0 jmap 05:27:23 PM 0 4807 0.00 0.00 0.00 2 more 05:27:23 PM 0 7408 0.00 0.00 0.00 0 bash 05:27:23 PM 0 29787 0.00 0.00 0.00 0 top 05:27:23 PM 0 30124 0.00 0.00 0.00 0 bash 05:27:23 PM 0 30575 0.01 0.00 0.00 0 bash IO现实说明 PID :进程id kB_rd/s :每秒从磁盘读取的KB kB_wr/s :每秒写入磁盘KB kB_ccwr/s :任务取消的写入磁盘的KB。当任务截断脏的pagecache的时候会发生。 Command :task的命令名 显示选择任务的线程的统计信息外的额外信息 (-t) pidstat -t -p 7 root@social-85d74b896d-bmzsr:/# pidstat -t -p 7 Linux 4.4.237-1.el7.elrepo.x86_64 (social-85d74b896d-bmzsr) 10/13/2021 _x86_64_ (8 CPU) 05:32:56 PM UID TGID TID %usr %system %guest %wait %CPU CPU Command 05:32:56 PM 0 7 - 0.09 0.06 0.00 0.00 0.15 6 java 05:32:56 PM 0 - 7 0.00 0.00 0.00 0.00 0.00 6 |__java 05:32:56 PM 0 - 8 0.00 0.00 0.00 0.00 0.00 4 |__java 05:32:56 PM 0 - 9 0.00 0.00 0.00 0.00 0.00 2 |__VM Thread 05:32:56 PM 0 - 10 0.00 0.00 0.00 0.00 0.00 0 |__Reference Handl 05:32:56 PM 0 - 11 0.00 0.00 0.00 0.00 0.00 5 |__Finalizer 05:32:56 PM 0 - 17 0.00 0.00 0.00 0.00 0.00 7 |__Signal Dispatch 05:32:56 PM 0 - 18 0.00 0.00 0.00 0.00 0.00 4 |__C2 CompilerThre 05:32:56 PM 0 - 19 0.00 0.00 0.00 0.00 0.00 7 |__C1 CompilerThre 05:32:56 PM 0 - 21 0.00 0.00 0.00 0.00 0.00 2 |__Service Thread 05:32:56 PM 0 - 22 0.00 0.00 0.00 0.02 0.00 3 |__VM Periodic Tas 05:32:56 PM 0 - 33 0.00 0.00 0.00 0.00 0.00 0 |__Timer-0 05:32:56 PM 0 - 34 0.00 0.00 0.00 0.00 0.00 7 |__com.alibaba.nac 05:32:56 PM 0 - 35 0.01 0.01 0.00 0.06 0.01 1 |__com.alibaba.nac 05:32:56 PM 0 - 41 0.00 0.00 0.00 0.02 0.01 4 |__logback-appende 05:32:56 PM 0 - 42 0.00 0.00 0.00 0.00 0.00 1 |__logback-appende 05:32:56 PM 0 - 43 0.00 0.00 0.00 0.00 0.00 4 |__logback-appende 05:32:56 PM 0 - 45 0.00 0.00 0.00 0.00 0.00 6 |__GC Daemon 05:32:56 PM 0 - 48 0.00 0.00 0.00 0.00 0.00 2 |__spring.cloud.in 05:32:56 PM 0 - 49 0.00 0.00 0.00 0.00 0.00 7 |__com.alibaba.nac 05:32:56 PM 0 - 50 0.00 0.00 0.00 0.00 0.00 6 |__com.alibaba.nac 05:32:56 PM 0 - 51 0.00 0.00 0.00 0.00 0.00 7 |__com.alibaba.nac 05:32:56 PM 0 - 52 0.00 0.00 0.00 0.00 0.00 6 |__com.alibaba.nac 05:32:56 PM 0 - 53 0.00 0.00 0.00 0.00 0.00 6 |__com.alibaba.nac 05:32:56 PM 0 - 54 0.00 0.00 0.00 0.00 0.00 7 |__Thread-22 05:32:56 PM 0 - 55 0.00 0.00 0.00 0.01 0.00 0 |__SimplePauseDete 05:32:56 PM 0 - 57 0.00 0.00 0.00 0.00 0.00 5 |__commons-pool-ev 05:32:56 PM 0 - 58 0.00 0.00 0.00 0.00 0.00 6 |__Abandoned conne 05:32:56 PM 0 - 59 0.00 0.00 0.00 0.00 0.00 4 |__DatebookHikariC 05:32:56 PM 0 - 60 0.00 0.00 0.00 0.00 0.00 6 |__DatebookHikariC 05:32:56 PM 0 - 63 0.00 0.00 0.00 0.00 0.00 3 |__RxIoScheduler-1 05:32:56 PM 0 - 64 0.00 0.00 0.00 0.00 0.00 5 |__ContainerBackgr 05:32:56 PM 0 - 65 0.00 0.00 0.00 0.00 0.00 5 |__container-0 05:32:56 PM 0 - 66 0.00 0.00 0.00 0.00 0.00 1 |__FeignApacheHttp 05:32:56 PM 0 - 67 0.00 0.00 0.00 0.00 0.00 2 |__redisson-netty- TGID:主线程的表示 TID:线程id %usr：进程在用户空间占用cpu的百分比 %system：进程在内核空间占用cpu的百分比 %guest：进程在虚拟机占用cpu的百分比 %CPU：进程占用cpu的百分比 Command：当前进程对应的命令 使用 pidstat 工具查询Java项目cpu占用情况 ➜ ~ ps -ef|grep java ## 其中 187857 就是java项目进程 root 187857 185541 99 Oct12 ? 1-03:33:08 /opt/jdk1.8.0_301/bin/java -Xms256m -Xmx256m -Dspring.profiles.active=dev -Dserver.port=9899 -jar /opt/webApp/feetoms1/target/feet-oms-0.0.1-SNAPSHOT.jar ## -p 指定进程号 ## 15539 即进程号 紧跟 -p后面 ## -t 展示进程下的线程资源占用情况 ## 1 每秒刷新1次 ## 1 共刷新一次 ~ pidstat -p 187857 -t -d 1 1 Linux 5.10.23-5.al8.x86_64 (iZ8vb11w0foe0ne254sjbhZ) 10/13/2021 _x86_64_ (2 CPU) ## 通过查询出的信息可以检测到 线程号：187915 占用了很大的磁盘IO 06:39:15 PM UID TGID TID kB_rd/s kB_wr/s kB_ccwr/s iodelay Command 06:39:16 PM 0 187857 - 0.00 592.00 0.00 0 java 06:39:16 PM 0 - 187857 0.00 0.00 0.00 0 |__java 06:39:16 PM 0 - 187858 0.00 0.00 0.00 0 |__java 06:39:16 PM 0 - 187859 0.00 0.00 0.00 0 |__java 06:39:16 PM 0 - 187860 0.00 0.00 0.00 0 |__java 06:39:16 PM 0 - 187861 0.00 0.00 0.00 0 |__java 06:39:16 PM 0 - 187862 0.00 0.00 0.00 0 |__java 06:39:16 PM 0 - 187863 0.00 0.00 0.00 0 |__java 06:39:16 PM 0 - 187864 0.00 0.00 0.00 0 |__java 06:39:16 PM 0 - 187865 0.00 0.00 0.00 0 |__java 06:39:16 PM 0 - 187866 0.00 0.00 0.00 0 |__java 06:39:16 PM 0 - 187867 0.00 0.00 0.00 0 |__java 06:39:16 PM 0 - 187868 0.00 0.00 0.00 0 |__java 06:39:16 PM 0 - 187884 0.00 0.00 0.00 0 |__java 06:39:16 PM 0 - 187885 0.00 0.00 0.00 0 |__java 06:39:16 PM 0 - 187886 0.00 0.00 0.00 0 |__java 06:39:16 PM 0 - 187887 0.00 0.00 0.00 0 |__java 06:39:16 PM 0 - 187888 0.00 0.00 0.00 0 |__java 06:39:16 PM 0 - 187889 0.00 0.00 0.00 0 |__java 06:39:16 PM 0 - 187896 0.00 0.00 0.00 0 |__java 06:39:16 PM 0 - 187897 0.00 0.00 0.00 0 |__java 06:39:16 PM 0 - 187898 0.00 0.00 0.00 0 |__java 06:39:16 PM 0 - 187900 0.00 0.00 0.00 0 |__java 06:39:16 PM 0 - 187901 0.00 0.00 0.00 0 |__java 06:39:16 PM 0 - 187902 0.00 0.00 0.00 0 |__java 06:39:16 PM 0 - 187903 0.00 0.00 0.00 0 |__java 06:39:16 PM 0 - 187904 0.00 0.00 0.00 0 |__java 06:39:16 PM 0 - 187905 0.00 0.00 0.00 0 |__java 06:39:16 PM 0 - 187906 0.00 0.00 0.00 0 |__java 06:39:16 PM 0 - 187907 0.00 0.00 0.00 0 |__java 06:39:16 PM 0 - 187908 0.00 0.00 0.00 0 |__java 06:39:16 PM 0 - 187909 0.00 0.00 0.00 0 |__java 06:39:16 PM 0 - 187910 0.00 0.00 0.00 0 |__java 06:39:16 PM 0 - 187911 0.00 0.00 0.00 0 |__java 06:39:16 PM 0 - 187912 0.00 0.00 0.00 0 |__java 06:39:16 PM 0 - 187913 0.00 0.00 0.00 0 |__java 06:39:16 PM 0 - 187914 0.00 0.00 0.00 0 |__java 06:39:16 PM 0 - 187915 0.00 592.00 0.00 0 |__java 06:39:16 PM 0 - 187916 0.00 0.00 0.00 0 |__java 06:39:16 PM 0 - 187917 0.00 0.00 0.00 0 |__java 06:39:16 PM 0 - 187918 0.00 0.00 0.00 0 |__java 06:39:16 PM 0 - 187954 0.00 0.00 0.00 0 |__java 06:39:16 PM 0 - 187960 0.00 0.00 0.00 0 |__java 06:39:16 PM 0 - 187961 0.00 0.00 0.00 0 |__java 06:39:16 PM 0 - 187962 0.00 0.00 0.00 0 |__java 06:39:16 PM 0 - 187963 0.00 0.00 0.00 0 |__java 06:39:16 PM 0 - 187964 0.00 0.00 0.00 0 |__java 使用jstack工具打印堆栈信息 jstack主要用来查看某个Java进程内的线程堆栈信息。 jstack可以定位到线程堆栈，根据堆栈信息我们可以定位到具体代码，所以它在JVM性能调优中使用得非常多.也可以利用该命令打印java线程的堆栈跟踪，可以得知哪些线程被阻塞或正等待，以便于查找如线程死锁等原因 ➜ ~ ps -ef|grep java ## 其中 187857 就是java项目进程 root 187857 185541 99 Oct12 ? 1-03:35:53 /opt/jdk1.8.0_301/bin/java -Xms256m -Xmx256m -Dspring.profiles.active=dev -Dserver.port=9899 -jar /opt/webApp/feetoms1/target/feet-oms-0.0.1-SNAPSHOT.jar 根据线程ID(187915)，在jstack查询对应的堆栈信息 kB_wr/s 就是各个Java线程当时的写入磁盘KB，上面我们已经看到写入磁盘KB最大线程是187915 ## 注意 此处根据 pidstat获取的线程号是 十进制。但是 jstack打印的堆栈信息中的nid是十六进制，因此需要做一层进制转换，187915转十六进制为2de0b ➜ ~ printf \"%x\\n\" 187915 2de0b 可以使用jstack来输出进程187857的堆栈信息，然后根据线程ID的十六进制值grep，如下： ➜ ~ jstack 187857 | grep 2de0b -A10 \"Thread-6\" #38 prio=5 os_prio=0 tid=0x00007efe94f12000 nid=0x2de0b runnable [0x00007efe5d0be000] java.lang.Thread.State: RUNNABLE at java.io.FileInputStream.read0(Native Method) at java.io.FileInputStream.read(FileInputStream.java:207) at com.crm.oms.component.FullIOTask.run(FullIOTask.java:24) at java.lang.Thread.run(Thread.java:748) \"http-nio-9899-Acceptor-0\" #36 daemon prio=5 os_prio=0 tid=0x00007efe9436f800 nid=0x2de0a runnable [0x00007efe5d1bf000] java.lang.Thread.State: RUNNABLE at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method) at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:424) 可以看磁盘IO量最大的在FullIOTask这类下面的run()方法，那我现在找下我写的demo定位到下面的代码 package com.crm.oms.component; import java.io.FileInputStream; import java.io.FileOutputStream; import java.io.IOException; /** * IO 操作频繁的任务 * * @author lfg * @version 1.0 */ public class FullIOTask implements Runnable { @Override public void run() { while (true) { try { FileOutputStream fileOutputStream = new FileOutputStream(\"tempFile.txt\"); for (int i = 0; i 结论:从上面线程的堆栈信息我们可以看到当前这个线程是出于运行状态的，频繁的文件流读取关闭，导致服务器内磁盘IO频繁 利用jstack拷贝当前进程下进程的堆栈信息 ## 187857 进程号 ## > jstack.text 将堆栈信息打到 当前目录下的jstack.text文件中 ➜ ~ jstack 187857 > jstack.text 2de0b Jstack扩展 当前tomcat线程状态的种类 线程状态为“waiting on condition” java.lang.Thread.State: WAITING (parking)：一直等那个条件发生； java.lang.Thread.State: TIMED_WAITING (parking或sleeping)：定时的，那个条件不到来，也将定时唤醒自己 如果大量线程在“waiting on condition”： 可能是它们又跑去获取第三方资源，尤其是第三方网络资源，迟迟获取不到Response，导致大量线程进入等待状态。 所以如果发现有大量的线程都处在 Wait on condition，从线程堆栈看，正等待网络读写，这可能是一个网络瓶颈的征兆，因为网络阻塞导致线程无法执行。 线程状态为“waiting for monitor entry” java.lang.Thread.State: BLOCKED (on object monitor) : 意味着它 在等待进入一个临界区 ，所以它在”Entry Set“队列中等待。此时线程状态一般都是 Blocked 如果大量线程在“waiting for monitor entry”,可能是一个全局锁阻塞住了大量线程. rwaiting for monitor entry 的线程越来越多，没有减少的趋势，可能意味着某些线程在临界区里呆的时间太长了，以至于越来越多新线程迟迟无法进入临界区。 实例操作说明 ➜ ~ cat jstack.text |grep 'java.lang.Thread.State' |grep 'parking' java.lang.Thread.State: WAITING (parking) java.lang.Thread.State: WAITING (parking) java.lang.Thread.State: WAITING (parking) java.lang.Thread.State: WAITING (parking) java.lang.Thread.State: WAITING (parking) java.lang.Thread.State: WAITING (parking) java.lang.Thread.State: WAITING (parking) java.lang.Thread.State: WAITING (parking) java.lang.Thread.State: WAITING (parking) java.lang.Thread.State: WAITING (parking) java.lang.Thread.State: WAITING (parking) java.lang.Thread.State: WAITING (parking) java.lang.Thread.State: WAITING (parking) java.lang.Thread.State: WAITING (parking) java.lang.Thread.State: WAITING (parking) java.lang.Thread.State: TIMED_WAITING (parking) java.lang.Thread.State: TIMED_WAITING (parking) java.lang.Thread.State: WAITING (parking) java.lang.Thread.State: TIMED_WAITING (parking) java.lang.Thread.State: WAITING (parking) java.lang.Thread.State: WAITING (parking) 统计当前jstack快照下 线程的状态 ➜ ~ cat jstack.text |grep 'java.lang.Thread.State' |grep 'parking'|wc -l 21 社保服务磁盘IO过高原因 由于运维权限原因，目前只有beta环境进行参考。 root@social-85d74b896d-bmzsr:/# ps -ef|grep java root 1 0 0 Sep24 ? 00:00:00 sh -c java $JAVA_OPTS -jar *.jar root 7 1 1 Sep24 ? 06:47:33 java -Xms2048m -Xmx2048m -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/logs -jar smarthr-social-app-1.0.0-SNAPSHOT.jar root 14961 14842 0 10:59 pts/12 00:00:00 grep --color=auto java root@social-85d74b896d-bmzsr:/# pidstat -p 7 -t -d 1 3 Linux 4.4.237-1.el7.elrepo.x86_64 (social-85d74b896d-bmzsr) 10/14/2021 _x86_64_ (8 CPU) 10:55:21 AM UID TGID TID kB_rd/s kB_wr/s kB_ccwr/s iodelay Command 10:55:22 AM 0 7 - 0.00 44.00 0.00 0 java 10:55:22 AM 0 - 135 0.00 12.00 0.00 1 |__xxl-job, execut 10:55:22 AM 0 - 169 0.00 8.00 0.00 1 |__Thread-35 10:55:22 AM 0 - 170 0.00 8.00 0.00 1 |__Thread-36 10:55:22 AM 0 - 171 0.00 8.00 0.00 0 |__Thread-37 执行pidstat -p 7 -t -d 1 3 但是 jstack 7 > jstack.text相关读写的操作没有权限进行没有反应，因此只能初步判定为xxl-job执行频率过高和线程池使用不规范（ps:处于队列带执行的线程过多）导致服务器磁盘IO一直处于比较高的状态。 "},"chapter2/section5.html":{"url":"chapter2/section5.html","title":"2.5 大事务导致数据库死锁、引起线上云服务器CPU利用率过高","keywords":"","body":"大事务导致数据库死锁、引起线上云服务器CPU利用率过高 简介 [!note] 今天（2021-11-01 09:36:00）腾讯云监控报警、云数据库-MySQL-主机监控报警 CPU利用率为100%，针对这样的情况，第一反应可能是不是批量数据的操作导致大事务的数据库的死锁导致的。（ps: 在之前在上线的版本中 我特别留意了线上社保相关的错误日志，其中有一种情况是大批量花名册导入会偶现死锁从而服务器CPU上升场景。当是我并没有进行深入一步的学习，现在又出现类似情况，所以联想到之前情况判断可能也是大事务导致死锁的结论). 下面我证实下关于是否是大事务导致mysql的死锁从而导致线上服务器load飙升。 引用: https://cloud.tencent.com/developer/article/1595282 https://zhuanlan.zhihu.com/p/93647727 https://cloud.tencent.com/developer/article/1669350 死锁带来的影响 如果死锁发生，会浪费大量系统资源，甚至导致系统崩溃 麒麟系统死锁隐患点 图例 [!note] 1、目前查询了整个麒麟系统线上最近两周的关于死锁的日志。已经出现了557次死锁的。服务CPU飙升等也是死锁导致的其中最重要的原因。 2、同样Review过麒麟系统其他的一些微服务，大事务、大事务多层嵌套的使用不规范比较常见。这些都为系统埋下隐患点。 反馈图例 腾讯云监控告警 数据库事件详情 MySql更新死锁问题 Deadlock found when trying to get lock; try restarting transaction ES日志定位 这块一直平稳运行近一年的代码，突然在今天前道专员导入对应的服务网点进行批量生效的时候频繁出现死锁异常，下面我就截取一段高峰期的业务日志: ### Error updating database. Cause: com.mysql.jdbc.exceptions.jdbc4.MySQLTransactionRollbackException: Deadlock found when trying to get lock; try restarting transaction ### The error may involve com.joyowo.smarthr.social.infra.mappers.SectionConfigMapper.updateByPrimaryKeySelective-Inline ### The error occurred while setting parameters ### SQL: update section_config SET soc_service_info_id = ?, is_cross_month = ?, increase_type = ?, increase_day = ?, increase_time = ?,recognize_type = ?,recognize_day = ?, recognize_time = ?, order_type = ?,order_day = ?,order_time = ?, material_type = ?, material_day = ?, material_time = ?, back_rode_type = ?, back_rode_day = ?, back_rode_time = ?, effective_start_time = ?, effective_end_time = ?, state = ?, create_time = ?, update_time = ?, verify_time = ?, create_uid = ?, update_uid = ?, verify_uid = ? where id = ? ### Cause: com.mysql.jdbc.exceptions.jdbc4.MySQLTransactionRollbackException: Deadlock found when trying to get lock; try restarting transaction 接口请求汇总 序号 日志id 异常提示 请求开始时间 请求结束时间 耗 时 1 prd_904660322688696320 成功 09:17:08.705 09:20:16.871 耗时188168ms 2 prd_904660580017635328 异常: 截点设置仅可通过待审核状态 09:18:10.057 09:20:23.334 耗时133279ms 3 prd_904660629439131648 异常: 截点设置仅可通过待审核状态 09:18:21.840 09:20:23.434 耗时121596ms 4 prd_904660975251095552 异常: 截点设置仅可通过待审核状态 09:19:44.288 09:20:29.833 耗时45547ms 排查分析 4.1、场景分析 1、 Deadlock 非常明显了，说明业务上出现了死锁，可以确定的是业务上有问题。但是改业务代码一直运行了一年，查看Git记录也发现最近没人动该业务相关代码，说明该业务之前就可能有问题，只是最近才达到了触发这种异常的条件 2、从异常日志日志可以看出, Mysql出现了死锁，死锁线程会一直处于等待状态，数据库的连接会一直被占用，之后进来的新请求获取不到数据库连接，处于等待状态，这个时候业务人员第一反应可能是网络原因，页面反馈比较慢。从而多次点击该社保服务网点批量通过的接口，请求就在不断的累加，其中某个事务进行回滚，然后同时提交另外一个事务，最后云服务器CPU利用率达到100%，从而导致系统崩溃。 4.2、对应的代码定位 核心错误的调用方法是哪个，即事务开始的方法是哪个? @Override @Transactional(propagation = Propagation.REQUIRED, rollbackFor = Exception.class) public void pass(PassForSessionConfigReqDto dto) { for (Long id : dto.getIds()) { SectionConfigEntity config1 = sectionConfigLogic.selectByPrimaryKey(id); ValidateParam.isEmpty(config1, \"截点设置信息不存在\"); if (config1.getState() != 0) { throw new ServiceException(ErrorCode.SCO0009); } config1.setState(2); config1.setVerifyTime(new Date()); config1.setVerifyUid(dto.getStaffId()); sectionConfigLogic.update(config1); try { List dateList = DateUtil.getMonthBetween(config1.getEffectiveStartTime(), config1.getEffectiveEndTime()); for (String date : dateList) { // todo 具体逻辑处理 ...... } } catch (ParseException e) { logger.error(\"生成社保日历异常\"); } } } 4.3、大事务 从功能需求上看、批量通过社保服务网点的方法是包裹在一个大事务中的。 4.3.1、什么是大事务？ 可以总结成一句话，就是运行时间比较长，操作的数据比较多的事务。 4.3.2、如何查询大事务？ ### 查询执行时间超过10秒的事务 select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))>10 4.3.3、大事务一般会对数据库造成什么问题？ 4.3.3.1、锁定数据过多，容易造成大量的死锁和锁超时 当系统中不同事务之间出现循环资源依赖，涉及的事务都在等待别的事务释放资源时，就会导致这几个事务都进入无限等待的状态，比如下面这个场景： 步骤 事务A 事务B 1 ` BEGIN; ` 2 ` UPDATE ` mall ` . ` pms_sku_stock ` SET ` price ` = 100.00 WHERE ` id ` = 1; ` 3 ` BEGIN; ` 4 ` UPDATE `mall` . `pms_sku_stock` SET `price` = 100.00 WHERE `id` = 2; ` 5 ` UPDATE `mall` . `pms_sku_stock` SET `price` = 100.00 WHERE `id` = 2; ` 6 ` UPDATE ` mall ` . ` pms_sku_stock ` SET ` price ` = 100.00 WHERE ` id ` = 1; ` 1、执行mysql返回日志 这个时候，事务A在等待事务B释放id=2的行锁，而事务B在等待事务A释放id=2的行锁。事务A和事务B在互相等待对方的资源释放，就是进入了死锁状态 ### 执行后反馈的异常 1213 - Deadlock found when trying to get lock; try restarting transaction, Time: 0.031000s 2、死锁日志 去查看对应的数据库最近一次发生死锁日志，使用命令：show engine innodb status; *** (1) TRANSACTION: TRANSACTION 12307473, ACTIVE 49 sec starting index read #事务一 活跃49S 状态是read mysql tables in use 1, locked 1 #tables in use 1 表示一个表被使用 locked 1 表示有一个表锁 LOCK WAIT 3 lock struct(s), heap size 1136, 2 row lock(s) #LOCK WAIT 表示事务正在等待锁 | 3 lock struct(s) 表示该事务的锁链表的长度为2，每个链表节点代表该事务持有的一个锁结构，包括表锁，记录锁以及 autoinc 锁等| 2 row lock(s) 表示当前事务持有的行锁个数 MySQL thread id 24584, OS thread handle 139819141809920, query id 108335192 39.170.42.74 fangyang updating UPDATE `mall`.`pms_sku_stock` SET `price` = 100.00 WHERE `id` = 2 #这里显示的是正在等待锁的SQL语句，通过这个我们可以找到具体的业务数据，不过如果SQL过长的话会被截断，可以结合binlog去找 *** (1) HOLDS THE LOCK(S): #事务一 持有的行锁，往往就是事务二等待的锁 RECORD LOCKS space id 41 page no 4 n bits 104 index PRIMARY of table `mall`.`pms_sku_stock` trx id 12307473 lock_mode X locks rec but not gap Record lock, heap no 2 PHYSICAL RECORD: n_fields 17; compact format; info bits 0 #RECORD LOCKS 表示记录锁（并且可以看出要加锁的索引为 id|lock mode X waiting表持有一个记录锁排他锁，非间隙 0: len 8; hex 8000000000000001; asc ;; 1: len 6; hex 000000018bbe; asc ;; 2: len 7; hex 85000000d30128; asc (;; 3: len 8; hex 000000000001ebdb; asc ;; 4: len 8; hex 8003000001da1073; asc s;; 5: len 8; hex 8000000000000007; asc ;; 6: len 6; hex 737472696e67; asc string;; 7: len 5; hex 8000006400; asc d ;; 8: len 4; hex 80000000; asc ;; 9: len 4; hex 80000005; asc ;; 10: len 6; hex 737472696e67; asc string;; 11: len 6; hex 737472696e67; asc string;; 12: len 6; hex 737472696e67; asc string;; 13: len 6; hex 737472696e67; asc string;; 14: len 4; hex 80000000; asc ;; 15: SQL NULL; 16: len 4; hex 80000000; asc ;; *** (1) WAITING FOR THIS LOCK TO BE GRANTED: #此处表示当前事务一等待获取行锁； RECORD LOCKS space id 41 page no 4 n bits 104 index PRIMARY of table `mall`.`pms_sku_stock` trx id 12307473 lock_mode X locks rec but not gap waiting #InnoDB试图在行上获得排他锁（实际上是对聚集索引记录PK的锁），而不是周围的间隙（间隙锁） Record lock, heap no 3 PHYSICAL RECORD: n_fields 17; compact format; info bits 0 0: len 8; hex 8000000000000002; asc ;; 1: len 6; hex 000000018bbf; asc ;; 2: len 7; hex 86000000d40128; asc (;; 3: len 8; hex 000000000001ebdd; asc ;; 4: len 8; hex 8004000001ef0d3a; asc :;; 5: len 8; hex 8000000000000008; asc ;; 6: len 6; hex 737472696e67; asc string;; 7: len 5; hex 8000006400; asc d ;; 8: len 4; hex 80000000; asc ;; 9: len 4; hex 80000005; asc ;; 10: len 6; hex 737472696e67; asc string;; 11: len 6; hex 737472696e67; asc string;; 12: len 6; hex 737472696e67; asc string;; 13: len 6; hex 737472696e67; asc string;; 14: len 4; hex 80000000; asc ;; 15: SQL NULL; 16: len 4; hex 80000000; asc ;; *** (2) TRANSACTION: #此处表示事务1开始 TRANSACTION 12307475, ACTIVE 45 sec starting index read #事务二 活跃45S 状态是read mysql tables in use 1, locked 1 LOCK WAIT 3 lock struct(s), heap size 1136, 2 row lock(s) #LOCK WAIT 表示事务正在等待锁 | 2 lock struct(s) 表示该事务的锁链表的长度为2，每个链表节点代表该事务持有的一个锁结构，包括表锁，记录锁以及 autoinc 锁等| 2 row lock(s) 表示当前事务持有的行锁个数 MySQL thread id 24586, OS thread handle 139818176603904, query id 108335414 39.170.42.74 fangyang updating UPDATE `mall`.`pms_sku_stock` SET `price` = 100.00 WHERE `id` = 1 *** (2) HOLDS THE LOCK(S): #此处表示当前事务二持有的行锁； RECORD LOCKS space id 41 page no 4 n bits 104 index PRIMARY of table `mall`.`pms_sku_stock` trx id 12307475 lock_mode X locks rec but not gap Record lock, heap no 3 PHYSICAL RECORD: n_fields 17; compact format; info bits 0 #事务二 持有一个记录锁排他锁，非间隙锁 1: len 6; hex 000000018bbf; asc ;; 2: len 7; hex 86000000d40128; asc (;; 3: len 8; hex 000000000001ebdd; asc ;; 4: len 8; hex 8004000001ef0d3a; asc :;; 5: len 8; hex 8000000000000008; asc ;; 6: len 6; hex 737472696e67; asc string;; 7: len 5; hex 8000006400; asc d ;; 8: len 4; hex 80000000; asc ;; 9: len 4; hex 80000005; asc ;; 10: len 6; hex 737472696e67; asc string;; 11: len 6; hex 737472696e67; asc string;; 12: len 6; hex 737472696e67; asc string;; 13: len 6; hex 737472696e67; asc string;; 14: len 4; hex 80000000; asc ;; 15: SQL NULL; 16: len 4; hex 80000000; asc ;; *** (2) WAITING FOR THIS LOCK TO BE GRANTED: #此处表示当前事务二等待获取行锁； RECORD LOCKS space id 41 page no 4 n bits 104 index PRIMARY of table `mall`.`pms_sku_stock` trx id 12307475 lock_mode X locks rec but not gap waiting # InnoDB试图在行上获得排他锁（实际上是对聚集索引记录PK的锁），而不是周围的间隙（间隙锁） Record lock, heap no 2 PHYSICAL RECORD: n_fields 17; compact format; info bits 0 0: len 8; hex 8000000000000001; asc ;; 1: len 6; hex 000000018bbe; asc ;; 2: len 7; hex 85000000d30128; asc (;; 3: len 8; hex 000000000001ebdb; asc ;; 4: len 8; hex 8003000001da1073; asc s;; 5: len 8; hex 8000000000000007; asc ;; 6: len 6; hex 737472696e67; asc string;; 7: len 5; hex 8000006400; asc d ;; 8: len 4; hex 80000000; asc ;; 9: len 4; hex 80000005; asc ;; 10: len 6; hex 737472696e67; asc string;; 11: len 6; hex 737472696e67; asc string;; 12: len 6; hex 737472696e67; asc string;; 13: len 6; hex 737472696e67; asc string;; 14: len 4; hex 80000000; asc ;; 15: SQL NULL; 16: len 4; hex 80000000; asc ;; *** WE ROLL BACK TRANSACTION (2) ------------ TRANSACTIONS 两种策略可以处理死锁 [!note] 1、等待死锁超时。超时时间（innodb_lock_wait_timeout）默认是50s，这时间可以说真的是太长了，但是如果改小了吧，又可能会影响到本可以正常消除的死锁 2、Mysqlinnodb引擎自动检测死锁机制。锁检测的配置默认是开启的。MySQL选择打断其中一个事务破坏死锁条件来消除死锁。Mysql官方文档上显示，mysql会选择杀死小的事务，这里的小指的是执行的insert, update, detected语句数目小的事务。需要注意的是mysql inno 4.3.3.2、回滚记录占用大量存储空间，事务回滚时间长 [!note] 在MySQL中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。回滚日志不会一直保留着，当没有事务再需要用到这些回滚日志时，回滚日志会被删除。 4.3.3.3、执行时间长，容易造成主从延迟 [!note] 因为主库上必须等事务执行完成才会写入binlog，再传给从库。所以，如果一个主库上的语句执行10分钟，那这个事务很可能就会导致从库延迟10分钟 4.4、如何解决大事务带来的问题 1、基于两阶段锁协议 在InnoDB事务中，行锁是在需要的时候加上的，但并不是不需要了就立即释放，而是要等到食物结束时才释放。 基于两阶段协议我们可以进行优化:如果事务中需要多个行，要把最可能造成锁冲突的、最可能影响并发度的锁尽量往后放。 [!note] 比如我之前负责实现的用户报名兼职（针对单体架构）。用户报名兼职业务，需要涉及到以下的操作: 1、生成用户报名记录 2、对应兼职商家的总的报名单数量-1 3、记录一条对应商家的报名单消耗的记录 为了保证兼职报名单的原子性，需要将这三个操作放在一个事务中。假设同时有另外一个用户报名该商家发布的同一条个兼职。那么这两个事务冲突的部分就是操作2。因为它们要更新同一个商家账户下的报名单总的余额，需要修改同一行数据。根据两阶段锁协议，不论怎样安排语句顺序，所有的操作需要的行锁都是在事务提交的时候才释放的。但是如果按照1、3、2这样的顺序进行执行，那么商家报名单余量这一行的锁时间就最少。这就最大程度地减少了事务之间的锁等待，提升了并发度。 2、基于死锁检测 如果要解决死锁检测的问题那么就只能控制O(n)的数量，当同一行并发数小的时候死锁检测的成本就会很低了。 **参考JDK1.7的ConcurrentHashMap的分段锁设计，将一行数据改成逻辑上的多行数据来减少锁冲突。** [!note] 1、接着以用户报名商家兼职为例，可以将一个商家账号信息放在多条记录上，比如5个记录。商家账号报名单总数等于这5个记录的值的总和。这样每次扣减商家报名单数量的的时候，随机选其中一条记录来扣减。这样每次冲突概率变成原来的1/5，可以减少锁等待个数，也就减少了死锁检测的CPU消耗。 2、对于上面的方案，需要根据业务逻辑做详细设计。特别是当一行的报名单记录为0的时候，需要做特殊处理. 3、基于事务的隔离级别 MySQL的事务隔离级别默认是可重复读, 在这个隔离级别下写数据的时候会有这些问题： [!note] 1、如果有索引（包括主键索引）的时候，以索引列为条件更新数据，会存在间隙锁、行锁的问题，从而锁住一些行 2、如果没有索引，更新数据时会锁住整张表 3、如果把隔离级别改为读提交就不存在这两个问题了，每次写数据只会锁一行 项目中如何避免引起的死锁 死锁在目前的工作中遇到的是比较少的，需要结合不同的死锁日志进行分析和复现需要耗费挺多的精力，Mysql数据库通过行级锁的方式进行底层的优化。但是也产生死锁的问题。在平时的工作中可以通过一些可控的手段，降低出现死锁的概率。 避免死锁常见的方案 1、在InnoDB事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放，如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。 2、案例中的死锁问题为什么之前的一年都没有问题，突然抛出这种异常。业务人员的多次点击批量通过接口，导致有多个事务同时执行，并且多个事务中包含了相同的两个或者两个以上的服务网点的id，刚好其中每个事务是批量执行通过的，其中的某一个网点因为业务原因导致服务网点不能通过，从而导致这一批数据需要全部进行回滚，而在另外一个事务中也在执行批量相同的服务网点id通过，触发了这种异常。所以 需要添加短时间内的幂等操作，防止并发 3、调整事务的隔离级别。此方法影响面比较广，如果业务允许，将隔离级别调低也是较好的选择. 4、避免大事务，大事务更倾向于死锁，尽量将大事务拆成多个小事务来处理；因为大事务占用资源多，耗时长，与其他事务冲突的概率也会变高 5、设置锁等待超时参数：innodb_lock_wait_timeout，这个参数并不是只用来解决死锁问题，在并发访问比较高的情况下，如果大量事务因无法立即获得所需的锁而挂起，会占用大量计算机资源，造成严重性能问题，甚至拖跨数据库。我们通过设置合适的锁等。 6、采用固定的顺序去访问表和行数据。比如两个job批量更新的场景，简单方法是对id列表先排序，后执行，这样就避免了交叉等待锁的情形；另外，将两个事务的sql顺序调整为一致，也能避免死锁。 7、尽可能的走主键ID或索引进行更新。可以看到如果不走索引或ID，将会进行全表扫描，会对每一行记录添加上锁，很容易造成死锁。 社保服务网点批量通过业务技术优化调整 优化点 对麒麟系统目前就只需要控制幂等+大事务拆分就可以解决当前出现的问题 1、短时间内的幂等操作，防止并发。 2、避免这种大事务，将批量的大事务拆分成单个的小时候处理。（如果考虑到性能可以利用线程池+手动事务处理）。 总结 回顾下这次故障整个过程，其实整个类似异常信息在一个月前就已经暴露出来了，但是当时服务器性能也正常，偶现的情况没有太过关注。只有当这些小的问题彻底暴露出来，从而拖垮整个服务器才会引起重视, 同时也暴露出目前架构平台监控的力度不够. 在今后的业务迭代中、特别是大事务批量执行的场景，在写代码也要多考虑这方面的内容。目前自己的代码是否也能触发死锁的产生。（⚠️ps: 特别是需要批大量操作数据的业务和导入相关的功能特别注意） 平时可以多关注线上服务的异常的日志，提早发现扼杀在摇篮中。后续会总结下数据库连接池的原理已经innodb下常见的锁类型。 "},"项目规范/":{"url":"项目规范/","title":"3.项目管理规范","keywords":"","body":"项目规范 [!note] 主要是记录推行一些公司的技术规范 系统架构图 "},"项目规范/section1.html":{"url":"项目规范/section1.html","title":"3.1 测试bug类型定义","keywords":"","body":"测试bug类型定义 [!note] 以下内容转自测试部的标准规范 缺陷分类 需求缺陷 开发、测试、实际使用中，发现需求有不完善或存在漏洞的地方（逻辑缺陷） 新出的需求与现存的需求存在冲突（出需求未全局考虑） 新出的需求不能满足本版本所期望的功能实现（后期打补丁的情况） 原型上写的需求不易理解或存在二义性，导致开发进行二次开发，增加工作量 功能缺陷 功能缺失、功能未实现、功能使用时报错、开发出需求上没有的功能（多余功能、不需要的） 执行结果与预期结果不一致 实现的功能与需求定义的不一致 与原型所有需求设计实现不一致的地方 方案变更商议一致除外 代码缺陷 源码存在安全漏洞、应作限制而未限制的越权操作等 数据流、语义、结构、控制流、配置等方面报错 界面优化 错别字类 界面元素及交互实现方式与统一布局标准不一致 美观度、易用性、页面与设计稿不符 设计缺陷 设计实现与需求不符 操作交互实现与用户使用习惯不符 设计与统一布局标准冲突 业务流程设计、接口设计 、数据库表设计等不能满足业务需求 数据异常 输入框长度、类型、空格等未作限制 必填与非必填未作区分，未作控制 特定字符未作规则判断 重复数据写库，重复提交未作控制 异常需作处理或提示的未作处理或提示 接口或功能变更导致新、旧数据异常 外部原因 与第三方对接的所有第三方的bug 引入第三方框架源码本身的缺陷 性能问题 接口性能问题 客户端性能问题（web页面渲染、资源加载等相关的） 操作检验差，响应较慢的问题（跨库跨表慢查询等） 安全问题 SQL注入 XSS漏洞 越权问题 引入不安全的第三方组件 登录校验不严格，存在撞库或绕过登录验证等逻辑漏洞 接口请求写库权限控制不严谨，可能存在被刷或被攻击的情况 URL未作处理，存在被爬虫爬的风险等 兼容性问题 WEB主流浏览器各版本及wap页面功能及界面的兼容性 安卓目前市场的系统流行版本、各主流机型的兼容性问题 IOS端兼容性问题 其他 暂无法清晰分类的问题 缺陷等级 P0级：致命 服务器崩溃，如操作或上线后导致服务器不可用等。（尽量考虑存量） 软件崩溃，操作后软件自动崩溃退出。 系统重要模块功能、主核心业务流程不可用，报系统繁忙等异常提示 核心数据丢失或异常，应该落库的信息未落库或写入错误、重复写入等导致信息丢失、异常情况。 数据库出现死锁、数据库通讯异常 核心接口不通 主核心业务流的实现与产品的需求不符或未达到设计要求，导致主流程无法流转，无法继续测试 P1级：严重 重要的数据计算或传参取值错误 业务流无法正常使用或功能实现不符合设计要求 功能实现造成业务数据紊乱、丢失、保存不完整、无法保存、数据一致性异常等情形 重要接口或功能未实现，操作无响应 重要接口或功能更新导致旧数据异常或造成其他模块功能异常 敏感数据的权限控制存在缺陷 功能实现在明确的已支持的平台或版本上存在兼容性问题，导致功能不可用的情形。 操作响应时间超过8s。（看项目协商处理） P2级：一般 一般功能不可用或达不到设计要求，但不影响主业务流程的流转 未作相应的信息合法性校验 兼容性问题，体验不好但可用 显示/打印的内容或格式错误 应有的提示，未给出提示或给出的提示错误 P3级：提示 界面UI显示异常但不影响操作 辅助边缘性功能实现错误或不全，如不重要的日志记录、打印、查询等 提示性文字错位、错字或描述不清等 交互不友好，操作不便 其他 "},"项目规范/section2.html":{"url":"项目规范/section2.html","title":"3.2 项目过程变更情况处理方案","keywords":"","body":"项目过程变更情况处理方案 [!note] 在项目过程中存在一些特殊情况需要变更，实属正常，我们需要以平常心去拥抱变化，并以合理的应对方案去驱动变化。以下列举了常见的几种变更情况的处理流程 项目延期 [!note] 因需求方案的不严谨导致逻辑的缺失，需求的临时新增，技术方案设计的不严谨须调整方案，技术理解需求的偏差等等情况都会导致项目可能会延期 一般来讲：因需求的临时新增，或别的项目延期导致此项目顺延这两类是可接受的项目延期状况，其他情况都是项目前期准备不充分导致的延期，这种情况原则上都需要努力去追补的。 我们首先要思考通过如何方式去改变延期或减少延期时间，最常用的方式是需要加班去追赶进度或项目内成员任务适当分担调配解决。若尝试努力后也无法完全解决延期的，需要按如下流程走： 1、项目经理及时现场找总监说明实际情况，进一步寻求资源解决，或获得延期同意。 2、获得延期同意后，项目经理须邮件同步项目延期说明，更新延期后的新的项目时间，TAPD上任务时间做相应的调整。 项目优先级变更 因特殊项目的优先级特别高，需要临时插入而中断现行中的项目时，须按如下流程走。当然，需要尽量避免此类情况的发生 1、产品经理及时现场找总监说明实际情况，获得优先级变更同意；a 2、获得项目优先级变更同意后，产品经理须邮件同步说明情况； 3、项目经理收到此通知后，须回复被影响项目新的项目时间，同时TAPD上任务时间做相应的调整。 [!Tip] 若插入的内容不多，对现行项目的完成时间无影响时，由产品经理和项目经理协商解决 "},"项目规范/section3.html":{"url":"项目规范/section3.html","title":"3.3 技术评审会规则","keywords":"","body":"项技术评审会规则 技术评审会参与人员 项目成员、产品经理、该线产品经理主管、架构师、跨组协作人员 抄送人员：总监 [!Tip] 因产品安排的会议较多，为避免冲突，须提前一天与产品经理沟通时间 技术评审会议纪要邮件由项目经理发送 主送：项目全员 抄送：techleads、总监 内容 技术方案本身：整体性的描述，技术设计资料，如流程图交互图、模型设计表结构等 评审结论：是否通过，是否需要再开 需修改点：评审时记录的修改点 待确认事项/保留事项/Action事项：明确事项内容、责任人、期限（例如，有哪些事项是需要产品会后确认并反馈的，可以约定时间要求产品按时间节点前反馈 "},"项目规范/section4.html":{"url":"项目规范/section4.html","title":"3.4 多产品线联动，项目如何有序推进","keywords":"","body":"多产品线联动，项目如何有序推进 [!note] 随着分工的精细化，业务线整体串联闭环时，特别考验团队的合作配合能力。现就常规遇到的问题，给大家一些指导性的处理方法。 产品这边谁是主负责人 以引起这次变动的发起产品线的产品经理为主要负责人 [!note] 如：给大家举几个熟悉的场景 CRM要变更合同关系，会影响各业务线配合调整，那CRM线产品经理为主要负责人； 社保线要上线某个功能，需要CRM和财务线都配合调整，那社保线该版本的产品经理为此次联动上线项目的总负责人； 要新起项目中心线，代替原来的启动函分配，会影响从CRM到财务到各业务线的整体配合，那项目中心产品经理为此次的联动发版的总负责人 多产品线联动总负责人主要做什么工作 1、在产品方案阶段负责和各产品线产品经理串联好整体的方案，不能仅限于自己的一亩三分地，要大概知道相关产品线的产品方案，自己的东西对他们大概的影响点，左右都各走一遍做基本的了解； 2、在需求技术评审时，关联产品线相关技术人员派代表参与，一起把控前后串联关系，也为后面做技术方案提供业务背景依据； 3、按各线项目经理给出的排期时间，评估是否符合预期目标，是否各环节都能衔接上； 4、给业务端的上线时间是各线串联闭环的上线时间，而不是单个自己产品线迭代的上线时间，要满足业务功能具备使用条件来输出时间； 5、项目开发过程中，定期和项目经理了解情况，把控项目总体风险，有风险时及时反馈上级或对应职能的主管协调解决。 开发项目经理谁是主要负责人 [!note] 和产品负责人对应版本的项目负责人为总负责人 和产品负责人对应版本的项目负责人为总负责人 1、在技术方案评审时：需要和关联产品线的开发人员一起商议决策技术对接方案 2、在排期时：需要给出配合产品线各节点配合时间，如：接口时间，联调时间，配合测试时间，回归时间等等 3、在项目开发过程中：要定期和各产品线相应版本的项目经理碰进度，及时发现存在的问题。尤其进入串联调试期时，最好相关业务线的项目经理与一起参与主版本的站立会； "},"end/":{"url":"end/","title":"结束","keywords":"","body":"结束 啦啦啦 真的结束了 "}}